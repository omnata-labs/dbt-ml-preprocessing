{"nodes": {"model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_50_bins": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.k_bins_discretizer( ref('data_k_bins_discretizer') ,['col_to_bin_1'],n_bins=50) }}\r\n\r\n)\r\n\r\nselect * from data\r\norder by id_col", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_k_bins_discretizer_50_bins"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_50_bins", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_k_bins_discretizer_50_bins.sql", "original_file_path": "models\\sql\\test_k_bins_discretizer_50_bins.sql", "name": "test_k_bins_discretizer_50_bins", "resource_type": "model", "alias": "test_k_bins_discretizer_50_bins", "checksum": {"name": "sha256", "checksum": "cec4b6b5cb99518b8066b256e266394c87978fdb1ff5c9538c373d011b8ac682"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_k_bins_discretizer"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing.k_bins_discretizer"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\sql\\schema.yml", "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_k_bins_discretizer_50_bins.sql", "deferred": false, "compiled_sql": "\n\nwith data as (\n\n    -- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_bin_1_aggregates as(\n        select\n            min(col_to_bin_1) as min_value,\n            max(col_to_bin_1) as max_value\n        from DEMO_DB.DBT_MACRO.data_k_bins_discretizer\n    )\n\n\n\nselect \n\nsource_table.\"ID_COL\",\n\nsource_table.\"COL_TO_BIN_1\",\n\nsource_table.\"COL_TO_BIN_2\",\n\n\n\n    least(width_bucket(col_to_bin_1,col_to_bin_1_aggregates.min_value,col_to_bin_1_aggregates.max_value,50) - 1,49) as col_to_bin_1_binned\n    \n\nfrom \n  \n      col_to_bin_1_aggregates,\n  \n  DEMO_DB.DBT_MACRO.data_k_bins_discretizer as source_table\n\n\n\n)\n\nselect * from data\norder by id_col", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith data as (\n\n    -- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_bin_1_aggregates as(\n        select\n            min(col_to_bin_1) as min_value,\n            max(col_to_bin_1) as max_value\n        from DEMO_DB.DBT_MACRO.data_k_bins_discretizer\n    )\n\n\n\nselect \n\nsource_table.\"ID_COL\",\n\nsource_table.\"COL_TO_BIN_1\",\n\nsource_table.\"COL_TO_BIN_2\",\n\n\n\n    least(width_bucket(col_to_bin_1,col_to_bin_1_aggregates.min_value,col_to_bin_1_aggregates.max_value,50) - 1,49) as col_to_bin_1_binned\n    \n\nfrom \n  \n      col_to_bin_1_aggregates,\n  \n  DEMO_DB.DBT_MACRO.data_k_bins_discretizer as source_table\n\n\n\n)\n\nselect * from data\norder by id_col"}, "model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_default_bins": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.k_bins_discretizer( ref('data_k_bins_discretizer') ,['col_to_bin_1','col_to_bin_2']) }}\r\n\r\n)\r\n\r\nselect * from data\r\norder by id_col", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_k_bins_discretizer_default_bins"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_default_bins", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_k_bins_discretizer_default_bins.sql", "original_file_path": "models\\sql\\test_k_bins_discretizer_default_bins.sql", "name": "test_k_bins_discretizer_default_bins", "resource_type": "model", "alias": "test_k_bins_discretizer_default_bins", "checksum": {"name": "sha256", "checksum": "ee9c25003d36fececf68fc89d1e34ca7ebb8fbebfea67165321c8919c1e2e790"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_k_bins_discretizer"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing.k_bins_discretizer"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\sql\\schema.yml", "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_k_bins_discretizer_default_bins.sql", "deferred": false, "compiled_sql": "\n\nwith data as (\n\n    -- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_bin_1_aggregates as(\n        select\n            min(col_to_bin_1) as min_value,\n            max(col_to_bin_1) as max_value\n        from DEMO_DB.DBT_MACRO.data_k_bins_discretizer\n    )\n, \n\n    col_to_bin_2_aggregates as(\n        select\n            min(col_to_bin_2) as min_value,\n            max(col_to_bin_2) as max_value\n        from DEMO_DB.DBT_MACRO.data_k_bins_discretizer\n    )\n\n\n\nselect \n\nsource_table.\"ID_COL\",\n\nsource_table.\"COL_TO_BIN_1\",\n\nsource_table.\"COL_TO_BIN_2\",\n\n\n\n    least(width_bucket(col_to_bin_1,col_to_bin_1_aggregates.min_value,col_to_bin_1_aggregates.max_value,20) - 1,19) as col_to_bin_1_binned\n    , \n\n    least(width_bucket(col_to_bin_2,col_to_bin_2_aggregates.min_value,col_to_bin_2_aggregates.max_value,20) - 1,19) as col_to_bin_2_binned\n    \n\nfrom \n  \n      col_to_bin_1_aggregates,\n  \n      col_to_bin_2_aggregates,\n  \n  DEMO_DB.DBT_MACRO.data_k_bins_discretizer as source_table\n\n\n\n)\n\nselect * from data\norder by id_col", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith data as (\n\n    -- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_bin_1_aggregates as(\n        select\n            min(col_to_bin_1) as min_value,\n            max(col_to_bin_1) as max_value\n        from DEMO_DB.DBT_MACRO.data_k_bins_discretizer\n    )\n, \n\n    col_to_bin_2_aggregates as(\n        select\n            min(col_to_bin_2) as min_value,\n            max(col_to_bin_2) as max_value\n        from DEMO_DB.DBT_MACRO.data_k_bins_discretizer\n    )\n\n\n\nselect \n\nsource_table.\"ID_COL\",\n\nsource_table.\"COL_TO_BIN_1\",\n\nsource_table.\"COL_TO_BIN_2\",\n\n\n\n    least(width_bucket(col_to_bin_1,col_to_bin_1_aggregates.min_value,col_to_bin_1_aggregates.max_value,20) - 1,19) as col_to_bin_1_binned\n    , \n\n    least(width_bucket(col_to_bin_2,col_to_bin_2_aggregates.min_value,col_to_bin_2_aggregates.max_value,20) - 1,19) as col_to_bin_2_binned\n    \n\nfrom \n  \n      col_to_bin_1_aggregates,\n  \n      col_to_bin_2_aggregates,\n  \n  DEMO_DB.DBT_MACRO.data_k_bins_discretizer as source_table\n\n\n\n)\n\nselect * from data\norder by id_col"}, "model.dbt_ml_preprocessing_integration_tests.test_label_encoder": {"raw_sql": "{{ config(materialized='table') }} -- as a table because Redshift can't handle the equality checker query when it's a view\r\n\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.label_encoder( ref('data_label_encoder') ,'col_to_label_encode') }}\r\n\r\n)\r\n\r\nselect * from data", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_label_encoder"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_label_encoder", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_label_encoder.sql", "original_file_path": "models\\sql\\test_label_encoder.sql", "name": "test_label_encoder", "resource_type": "model", "alias": "test_label_encoder", "checksum": {"name": "sha256", "checksum": "894553cc057a60f06933bb647424a10f00ced8c10cd1efcdd61c4e4d31c456a4"}, "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_label_encoder"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing.label_encoder"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_label_encoder"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\sql\\schema.yml", "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_label_encoder.sql", "deferred": false, "compiled_sql": " -- as a table because Redshift can't handle the equality checker query when it's a view\n\nwith data as (\n\n    \n\nwith distinct_values as (\n    select array_agg(distinct col_to_label_encode) within group (order by col_to_label_encode asc) as all_values_array from DEMO_DB.DBT_MACRO.data_label_encoder\n)\nselect \n\nDEMO_DB.DBT_MACRO.data_label_encoder.*,\n\narray_position(col_to_label_encode::variant,all_values_array) as col_to_label_encode_encoded\nfrom distinct_values,DEMO_DB.DBT_MACRO.data_label_encoder\n\n\n\n)\n\nselect * from data", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": " -- as a table because Redshift can't handle the equality checker query when it's a view\n\nwith data as (\n\n    \n\nwith distinct_values as (\n    select array_agg(distinct col_to_label_encode) within group (order by col_to_label_encode asc) as all_values_array from DEMO_DB.DBT_MACRO.data_label_encoder\n)\nselect \n\nDEMO_DB.DBT_MACRO.data_label_encoder.*,\n\narray_position(col_to_label_encode::variant,all_values_array) as col_to_label_encode_encoded\nfrom distinct_values,DEMO_DB.DBT_MACRO.data_label_encoder\n\n\n\n)\n\nselect * from data"}, "model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.max_abs_scaler( ref('data_max_abs_scaler') ,['col_to_scale']) }}\r\n\r\n)\r\n\r\nselect * from data", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_max_abs_scaler"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_max_abs_scaler.sql", "original_file_path": "models\\sql\\test_max_abs_scaler.sql", "name": "test_max_abs_scaler", "resource_type": "model", "alias": "test_max_abs_scaler", "checksum": {"name": "sha256", "checksum": "77aec296ace517932d712fca73ccef9581f0da51c8b36575038db92714f78833"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_max_abs_scaler"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing.max_abs_scaler"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\sql\\schema.yml", "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_max_abs_scaler.sql", "deferred": false, "compiled_sql": "\n\nwith data as (\n\n    \n\n-- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_scale_aggregates as(\n        select\n            max(abs(col_to_scale)) as max_abs_value\n        from DEMO_DB.DBT_MACRO.data_max_abs_scaler\n    )\n\n\n\nselect \n\nsource_table.\"ID_COL\",\n\nsource_table.\"COL_TO_SCALE\",\n\n\n    col_to_scale / col_to_scale_aggregates.max_abs_value AS col_to_scale_scaled\n    \n\n\nfrom \n    \n        col_to_scale_aggregates,\n    \n    DEMO_DB.DBT_MACRO.data_max_abs_scaler as source_table\n\n\n)\n\nselect * from data", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith data as (\n\n    \n\n-- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_scale_aggregates as(\n        select\n            max(abs(col_to_scale)) as max_abs_value\n        from DEMO_DB.DBT_MACRO.data_max_abs_scaler\n    )\n\n\n\nselect \n\nsource_table.\"ID_COL\",\n\nsource_table.\"COL_TO_SCALE\",\n\n\n    col_to_scale / col_to_scale_aggregates.max_abs_value AS col_to_scale_scaled\n    \n\n\nfrom \n    \n        col_to_scale_aggregates,\n    \n    DEMO_DB.DBT_MACRO.data_max_abs_scaler as source_table\n\n\n)\n\nselect * from data"}, "model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler_with_column_selection": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.max_abs_scaler( ref('data_max_abs_scaler') ,['col_to_scale'],include_columns=['id_col']) }}\r\n\r\n)\r\n\r\nselect * from data", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_max_abs_scaler_with_column_selection"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler_with_column_selection", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_max_abs_scaler_with_column_selection.sql", "original_file_path": "models\\sql\\test_max_abs_scaler_with_column_selection.sql", "name": "test_max_abs_scaler_with_column_selection", "resource_type": "model", "alias": "test_max_abs_scaler_with_column_selection", "checksum": {"name": "sha256", "checksum": "05a91671570bcbd39df4b54b134228f90b1026bdee70214e504bf304a46e3582"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_max_abs_scaler"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing.max_abs_scaler"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\sql\\schema.yml", "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_max_abs_scaler_with_column_selection.sql", "deferred": false, "compiled_sql": "\n\nwith data as (\n\n    \n\n-- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_scale_aggregates as(\n        select\n            max(abs(col_to_scale)) as max_abs_value\n        from DEMO_DB.DBT_MACRO.data_max_abs_scaler\n    )\n\n\n\nselect \n\nsource_table.id_col,\n\n\n    col_to_scale / col_to_scale_aggregates.max_abs_value AS col_to_scale_scaled\n    \n\n\nfrom \n    \n        col_to_scale_aggregates,\n    \n    DEMO_DB.DBT_MACRO.data_max_abs_scaler as source_table\n\n\n)\n\nselect * from data", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith data as (\n\n    \n\n-- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_scale_aggregates as(\n        select\n            max(abs(col_to_scale)) as max_abs_value\n        from DEMO_DB.DBT_MACRO.data_max_abs_scaler\n    )\n\n\n\nselect \n\nsource_table.id_col,\n\n\n    col_to_scale / col_to_scale_aggregates.max_abs_value AS col_to_scale_scaled\n    \n\n\nfrom \n    \n        col_to_scale_aggregates,\n    \n    DEMO_DB.DBT_MACRO.data_max_abs_scaler as source_table\n\n\n)\n\nselect * from data"}, "model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.min_max_scaler( ref('data_max_abs_scaler') ,['col_to_scale']) }}\r\n\r\n)\r\n\r\nselect * from data", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_min_max_scaler"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_min_max_scaler.sql", "original_file_path": "models\\sql\\test_min_max_scaler.sql", "name": "test_min_max_scaler", "resource_type": "model", "alias": "test_min_max_scaler", "checksum": {"name": "sha256", "checksum": "a021b70546557fb96422399a0bcb8a0a0cd59cbc9618123fe7b685a442c97d14"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_max_abs_scaler"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing.min_max_scaler"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\sql\\schema.yml", "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_min_max_scaler.sql", "deferred": false, "compiled_sql": "\n\nwith data as (\n\n    \n\n-- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_scale_aggregates as(\n        select\n            min(col_to_scale) as min_value,\n            max(col_to_scale) as max_value\n        from DEMO_DB.DBT_MACRO.data_max_abs_scaler\n    )\n\n\n\nselect \n\nsource_table.\"ID_COL\",\n\nsource_table.\"COL_TO_SCALE\",\n\n\n    (col_to_scale - col_to_scale_aggregates.min_value) / (col_to_scale_aggregates.max_value - col_to_scale_aggregates.min_value) AS col_to_scale_scaled\n    \n\n\nfrom  \n    \n        col_to_scale_aggregates,\n    \n    DEMO_DB.DBT_MACRO.data_max_abs_scaler as source_table\n\n\n)\n\nselect * from data", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith data as (\n\n    \n\n-- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_scale_aggregates as(\n        select\n            min(col_to_scale) as min_value,\n            max(col_to_scale) as max_value\n        from DEMO_DB.DBT_MACRO.data_max_abs_scaler\n    )\n\n\n\nselect \n\nsource_table.\"ID_COL\",\n\nsource_table.\"COL_TO_SCALE\",\n\n\n    (col_to_scale - col_to_scale_aggregates.min_value) / (col_to_scale_aggregates.max_value - col_to_scale_aggregates.min_value) AS col_to_scale_scaled\n    \n\n\nfrom  \n    \n        col_to_scale_aggregates,\n    \n    DEMO_DB.DBT_MACRO.data_max_abs_scaler as source_table\n\n\n)\n\nselect * from data"}, "model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler_with_column_selection": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.min_max_scaler( ref('data_max_abs_scaler') ,['col_to_scale'],include_columns=['id_col']) }}\r\n\r\n)\r\n\r\nselect * from data", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_min_max_scaler_with_column_selection"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler_with_column_selection", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_min_max_scaler_with_column_selection.sql", "original_file_path": "models\\sql\\test_min_max_scaler_with_column_selection.sql", "name": "test_min_max_scaler_with_column_selection", "resource_type": "model", "alias": "test_min_max_scaler_with_column_selection", "checksum": {"name": "sha256", "checksum": "d385328aa1d9633f192b2e8bd4f3819888aa4c995c7d833352f6be243a2155b3"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_max_abs_scaler"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing.min_max_scaler"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\sql\\schema.yml", "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_min_max_scaler_with_column_selection.sql", "deferred": false, "compiled_sql": "\n\nwith data as (\n\n    \n\n-- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_scale_aggregates as(\n        select\n            min(col_to_scale) as min_value,\n            max(col_to_scale) as max_value\n        from DEMO_DB.DBT_MACRO.data_max_abs_scaler\n    )\n\n\n\nselect \n\nsource_table.id_col,\n\n\n    (col_to_scale - col_to_scale_aggregates.min_value) / (col_to_scale_aggregates.max_value - col_to_scale_aggregates.min_value) AS col_to_scale_scaled\n    \n\n\nfrom  \n    \n        col_to_scale_aggregates,\n    \n    DEMO_DB.DBT_MACRO.data_max_abs_scaler as source_table\n\n\n)\n\nselect * from data", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith data as (\n\n    \n\n-- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_scale_aggregates as(\n        select\n            min(col_to_scale) as min_value,\n            max(col_to_scale) as max_value\n        from DEMO_DB.DBT_MACRO.data_max_abs_scaler\n    )\n\n\n\nselect \n\nsource_table.id_col,\n\n\n    (col_to_scale - col_to_scale_aggregates.min_value) / (col_to_scale_aggregates.max_value - col_to_scale_aggregates.min_value) AS col_to_scale_scaled\n    \n\n\nfrom  \n    \n        col_to_scale_aggregates,\n    \n    DEMO_DB.DBT_MACRO.data_max_abs_scaler as source_table\n\n\n)\n\nselect * from data"}, "model.dbt_ml_preprocessing_integration_tests.test_normalizer": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.normalizer( ref('data_normalizer') ,['col1','col2','col3','col4']) }}\r\n\r\n)\r\n\r\nselect * from data", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_normalizer"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_normalizer", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_normalizer.sql", "original_file_path": "models\\sql\\test_normalizer.sql", "name": "test_normalizer", "resource_type": "model", "alias": "test_normalizer", "checksum": {"name": "sha256", "checksum": "f4dda1523a423cf2bd0db3b18e1a549b633a82e6421fae932b9d37223b5f9182"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_normalizer"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing.normalizer"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_normalizer"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\sql\\schema.yml", "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_normalizer.sql", "deferred": false, "compiled_sql": "\n\nwith data as (\n\n    with magnitude_calcs as (\n    select \n        \n        source_table.\"ID_COL\",\n        \n        source_table.\"COL1\",\n        \n        source_table.\"COL2\",\n        \n        source_table.\"COL3\",\n        \n        source_table.\"COL4\",\n        \n        SQRT(\n            \n            col1*col1\n             + \n            \n            col2*col2\n             + \n            \n            col3*col3\n             + \n            \n            col4*col4\n            \n            \n        ) as magnitude_calc\n    from DEMO_DB.DBT_MACRO.data_normalizer as source_table\n)\nselect \n\ncase magnitude_calc\n    when 0 then 0\n    else col1/magnitude_calc\n    end as col1_normalized\n, \n\ncase magnitude_calc\n    when 0 then 0\n    else col2/magnitude_calc\n    end as col2_normalized\n, \n\ncase magnitude_calc\n    when 0 then 0\n    else col3/magnitude_calc\n    end as col3_normalized\n, \n\ncase magnitude_calc\n    when 0 then 0\n    else col4/magnitude_calc\n    end as col4_normalized\n\n\nfrom magnitude_calcs\n\n\n)\n\nselect * from data", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith data as (\n\n    with magnitude_calcs as (\n    select \n        \n        source_table.\"ID_COL\",\n        \n        source_table.\"COL1\",\n        \n        source_table.\"COL2\",\n        \n        source_table.\"COL3\",\n        \n        source_table.\"COL4\",\n        \n        SQRT(\n            \n            col1*col1\n             + \n            \n            col2*col2\n             + \n            \n            col3*col3\n             + \n            \n            col4*col4\n            \n            \n        ) as magnitude_calc\n    from DEMO_DB.DBT_MACRO.data_normalizer as source_table\n)\nselect \n\ncase magnitude_calc\n    when 0 then 0\n    else col1/magnitude_calc\n    end as col1_normalized\n, \n\ncase magnitude_calc\n    when 0 then 0\n    else col2/magnitude_calc\n    end as col2_normalized\n, \n\ncase magnitude_calc\n    when 0 then 0\n    else col3/magnitude_calc\n    end as col3_normalized\n, \n\ncase magnitude_calc\n    when 0 then 0\n    else col4/magnitude_calc\n    end as col4_normalized\n\n\nfrom magnitude_calcs\n\n\n)\n\nselect * from data"}, "model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.one_hot_encoder( ref('data_one_hot_encoder') ,'column_to_encode',handle_unknown='ignore') }}\r\n\r\n)\r\n\r\nselect * from data", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_one_hot_encoder"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_one_hot_encoder.sql", "original_file_path": "models\\sql\\test_one_hot_encoder.sql", "name": "test_one_hot_encoder", "resource_type": "model", "alias": "test_one_hot_encoder", "checksum": {"name": "sha256", "checksum": "68e5d95f725120f5c4f13b573f2663297b3d33804266e5c9b5f5ede79c25274e"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_one_hot_encoder"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing.one_hot_encoder"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\sql\\schema.yml", "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_one_hot_encoder.sql", "deferred": false, "compiled_sql": "\n\nwith data as (\n\n    \n        \n        \n            \n            \n        \n    \n    \n\n\n\n\n    with binary_output as (\n    select\n                ID_COL,\n                COLUMN_TO_ENCODE,\n            \n                    case \n                        when column_to_encode = 'A' then true \n                        else false\n                    end as is_column_to_encode_A\n                ,\n            \n                    case \n                        when column_to_encode = 'B' then true \n                        else false\n                    end as is_column_to_encode_B\n                ,\n            \n                    case \n                        when column_to_encode = 'C' then true \n                        else false\n                    end as is_column_to_encode_C\n                ,\n            \n                    case \n                        when column_to_encode = 'D' then true \n                        else false\n                    end as is_column_to_encode_D\n                \n    from DEMO_DB.DBT_MACRO.data_one_hot_encoder\n    )\n\n    select * from binary_output\n\n)\n\nselect * from data", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith data as (\n\n    \n        \n        \n            \n            \n        \n    \n    \n\n\n\n\n    with binary_output as (\n    select\n                ID_COL,\n                COLUMN_TO_ENCODE,\n            \n                    case \n                        when column_to_encode = 'A' then true \n                        else false\n                    end as is_column_to_encode_A\n                ,\n            \n                    case \n                        when column_to_encode = 'B' then true \n                        else false\n                    end as is_column_to_encode_B\n                ,\n            \n                    case \n                        when column_to_encode = 'C' then true \n                        else false\n                    end as is_column_to_encode_C\n                ,\n            \n                    case \n                        when column_to_encode = 'D' then true \n                        else false\n                    end as is_column_to_encode_D\n                \n    from DEMO_DB.DBT_MACRO.data_one_hot_encoder\n    )\n\n    select * from binary_output\n\n)\n\nselect * from data"}, "model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder_category_selected": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.one_hot_encoder( source_table=ref('data_one_hot_encoder'),\r\n                                            source_column='column_to_encode',\r\n                                            categories=['A','B'],\r\n                                            handle_unknown='ignore') }}\r\n\r\n)\r\n\r\nselect * from data", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_one_hot_encoder_category_selected"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder_category_selected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_one_hot_encoder_category_selected.sql", "original_file_path": "models\\sql\\test_one_hot_encoder_category_selected.sql", "name": "test_one_hot_encoder_category_selected", "resource_type": "model", "alias": "test_one_hot_encoder_category_selected", "checksum": {"name": "sha256", "checksum": "55e316186197d52562803fdfc83c733e31f7b5b9019f4dc5a7d84f6d63df1086"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_one_hot_encoder"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing.one_hot_encoder"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\sql\\schema.yml", "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_one_hot_encoder_category_selected.sql", "deferred": false, "compiled_sql": "\n\nwith data as (\n\n    \n    \n\n\n\n\n    with binary_output as (\n    select\n                ID_COL,\n                COLUMN_TO_ENCODE,\n            \n                    case \n                        when column_to_encode = 'A' then true \n                        else false\n                    end as is_column_to_encode_A\n                ,\n            \n                    case \n                        when column_to_encode = 'B' then true \n                        else false\n                    end as is_column_to_encode_B\n                \n    from DEMO_DB.DBT_MACRO.data_one_hot_encoder\n    )\n\n    select * from binary_output\n\n)\n\nselect * from data", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith data as (\n\n    \n    \n\n\n\n\n    with binary_output as (\n    select\n                ID_COL,\n                COLUMN_TO_ENCODE,\n            \n                    case \n                        when column_to_encode = 'A' then true \n                        else false\n                    end as is_column_to_encode_A\n                ,\n            \n                    case \n                        when column_to_encode = 'B' then true \n                        else false\n                    end as is_column_to_encode_B\n                \n    from DEMO_DB.DBT_MACRO.data_one_hot_encoder\n    )\n\n    select * from binary_output\n\n)\n\nselect * from data"}, "model.dbt_ml_preprocessing_integration_tests.test_quantile_transformer": {"raw_sql": "{{ config(materialized='table') }}\r\n\r\n-- test model is generated by adapter-specific macro, \r\n-- because the quantile_transformer is not supported by all DBs\r\n{{ adapter.dispatch('quantile_transformer_model_macro')() }}", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_quantile_transformer"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_quantile_transformer", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_quantile_transformer.sql", "original_file_path": "models\\sql\\test_quantile_transformer.sql", "name": "test_quantile_transformer", "resource_type": "model", "alias": "test_quantile_transformer", "checksum": {"name": "sha256", "checksum": "03df31f979e7cdcc9033a8823434af5faafdb956de3e57ee97b037ad31ea5909"}, "config": {"enabled": true, "materialized": "table", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_quantile_transformer"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing_integration_tests.snowflake__quantile_transformer_model_macro"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_quantile_transformer"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_quantile_transformer.sql", "deferred": false, "compiled_sql": "\n\n-- test model is generated by adapter-specific macro, \n-- because the quantile_transformer is not supported by all DBs\n\nwith data as (\n\n    \nwith quantile_values as(\n  \n    \n    select 0.0 as quantile,percentile_cont(0.0)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.1111111111111111 as quantile,percentile_cont(0.1111111111111111)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.2222222222222222 as quantile,percentile_cont(0.2222222222222222)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.3333333333333333 as quantile,percentile_cont(0.3333333333333333)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.4444444444444444 as quantile,percentile_cont(0.4444444444444444)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.5555555555555556 as quantile,percentile_cont(0.5555555555555556)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.6666666666666666 as quantile,percentile_cont(0.6666666666666666)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.7777777777777778 as quantile,percentile_cont(0.7777777777777778)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.8888888888888888 as quantile,percentile_cont(0.8888888888888888)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 1.0 as quantile,percentile_cont(1.0)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n    \n  \n),\n-- prepare to apply linear interpolation formula\nlinear_interpolation_variables as(\n  select \n    \"ID_COL\", \"COL_TO_TRANSFORM\",\n    col_to_transform as x,\n    (select max(b.quantile) from quantile_values b where b.quantile_value<a.col_to_transform) as y1,\n    (select min(b.quantile) from quantile_values b where b.quantile_value>=a.col_to_transform) as y2,\n    (select max(b.quantile_value) from quantile_values b where b.quantile_value<a.col_to_transform) as x1,\n    (select min(b.quantile_value) from quantile_values b where b.quantile_value>=a.col_to_transform) as x2\n  from DEMO_DB.DBT_MACRO.data_quantile_transformer a\n  where col_to_transform is not null\n  order by col_to_transform\n)\nselect\n\"ID_COL\", \"COL_TO_TRANSFORM\",\ncoalesce(y1 + ((x-x1)/(x2-x1)) * (y2-y1),0) as col_to_transform_transformed\nfrom linear_interpolation_variables\n\n\n\n)\nselect * from data\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n-- test model is generated by adapter-specific macro, \n-- because the quantile_transformer is not supported by all DBs\n\nwith data as (\n\n    \nwith quantile_values as(\n  \n    \n    select 0.0 as quantile,percentile_cont(0.0)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.1111111111111111 as quantile,percentile_cont(0.1111111111111111)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.2222222222222222 as quantile,percentile_cont(0.2222222222222222)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.3333333333333333 as quantile,percentile_cont(0.3333333333333333)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.4444444444444444 as quantile,percentile_cont(0.4444444444444444)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.5555555555555556 as quantile,percentile_cont(0.5555555555555556)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.6666666666666666 as quantile,percentile_cont(0.6666666666666666)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.7777777777777778 as quantile,percentile_cont(0.7777777777777778)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 0.8888888888888888 as quantile,percentile_cont(0.8888888888888888)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n     union all \n  \n    \n    select 1.0 as quantile,percentile_cont(1.0)  within group (order by col_to_transform)as quantile_value from DEMO_DB.DBT_MACRO.data_quantile_transformer\n    \n  \n),\n-- prepare to apply linear interpolation formula\nlinear_interpolation_variables as(\n  select \n    \"ID_COL\", \"COL_TO_TRANSFORM\",\n    col_to_transform as x,\n    (select max(b.quantile) from quantile_values b where b.quantile_value<a.col_to_transform) as y1,\n    (select min(b.quantile) from quantile_values b where b.quantile_value>=a.col_to_transform) as y2,\n    (select max(b.quantile_value) from quantile_values b where b.quantile_value<a.col_to_transform) as x1,\n    (select min(b.quantile_value) from quantile_values b where b.quantile_value>=a.col_to_transform) as x2\n  from DEMO_DB.DBT_MACRO.data_quantile_transformer a\n  where col_to_transform is not null\n  order by col_to_transform\n)\nselect\n\"ID_COL\", \"COL_TO_TRANSFORM\",\ncoalesce(y1 + ((x-x1)/(x2-x1)) * (y2-y1),0) as col_to_transform_transformed\nfrom linear_interpolation_variables\n\n\n\n)\nselect * from data\n"}, "model.dbt_ml_preprocessing_integration_tests.test_robust_scaler": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.robust_scaler( ref('data_robust_scaler') ,['col_to_scale']) }}\r\n\r\n)\r\n\r\nselect * from data", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_robust_scaler"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_robust_scaler", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_robust_scaler.sql", "original_file_path": "models\\sql\\test_robust_scaler.sql", "name": "test_robust_scaler", "resource_type": "model", "alias": "test_robust_scaler", "checksum": {"name": "sha256", "checksum": "5e86b5d74ba7ab0435e2167027febbebbb0938fafd52abef8ab505b4bffda2e3"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_robust_scaler"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing.robust_scaler"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_robust_scaler"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\sql\\schema.yml", "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_robust_scaler.sql", "deferred": false, "compiled_sql": "\n\nwith data as (\n\n    \nwith \n\n    col_to_scale_quartiles as(\n        select\n            percentile_cont(0.25) within group (order by col_to_scale) as first_quartile,\n            percentile_cont(0.75) within group (order by col_to_scale) as third_quartile\n        from DEMO_DB.DBT_MACRO.data_robust_scaler\n    )\n\n\nselect \n\nsource_table.\"ID_COL\",\n\nsource_table.\"COL_TO_SCALE\",\n\n\n    (col_to_scale / (col_to_scale_quartiles.third_quartile - col_to_scale_quartiles.first_quartile)) as col_to_scale_scaled\n    \n\nfrom \n    \n        col_to_scale_quartiles,\n    \n    DEMO_DB.DBT_MACRO.data_robust_scaler as source_table\n\n\n\n\n)\n\nselect * from data", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith data as (\n\n    \nwith \n\n    col_to_scale_quartiles as(\n        select\n            percentile_cont(0.25) within group (order by col_to_scale) as first_quartile,\n            percentile_cont(0.75) within group (order by col_to_scale) as third_quartile\n        from DEMO_DB.DBT_MACRO.data_robust_scaler\n    )\n\n\nselect \n\nsource_table.\"ID_COL\",\n\nsource_table.\"COL_TO_SCALE\",\n\n\n    (col_to_scale / (col_to_scale_quartiles.third_quartile - col_to_scale_quartiles.first_quartile)) as col_to_scale_scaled\n    \n\nfrom \n    \n        col_to_scale_quartiles,\n    \n    DEMO_DB.DBT_MACRO.data_robust_scaler as source_table\n\n\n\n\n)\n\nselect * from data"}, "model.dbt_ml_preprocessing_integration_tests.test_standard_scaler": {"raw_sql": "{{ config(materialized='view') }}\r\n\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.standard_scaler( ref('data_standard_scaler') ,['col_to_scale_1','col_to_scale_2']) }}\r\n\r\n)\r\n\r\nselect id_col,\r\n        col_to_scale_1,\r\n        col_to_scale_2,\r\n        round(col_to_scale_1_scaled,10) as col_to_scale_1_scaled,\r\n        round(col_to_scale_2_scaled,10) as col_to_scale_2_scaled \r\nfrom data", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "test_standard_scaler"], "unique_id": "model.dbt_ml_preprocessing_integration_tests.test_standard_scaler", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\test_standard_scaler.sql", "original_file_path": "models\\sql\\test_standard_scaler.sql", "name": "test_standard_scaler", "resource_type": "model", "alias": "test_standard_scaler", "checksum": {"name": "sha256", "checksum": "cf2dc52382b75eb9e89bd83058d94b69be69bb06fd45d07029ab7ce158697c76"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null}, "tags": [], "refs": [["data_standard_scaler"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing.standard_scaler"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": "models\\sql\\schema.yml", "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\test_standard_scaler.sql", "deferred": false, "compiled_sql": "\n\nwith data as (\n\n    -- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_scale_1_aggregates as(\n        select\n            avg(col_to_scale_1) as avg_value,\n            stddev_pop(col_to_scale_1) as stddev_value\n        from DEMO_DB.DBT_MACRO.data_standard_scaler\n    )\n, \n\n    col_to_scale_2_aggregates as(\n        select\n            avg(col_to_scale_2) as avg_value,\n            stddev_pop(col_to_scale_2) as stddev_value\n        from DEMO_DB.DBT_MACRO.data_standard_scaler\n    )\n\n\n\nselect \n    \n        source_table.\"ID_COL\",\n    \n        source_table.\"COL_TO_SCALE_1\",\n    \n        source_table.\"COL_TO_SCALE_2\",\n    \n    \n        (col_to_scale_1 - col_to_scale_1_aggregates.avg_value) / col_to_scale_1_aggregates.stddev_value as col_to_scale_1_scaled\n        , \n    \n        (col_to_scale_2 - col_to_scale_2_aggregates.avg_value) / col_to_scale_2_aggregates.stddev_value as col_to_scale_2_scaled\n        \n    \nfrom \n    \n        col_to_scale_1_aggregates,\n    \n        col_to_scale_2_aggregates,\n    \n    DEMO_DB.DBT_MACRO.data_standard_scaler as source_table\n\n\n)\n\nselect id_col,\n        col_to_scale_1,\n        col_to_scale_2,\n        round(col_to_scale_1_scaled,10) as col_to_scale_1_scaled,\n        round(col_to_scale_2_scaled,10) as col_to_scale_2_scaled \nfrom data", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith data as (\n\n    -- generate a CTE for each source column, a single row containing the aggregates\nwith \n\n    col_to_scale_1_aggregates as(\n        select\n            avg(col_to_scale_1) as avg_value,\n            stddev_pop(col_to_scale_1) as stddev_value\n        from DEMO_DB.DBT_MACRO.data_standard_scaler\n    )\n, \n\n    col_to_scale_2_aggregates as(\n        select\n            avg(col_to_scale_2) as avg_value,\n            stddev_pop(col_to_scale_2) as stddev_value\n        from DEMO_DB.DBT_MACRO.data_standard_scaler\n    )\n\n\n\nselect \n    \n        source_table.\"ID_COL\",\n    \n        source_table.\"COL_TO_SCALE_1\",\n    \n        source_table.\"COL_TO_SCALE_2\",\n    \n    \n        (col_to_scale_1 - col_to_scale_1_aggregates.avg_value) / col_to_scale_1_aggregates.stddev_value as col_to_scale_1_scaled\n        , \n    \n        (col_to_scale_2 - col_to_scale_2_aggregates.avg_value) / col_to_scale_2_aggregates.stddev_value as col_to_scale_2_scaled\n        \n    \nfrom \n    \n        col_to_scale_1_aggregates,\n    \n        col_to_scale_2_aggregates,\n    \n    DEMO_DB.DBT_MACRO.data_standard_scaler as source_table\n\n\n)\n\nselect id_col,\n        col_to_scale_1,\n        col_to_scale_2,\n        round(col_to_scale_1_scaled,10) as col_to_scale_1_scaled,\n        round(col_to_scale_2_scaled,10) as col_to_scale_2_scaled \nfrom data"}, "test.dbt_ml_preprocessing_integration_tests.test_quantile_transformer_result_with_tolerance": {"raw_sql": "{{ adapter.dispatch('test_quantile_transformer_result_with_tolerance')() }}", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "data_test", "test_quantile_transformer_result_with_tolerance"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.test_quantile_transformer_result_with_tolerance", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "data_test\\test_quantile_transformer_result_with_tolerance.sql", "original_file_path": "tests\\test_quantile_transformer_result_with_tolerance.sql", "name": "test_quantile_transformer_result_with_tolerance", "resource_type": "test", "alias": "test_quantile_transformer_result_with_tolerance", "checksum": {"name": "sha256", "checksum": "44f61c0e23d9a9e48a292199333048817bb3bdb34e3730103ae9b96419f1dfae"}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["data"], "refs": [], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing_integration_tests.snowflake__test_quantile_transformer_result_with_tolerance"], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\tests\\test_quantile_transformer_result_with_tolerance.sql", "deferred": false, "compiled_sql": "\nselect count(*) from dbt__CTE__INTERNAL_test", "extra_ctes_injected": true, "extra_ctes": [{"id": "dbt__CTE__INTERNAL_test", "sql": " dbt__CTE__INTERNAL_test as (\n\n\n\n\nwith a as (\n    select * from test_quantile_transformer\n),\nb as (\n    select * from data_quantile_transformer_expected\n),\njoined as(\n    select round(a.col_to_transform_transformed,6) as actual,\n        round(b.col_to_transform_transformed,6) as expected,\n        abs(actual-expected) as difference,\n        iff(difference>0,difference/b.col_to_transform_transformed,0)*100 as percent_difference\n  from a\n  join b on a.id_col=b.id_col\n  )\nselect \n        *\n       \nfrom joined\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \n-- the values do not end up exactly the same as those output from python\nwhere percent_difference > 0.005\n\n\n)"}], "injected_sql": "\nwith dbt__CTE__INTERNAL_test as (\n\n\n\n\nwith a as (\n    select * from test_quantile_transformer\n),\nb as (\n    select * from data_quantile_transformer_expected\n),\njoined as(\n    select round(a.col_to_transform_transformed,6) as actual,\n        round(b.col_to_transform_transformed,6) as expected,\n        abs(actual-expected) as difference,\n        iff(difference>0,difference/b.col_to_transform_transformed,0)*100 as percent_difference\n  from a\n  join b on a.id_col=b.id_col\n  )\nselect \n        *\n       \nfrom joined\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \n-- the values do not end up exactly the same as those output from python\nwhere percent_difference > 0.005\n\n\n)select count(*) from dbt__CTE__INTERNAL_test"}, "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_k_bins_discretizer"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_k_bins_discretizer.csv", "original_file_path": "data\\sql\\data_k_bins_discretizer.csv", "name": "data_k_bins_discretizer", "resource_type": "seed", "alias": "data_k_bins_discretizer", "checksum": {"name": "sha256", "checksum": "408716f278470c9842f5db51c55d2851632eaabbc02c9e1705272f946af74d47"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer_50_bins_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_k_bins_discretizer_50_bins_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer_50_bins_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_k_bins_discretizer_50_bins_expected.csv", "original_file_path": "data\\sql\\data_k_bins_discretizer_50_bins_expected.csv", "name": "data_k_bins_discretizer_50_bins_expected", "resource_type": "seed", "alias": "data_k_bins_discretizer_50_bins_expected", "checksum": {"name": "sha256", "checksum": "2195536b02b997ba5edd6c926cd484b6e9247482faa39d24ad4020fab69dbc6c"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"col_to_bin_1_binned": "DECIMAL(38,6)"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer_default_bins_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_k_bins_discretizer_default_bins_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer_default_bins_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_k_bins_discretizer_default_bins_expected.csv", "original_file_path": "data\\sql\\data_k_bins_discretizer_default_bins_expected.csv", "name": "data_k_bins_discretizer_default_bins_expected", "resource_type": "seed", "alias": "data_k_bins_discretizer_default_bins_expected", "checksum": {"name": "sha256", "checksum": "6d2587e0db4463b5bf18a2a8796bea667ac04ff07a68a1293849ea225e68bd12"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"col_to_bin_1_binned": "DECIMAL(38,6)", "col_to_bin_2_binned": "DECIMAL(38,6)"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_label_encoder": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_label_encoder"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_label_encoder", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_label_encoder.csv", "original_file_path": "data\\sql\\data_label_encoder.csv", "name": "data_label_encoder", "resource_type": "seed", "alias": "data_label_encoder", "checksum": {"name": "sha256", "checksum": "714446c614594a86103a2ead8ef7243ed6d389f6e629e79bc882f17ec961ccfb"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_label_encoder_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_label_encoder_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_label_encoder_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_label_encoder_expected.csv", "original_file_path": "data\\sql\\data_label_encoder_expected.csv", "name": "data_label_encoder_expected", "resource_type": "seed", "alias": "data_label_encoder_expected", "checksum": {"name": "sha256", "checksum": "dca696a2d460c7a7a1483a22e0ff5eaf7c7e001839dedcbade6fc7e32428e04b"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_max_abs_scaler"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_max_abs_scaler.csv", "original_file_path": "data\\sql\\data_max_abs_scaler.csv", "name": "data_max_abs_scaler", "resource_type": "seed", "alias": "data_max_abs_scaler", "checksum": {"name": "sha256", "checksum": "7d6160e955f44ae0cd0c891a67852fe8757c8fb72ad5cf915fb71acf73d59539"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"col_to_scale": "DECIMAL(38,6)"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_max_abs_scaler_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_max_abs_scaler_expected.csv", "original_file_path": "data\\sql\\data_max_abs_scaler_expected.csv", "name": "data_max_abs_scaler_expected", "resource_type": "seed", "alias": "data_max_abs_scaler_expected", "checksum": {"name": "sha256", "checksum": "b6ba0b51d6d4dada172c57f7ea682810600f016ddd9de9741c0cb913e1ecbf78"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"col_to_scale_scaled": "DECIMAL(38,6)"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler_with_column_selection_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_max_abs_scaler_with_column_selection_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler_with_column_selection_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_max_abs_scaler_with_column_selection_expected.csv", "original_file_path": "data\\sql\\data_max_abs_scaler_with_column_selection_expected.csv", "name": "data_max_abs_scaler_with_column_selection_expected", "resource_type": "seed", "alias": "data_max_abs_scaler_with_column_selection_expected", "checksum": {"name": "sha256", "checksum": "9a7a2c45d4ba14be53e95d9df4c5493e0c3d87c9d61ada619d219351a2ba6c4c"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"col_to_scale_scaled": "DECIMAL(38,6)"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_min_max_scaler"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_min_max_scaler.csv", "original_file_path": "data\\sql\\data_min_max_scaler.csv", "name": "data_min_max_scaler", "resource_type": "seed", "alias": "data_min_max_scaler", "checksum": {"name": "sha256", "checksum": "7d6160e955f44ae0cd0c891a67852fe8757c8fb72ad5cf915fb71acf73d59539"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"col_to_scale": "DECIMAL(38,6)"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_min_max_scaler_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_min_max_scaler_expected.csv", "original_file_path": "data\\sql\\data_min_max_scaler_expected.csv", "name": "data_min_max_scaler_expected", "resource_type": "seed", "alias": "data_min_max_scaler_expected", "checksum": {"name": "sha256", "checksum": "b10fef66bf5e3b219f150d8634dfc9e87e59e71ac925f23219b542fc9fde46df"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"col_to_scale_scaled": "DECIMAL(38,6)"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler_with_column_selection_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_min_max_scaler_with_column_selection_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler_with_column_selection_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_min_max_scaler_with_column_selection_expected.csv", "original_file_path": "data\\sql\\data_min_max_scaler_with_column_selection_expected.csv", "name": "data_min_max_scaler_with_column_selection_expected", "resource_type": "seed", "alias": "data_min_max_scaler_with_column_selection_expected", "checksum": {"name": "sha256", "checksum": "c510b41da8af10f211668ac00b4dbbd1ff8843664956fffc2178143b22c440df"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"col_to_scale_scaled": "DECIMAL(38,6)"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_normalizer": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_normalizer"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_normalizer", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_normalizer.csv", "original_file_path": "data\\sql\\data_normalizer.csv", "name": "data_normalizer", "resource_type": "seed", "alias": "data_normalizer", "checksum": {"name": "sha256", "checksum": "79603fc9ba213b8bb7b3609a2c62c441d9ff53b046f0a52641de5d2d60246479"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_normalizer_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_normalizer_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_normalizer_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_normalizer_expected.csv", "original_file_path": "data\\sql\\data_normalizer_expected.csv", "name": "data_normalizer_expected", "resource_type": "seed", "alias": "data_normalizer_expected", "checksum": {"name": "sha256", "checksum": "77d7aed4489648c937dd306d05d24619158341ead39038183b2b1926280a7b40"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_one_hot_encoder"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_one_hot_encoder.csv", "original_file_path": "data\\sql\\data_one_hot_encoder.csv", "name": "data_one_hot_encoder", "resource_type": "seed", "alias": "data_one_hot_encoder", "checksum": {"name": "sha256", "checksum": "9f15d85dc6fb66729812e09a89ef7f309e7dec1fd69b54d4c123e60d95d37743"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder_category_selected_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_one_hot_encoder_category_selected_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder_category_selected_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_one_hot_encoder_category_selected_expected.csv", "original_file_path": "data\\sql\\data_one_hot_encoder_category_selected_expected.csv", "name": "data_one_hot_encoder_category_selected_expected", "resource_type": "seed", "alias": "data_one_hot_encoder_category_selected_expected", "checksum": {"name": "sha256", "checksum": "dee1a695a7e12728886fd8550264b97d239c0faee0860871fcf09b29bf94c6af"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"is_column_to_encode_A": "boolean", "is_column_to_encode_B": "boolean"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_one_hot_encoder_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_one_hot_encoder_expected.csv", "original_file_path": "data\\sql\\data_one_hot_encoder_expected.csv", "name": "data_one_hot_encoder_expected", "resource_type": "seed", "alias": "data_one_hot_encoder_expected", "checksum": {"name": "sha256", "checksum": "cf42807b785ef4feaf53739bc479f61e4c0d1063fa339a496d8af432c1a39147"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"is_column_to_encode_A": "boolean", "is_column_to_encode_B": "boolean", "is_column_to_encode_C": "boolean", "is_column_to_encode_D": "boolean"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_quantile_transformer": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_quantile_transformer"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_quantile_transformer", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_quantile_transformer.csv", "original_file_path": "data\\sql\\data_quantile_transformer.csv", "name": "data_quantile_transformer", "resource_type": "seed", "alias": "data_quantile_transformer", "checksum": {"name": "sha256", "checksum": "171a3e2b325abb088f3bc2c55f3c36010a1d0abadd89e870d6337435c40a482e"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"col_to_transform": "DECIMAL(38,6)"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_quantile_transformer_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_quantile_transformer_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_quantile_transformer_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_quantile_transformer_expected.csv", "original_file_path": "data\\sql\\data_quantile_transformer_expected.csv", "name": "data_quantile_transformer_expected", "resource_type": "seed", "alias": "data_quantile_transformer_expected", "checksum": {"name": "sha256", "checksum": "2881e3a1debdd2eeccad9a2b503cc4c0f6981681786afa2ac2d87cfe77a4eb98"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"col_to_transform_transformed": "DECIMAL(38,6)"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_robust_scaler": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_robust_scaler"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_robust_scaler", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_robust_scaler.csv", "original_file_path": "data\\sql\\data_robust_scaler.csv", "name": "data_robust_scaler", "resource_type": "seed", "alias": "data_robust_scaler", "checksum": {"name": "sha256", "checksum": "7d6160e955f44ae0cd0c891a67852fe8757c8fb72ad5cf915fb71acf73d59539"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_robust_scaler_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_robust_scaler_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_robust_scaler_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_robust_scaler_expected.csv", "original_file_path": "data\\sql\\data_robust_scaler_expected.csv", "name": "data_robust_scaler_expected", "resource_type": "seed", "alias": "data_robust_scaler_expected", "checksum": {"name": "sha256", "checksum": "9768158aeac366bc5194ead4c12af61315c821396ee69a866b686f789fac75e1"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_standard_scaler"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_standard_scaler.csv", "original_file_path": "data\\sql\\data_standard_scaler.csv", "name": "data_standard_scaler", "resource_type": "seed", "alias": "data_standard_scaler", "checksum": {"name": "sha256", "checksum": "4197607e52912a5c28c293fb52a4386913ca2f3c96d231b8cae3f9a9ad1f7bab"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"col_to_scale_1": "DECIMAL(38,10)", "col_to_scale_2": "DECIMAL(38,10)"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler_expected": {"raw_sql": "", "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "sql", "data_standard_scaler_expected"], "unique_id": "seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler_expected", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "sql\\data_standard_scaler_expected.csv", "original_file_path": "data\\sql\\data_standard_scaler_expected.csv", "name": "data_standard_scaler_expected", "resource_type": "seed", "alias": "data_standard_scaler_expected", "checksum": {"name": "sha256", "checksum": "9834571fd075090099cc42584a7498d6ef7b467ed32b1a09fb5de60806762031"}, "config": {"enabled": true, "materialized": "seed", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {"col_to_scale_1_scaled": "DECIMAL(38,10)", "col_to_scale_2_scaled": "DECIMAL(38,10)"}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "quote_columns": false}, "tags": [], "refs": [], "sources": [], "depends_on": {"macros": [], "nodes": []}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": null, "deferred": false, "compiled_sql": "", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": ""}, "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_max_abs_scaler_ref_data_max_abs_scaler_expected_": {"raw_sql": "{{ config(severity='ERROR') }}{{ dbt_utils.test_equality(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": "dbt_utils", "name": "equality", "kwargs": {"compare_model": "ref('data_max_abs_scaler_expected')", "model": "{{ ref('test_max_abs_scaler') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "dbt_utils_equality_test_max_abs_scaler_ref_data_max_abs_scaler_expected_"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_max_abs_scaler_ref_data_max_abs_scaler_expected_", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\dbt_utils_equality_test_max_abs_scaler_b407bf7ecaaa8ca6381fdfdbe9e5be7e.sql", "original_file_path": "models\\sql\\schema.yml", "name": "dbt_utils_equality_test_max_abs_scaler_ref_data_max_abs_scaler_expected_", "resource_type": "test", "alias": "dbt_utils_equality_test_max_abs_scaler_ref_data_max_abs_scaler_expected_", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_max_abs_scaler_expected"], ["test_max_abs_scaler"]], "sources": [], "depends_on": {"macros": ["macro.dbt_utils.test_equality"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler_expected", "model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\dbt_utils_equality_test_max_abs_scaler_b407bf7ecaaa8ca6381fdfdbe9e5be7e.sql", "deferred": false, "compiled_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_max_abs_scaler\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_max_abs_scaler_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_max_abs_scaler\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_max_abs_scaler_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "column_name": null}, "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_max_abs_scaler_with_column_selection_ref_data_max_abs_scaler_with_column_selection_expected_": {"raw_sql": "{{ config(severity='ERROR') }}{{ dbt_utils.test_equality(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": "dbt_utils", "name": "equality", "kwargs": {"compare_model": "ref('data_max_abs_scaler_with_column_selection_expected')", "model": "{{ ref('test_max_abs_scaler_with_column_selection') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "dbt_utils_equality_test_max_abs_scaler_with_column_selection_ref_data_max_abs_scaler_with_column_selection_expected_"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_max_abs_scaler_with_column_selection_ref_data_max_abs_scaler_with_column_selection_expected_", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\dbt_utils_equality_test_max_abs_scaler_with_column_selection_252460a249c7f8146fe4ee22d639a655.sql", "original_file_path": "models\\sql\\schema.yml", "name": "dbt_utils_equality_test_max_abs_scaler_with_column_selection_ref_data_max_abs_scaler_with_column_selection_expected_", "resource_type": "test", "alias": "dbt_utils_equality_test_max_abs_scaler_with_column_selection_ref_data_max_abs_scaler_with_column_selection_expected_", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_max_abs_scaler_with_column_selection_expected"], ["test_max_abs_scaler_with_column_selection"]], "sources": [], "depends_on": {"macros": ["macro.dbt_utils.test_equality"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler_with_column_selection_expected", "model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler_with_column_selection"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\dbt_utils_equality_test_max_abs_scaler_with_column_selection_252460a249c7f8146fe4ee22d639a655.sql", "deferred": false, "compiled_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_max_abs_scaler_with_column_selection\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_max_abs_scaler_with_column_selection_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COL_TO_SCALE_SCALED\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_SCALE_SCALED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COL_TO_SCALE_SCALED\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_SCALE_SCALED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_max_abs_scaler_with_column_selection\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_max_abs_scaler_with_column_selection_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COL_TO_SCALE_SCALED\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_SCALE_SCALED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COL_TO_SCALE_SCALED\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_SCALE_SCALED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "column_name": null}, "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_min_max_scaler_ref_data_min_max_scaler_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_equality_with_numeric_tolerance(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": null, "name": "equality_with_numeric_tolerance", "kwargs": {"compare_model": "ref('data_min_max_scaler_expected')", "source_join_column": "id_col", "target_join_column": "id_col", "source_numeric_column_name": "col_to_scale_scaled", "target_numeric_column_name": "col_to_scale_scaled", "percentage_tolerance": 1e-08, "model": "{{ ref('test_min_max_scaler') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "equality_with_numeric_tolerance_test_min_max_scaler_ref_data_min_max_scaler_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_min_max_scaler_ref_data_min_max_scaler_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\equality_with_numeric_tolerance_test_min_max_scaler_ed09efccac06137b3f16ef9e5d69acf5.sql", "original_file_path": "models\\sql\\schema.yml", "name": "equality_with_numeric_tolerance_test_min_max_scaler_ref_data_min_max_scaler_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled", "resource_type": "test", "alias": "equality_with_numeric_tolerance_test_min_max_scaler_ref_data_min_max_scaler_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_min_max_scaler_expected"], ["test_min_max_scaler"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing_integration_tests.test_equality_with_numeric_tolerance"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler_expected", "model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\equality_with_numeric_tolerance_test_min_max_scaler_ed09efccac06137b3f16ef9e5d69acf5.sql", "deferred": false, "compiled_sql": "\n\nwith a as (\n    select * from DEMO_DB.DBT_MACRO.test_min_max_scaler\n),\nb as (\n    select * from DEMO_DB.DBT_MACRO.data_min_max_scaler_expected\n),\njoined as(\n    select round(a.col_to_scale_scaled,6) as actual,\n        round(b.col_to_scale_scaled,6) as expected,\n        abs(actual-expected) as difference,\n        iff(difference>0,difference/b.col_to_scale_scaled,0)*100 as percent_difference\n  from a\n  join b on a.id_col=b.id_col\n  )\nselect \n       count(*) \n       \nfrom joined\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \n-- the values do not end up exactly the same as those output from python\nwhere percent_difference > 1e-08\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith a as (\n    select * from DEMO_DB.DBT_MACRO.test_min_max_scaler\n),\nb as (\n    select * from DEMO_DB.DBT_MACRO.data_min_max_scaler_expected\n),\njoined as(\n    select round(a.col_to_scale_scaled,6) as actual,\n        round(b.col_to_scale_scaled,6) as expected,\n        abs(actual-expected) as difference,\n        iff(difference>0,difference/b.col_to_scale_scaled,0)*100 as percent_difference\n  from a\n  join b on a.id_col=b.id_col\n  )\nselect \n       count(*) \n       \nfrom joined\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \n-- the values do not end up exactly the same as those output from python\nwhere percent_difference > 1e-08\n", "column_name": null}, "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_min_max_scaler_with_column_selection_ref_data_min_max_scaler_with_column_selection_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_equality_with_numeric_tolerance(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": null, "name": "equality_with_numeric_tolerance", "kwargs": {"compare_model": "ref('data_min_max_scaler_with_column_selection_expected')", "source_join_column": "id_col", "target_join_column": "id_col", "source_numeric_column_name": "col_to_scale_scaled", "target_numeric_column_name": "col_to_scale_scaled", "percentage_tolerance": 1e-08, "model": "{{ ref('test_min_max_scaler_with_column_selection') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "equality_with_numeric_tolerance_test_min_max_scaler_with_column_selection_ref_data_min_max_scaler_with_column_selection_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_min_max_scaler_with_column_selection_ref_data_min_max_scaler_with_column_selection_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\equality_with_numeric_tolerance_test_min_max_scaler_with_column_selection_bd5c0288e77be49e09e9f6b2e67ec6b7.sql", "original_file_path": "models\\sql\\schema.yml", "name": "equality_with_numeric_tolerance_test_min_max_scaler_with_column_selection_ref_data_min_max_scaler_with_column_selection_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled", "resource_type": "test", "alias": "equality_with_numeric_tolerance_test_min_max_scaler_with_column_selection_ref_data_min_max_scaler_with_column_selection_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_min_max_scaler_with_column_selection_expected"], ["test_min_max_scaler_with_column_selection"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing_integration_tests.test_equality_with_numeric_tolerance"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler_with_column_selection_expected", "model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler_with_column_selection"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\equality_with_numeric_tolerance_test_min_max_scaler_with_column_selection_bd5c0288e77be49e09e9f6b2e67ec6b7.sql", "deferred": false, "compiled_sql": "\n\nwith a as (\n    select * from DEMO_DB.DBT_MACRO.test_min_max_scaler_with_column_selection\n),\nb as (\n    select * from DEMO_DB.DBT_MACRO.data_min_max_scaler_with_column_selection_expected\n),\njoined as(\n    select round(a.col_to_scale_scaled,6) as actual,\n        round(b.col_to_scale_scaled,6) as expected,\n        abs(actual-expected) as difference,\n        iff(difference>0,difference/b.col_to_scale_scaled,0)*100 as percent_difference\n  from a\n  join b on a.id_col=b.id_col\n  )\nselect \n       count(*) \n       \nfrom joined\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \n-- the values do not end up exactly the same as those output from python\nwhere percent_difference > 1e-08\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith a as (\n    select * from DEMO_DB.DBT_MACRO.test_min_max_scaler_with_column_selection\n),\nb as (\n    select * from DEMO_DB.DBT_MACRO.data_min_max_scaler_with_column_selection_expected\n),\njoined as(\n    select round(a.col_to_scale_scaled,6) as actual,\n        round(b.col_to_scale_scaled,6) as expected,\n        abs(actual-expected) as difference,\n        iff(difference>0,difference/b.col_to_scale_scaled,0)*100 as percent_difference\n  from a\n  join b on a.id_col=b.id_col\n  )\nselect \n       count(*) \n       \nfrom joined\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \n-- the values do not end up exactly the same as those output from python\nwhere percent_difference > 1e-08\n", "column_name": null}, "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_k_bins_discretizer_default_bins_ref_data_k_bins_discretizer_default_bins_expected_": {"raw_sql": "{{ config(severity='ERROR') }}{{ dbt_utils.test_equality(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": "dbt_utils", "name": "equality", "kwargs": {"compare_model": "ref('data_k_bins_discretizer_default_bins_expected')", "model": "{{ ref('test_k_bins_discretizer_default_bins') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "dbt_utils_equality_test_k_bins_discretizer_default_bins_ref_data_k_bins_discretizer_default_bins_expected_"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_k_bins_discretizer_default_bins_ref_data_k_bins_discretizer_default_bins_expected_", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\dbt_utils_equality_test_k_bins_discretizer_default_bins_3d76688fc2d41e39e5d2e2a8056b8f61.sql", "original_file_path": "models\\sql\\schema.yml", "name": "dbt_utils_equality_test_k_bins_discretizer_default_bins_ref_data_k_bins_discretizer_default_bins_expected_", "resource_type": "test", "alias": "dbt_utils_equality_test_k_bins_discretizer_default_bins_ref_data_k_bins_discretizer_default_bins_expected_", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_k_bins_discretizer_default_bins_expected"], ["test_k_bins_discretizer_default_bins"]], "sources": [], "depends_on": {"macros": ["macro.dbt_utils.test_equality"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer_default_bins_expected", "model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_default_bins"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\dbt_utils_equality_test_k_bins_discretizer_default_bins_3d76688fc2d41e39e5d2e2a8056b8f61.sql", "deferred": false, "compiled_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_k_bins_discretizer_default_bins\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_k_bins_discretizer_default_bins_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\", \"COL_TO_BIN_2_BINNED\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\", \"COL_TO_BIN_2_BINNED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\", \"COL_TO_BIN_2_BINNED\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\", \"COL_TO_BIN_2_BINNED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_k_bins_discretizer_default_bins\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_k_bins_discretizer_default_bins_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\", \"COL_TO_BIN_2_BINNED\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\", \"COL_TO_BIN_2_BINNED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\", \"COL_TO_BIN_2_BINNED\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\", \"COL_TO_BIN_2_BINNED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "column_name": null}, "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_k_bins_discretizer_50_bins_ref_data_k_bins_discretizer_50_bins_expected_": {"raw_sql": "{{ config(severity='ERROR') }}{{ dbt_utils.test_equality(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": "dbt_utils", "name": "equality", "kwargs": {"compare_model": "ref('data_k_bins_discretizer_50_bins_expected')", "model": "{{ ref('test_k_bins_discretizer_50_bins') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "dbt_utils_equality_test_k_bins_discretizer_50_bins_ref_data_k_bins_discretizer_50_bins_expected_"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_k_bins_discretizer_50_bins_ref_data_k_bins_discretizer_50_bins_expected_", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\dbt_utils_equality_test_k_bins_discretizer_50_bins_e0df257adfdbcb8055d03e33ba889e4b.sql", "original_file_path": "models\\sql\\schema.yml", "name": "dbt_utils_equality_test_k_bins_discretizer_50_bins_ref_data_k_bins_discretizer_50_bins_expected_", "resource_type": "test", "alias": "dbt_utils_equality_test_k_bins_discretizer_50_bins_ref_data_k_bins_discretizer_50_bins_expected_", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_k_bins_discretizer_50_bins_expected"], ["test_k_bins_discretizer_50_bins"]], "sources": [], "depends_on": {"macros": ["macro.dbt_utils.test_equality"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer_50_bins_expected", "model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_50_bins"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\dbt_utils_equality_test_k_bins_discretizer_50_bins_e0df257adfdbcb8055d03e33ba889e4b.sql", "deferred": false, "compiled_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_k_bins_discretizer_50_bins\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_k_bins_discretizer_50_bins_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_k_bins_discretizer_50_bins\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_k_bins_discretizer_50_bins_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_BIN_1\", \"COL_TO_BIN_2\", \"COL_TO_BIN_1_BINNED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "column_name": null}, "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_label_encoder_ref_data_label_encoder_expected_": {"raw_sql": "{{ config(severity='ERROR') }}{{ dbt_utils.test_equality(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": "dbt_utils", "name": "equality", "kwargs": {"compare_model": "ref('data_label_encoder_expected')", "model": "{{ ref('test_label_encoder') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "dbt_utils_equality_test_label_encoder_ref_data_label_encoder_expected_"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_label_encoder_ref_data_label_encoder_expected_", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\dbt_utils_equality_test_label_encoder_ref_data_label_encoder_expected_.sql", "original_file_path": "models\\sql\\schema.yml", "name": "dbt_utils_equality_test_label_encoder_ref_data_label_encoder_expected_", "resource_type": "test", "alias": "dbt_utils_equality_test_label_encoder_ref_data_label_encoder_expected_", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_label_encoder_expected"], ["test_label_encoder"]], "sources": [], "depends_on": {"macros": ["macro.dbt_utils.test_equality"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_label_encoder_expected", "model.dbt_ml_preprocessing_integration_tests.test_label_encoder"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\dbt_utils_equality_test_label_encoder_ref_data_label_encoder_expected_.sql", "deferred": false, "compiled_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_label_encoder\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_label_encoder_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COL_TO_LABEL_ENCODE\", \"COL_TO_LABEL_ENCODE_ENCODED\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_LABEL_ENCODE\", \"COL_TO_LABEL_ENCODE_ENCODED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COL_TO_LABEL_ENCODE\", \"COL_TO_LABEL_ENCODE_ENCODED\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_LABEL_ENCODE\", \"COL_TO_LABEL_ENCODE_ENCODED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_label_encoder\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_label_encoder_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COL_TO_LABEL_ENCODE\", \"COL_TO_LABEL_ENCODE_ENCODED\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_LABEL_ENCODE\", \"COL_TO_LABEL_ENCODE_ENCODED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COL_TO_LABEL_ENCODE\", \"COL_TO_LABEL_ENCODE_ENCODED\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_LABEL_ENCODE\", \"COL_TO_LABEL_ENCODE_ENCODED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "column_name": null}, "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_normalizer_ref_data_normalizer_expected_": {"raw_sql": "{{ config(severity='ERROR') }}{{ dbt_utils.test_equality(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": "dbt_utils", "name": "equality", "kwargs": {"compare_model": "ref('data_normalizer_expected')", "model": "{{ ref('test_normalizer') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "dbt_utils_equality_test_normalizer_ref_data_normalizer_expected_"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_normalizer_ref_data_normalizer_expected_", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\dbt_utils_equality_test_normalizer_ref_data_normalizer_expected_.sql", "original_file_path": "models\\sql\\schema.yml", "name": "dbt_utils_equality_test_normalizer_ref_data_normalizer_expected_", "resource_type": "test", "alias": "dbt_utils_equality_test_normalizer_ref_data_normalizer_expected_", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_normalizer_expected"], ["test_normalizer"]], "sources": [], "depends_on": {"macros": ["macro.dbt_utils.test_equality"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_normalizer_expected", "model.dbt_ml_preprocessing_integration_tests.test_normalizer"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\dbt_utils_equality_test_normalizer_ref_data_normalizer_expected_.sql", "deferred": false, "compiled_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_normalizer\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_normalizer_expected\n\n),\n\na_minus_b as (\n\n    select \"COL1_NORMALIZED\", \"COL2_NORMALIZED\", \"COL3_NORMALIZED\", \"COL4_NORMALIZED\" from a\n    \n  \n\n    except\n\n\n\n    select \"COL1_NORMALIZED\", \"COL2_NORMALIZED\", \"COL3_NORMALIZED\", \"COL4_NORMALIZED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"COL1_NORMALIZED\", \"COL2_NORMALIZED\", \"COL3_NORMALIZED\", \"COL4_NORMALIZED\" from b\n    \n  \n\n    except\n\n\n\n    select \"COL1_NORMALIZED\", \"COL2_NORMALIZED\", \"COL3_NORMALIZED\", \"COL4_NORMALIZED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_normalizer\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_normalizer_expected\n\n),\n\na_minus_b as (\n\n    select \"COL1_NORMALIZED\", \"COL2_NORMALIZED\", \"COL3_NORMALIZED\", \"COL4_NORMALIZED\" from a\n    \n  \n\n    except\n\n\n\n    select \"COL1_NORMALIZED\", \"COL2_NORMALIZED\", \"COL3_NORMALIZED\", \"COL4_NORMALIZED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"COL1_NORMALIZED\", \"COL2_NORMALIZED\", \"COL3_NORMALIZED\", \"COL4_NORMALIZED\" from b\n    \n  \n\n    except\n\n\n\n    select \"COL1_NORMALIZED\", \"COL2_NORMALIZED\", \"COL3_NORMALIZED\", \"COL4_NORMALIZED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "column_name": null}, "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_1_scaled__id_col__col_to_scale_1_scaled": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_equality_with_numeric_tolerance(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": null, "name": "equality_with_numeric_tolerance", "kwargs": {"compare_model": "ref('data_standard_scaler_expected')", "source_join_column": "id_col", "target_join_column": "id_col", "source_numeric_column_name": "col_to_scale_1_scaled", "target_numeric_column_name": "col_to_scale_1_scaled", "percentage_tolerance": 1e-07, "model": "{{ ref('test_standard_scaler') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_1_scaled__id_col__col_to_scale_1_scaled"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_1_scaled__id_col__col_to_scale_1_scaled", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\equality_with_numeric_tolerance_test_standard_scaler_c53fa90e2ca67500a6fbe4a5472766fa.sql", "original_file_path": "models\\sql\\schema.yml", "name": "equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_1_scaled__id_col__col_to_scale_1_scaled", "resource_type": "test", "alias": "equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_1_scaled__id_col__col_to_scale_1_scaled", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_standard_scaler_expected"], ["test_standard_scaler"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing_integration_tests.test_equality_with_numeric_tolerance"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler_expected", "model.dbt_ml_preprocessing_integration_tests.test_standard_scaler"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\equality_with_numeric_tolerance_test_standard_scaler_c53fa90e2ca67500a6fbe4a5472766fa.sql", "deferred": false, "compiled_sql": "\n\nwith a as (\n    select * from DEMO_DB.DBT_MACRO.test_standard_scaler\n),\nb as (\n    select * from DEMO_DB.DBT_MACRO.data_standard_scaler_expected\n),\njoined as(\n    select round(a.col_to_scale_1_scaled,6) as actual,\n        round(b.col_to_scale_1_scaled,6) as expected,\n        abs(actual-expected) as difference,\n        iff(difference>0,difference/b.col_to_scale_1_scaled,0)*100 as percent_difference\n  from a\n  join b on a.id_col=b.id_col\n  )\nselect \n       count(*) \n       \nfrom joined\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \n-- the values do not end up exactly the same as those output from python\nwhere percent_difference > 1e-07\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith a as (\n    select * from DEMO_DB.DBT_MACRO.test_standard_scaler\n),\nb as (\n    select * from DEMO_DB.DBT_MACRO.data_standard_scaler_expected\n),\njoined as(\n    select round(a.col_to_scale_1_scaled,6) as actual,\n        round(b.col_to_scale_1_scaled,6) as expected,\n        abs(actual-expected) as difference,\n        iff(difference>0,difference/b.col_to_scale_1_scaled,0)*100 as percent_difference\n  from a\n  join b on a.id_col=b.id_col\n  )\nselect \n       count(*) \n       \nfrom joined\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \n-- the values do not end up exactly the same as those output from python\nwhere percent_difference > 1e-07\n", "column_name": null}, "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_2_scaled__id_col__col_to_scale_2_scaled": {"raw_sql": "{{ config(severity='ERROR') }}{{ test_equality_with_numeric_tolerance(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": null, "name": "equality_with_numeric_tolerance", "kwargs": {"compare_model": "ref('data_standard_scaler_expected')", "source_join_column": "id_col", "target_join_column": "id_col", "source_numeric_column_name": "col_to_scale_2_scaled", "target_numeric_column_name": "col_to_scale_2_scaled", "percentage_tolerance": 1e-07, "model": "{{ ref('test_standard_scaler') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_2_scaled__id_col__col_to_scale_2_scaled"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_2_scaled__id_col__col_to_scale_2_scaled", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\equality_with_numeric_tolerance_test_standard_scaler_26654e3e50caa21255248d1fd99c9665.sql", "original_file_path": "models\\sql\\schema.yml", "name": "equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_2_scaled__id_col__col_to_scale_2_scaled", "resource_type": "test", "alias": "equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_2_scaled__id_col__col_to_scale_2_scaled", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_standard_scaler_expected"], ["test_standard_scaler"]], "sources": [], "depends_on": {"macros": ["macro.dbt_ml_preprocessing_integration_tests.test_equality_with_numeric_tolerance"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler_expected", "model.dbt_ml_preprocessing_integration_tests.test_standard_scaler"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\equality_with_numeric_tolerance_test_standard_scaler_26654e3e50caa21255248d1fd99c9665.sql", "deferred": false, "compiled_sql": "\n\nwith a as (\n    select * from DEMO_DB.DBT_MACRO.test_standard_scaler\n),\nb as (\n    select * from DEMO_DB.DBT_MACRO.data_standard_scaler_expected\n),\njoined as(\n    select round(a.col_to_scale_2_scaled,6) as actual,\n        round(b.col_to_scale_2_scaled,6) as expected,\n        abs(actual-expected) as difference,\n        iff(difference>0,difference/b.col_to_scale_2_scaled,0)*100 as percent_difference\n  from a\n  join b on a.id_col=b.id_col\n  )\nselect \n       count(*) \n       \nfrom joined\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \n-- the values do not end up exactly the same as those output from python\nwhere percent_difference > 1e-07\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\nwith a as (\n    select * from DEMO_DB.DBT_MACRO.test_standard_scaler\n),\nb as (\n    select * from DEMO_DB.DBT_MACRO.data_standard_scaler_expected\n),\njoined as(\n    select round(a.col_to_scale_2_scaled,6) as actual,\n        round(b.col_to_scale_2_scaled,6) as expected,\n        abs(actual-expected) as difference,\n        iff(difference>0,difference/b.col_to_scale_2_scaled,0)*100 as percent_difference\n  from a\n  join b on a.id_col=b.id_col\n  )\nselect \n       count(*) \n       \nfrom joined\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \n-- the values do not end up exactly the same as those output from python\nwhere percent_difference > 1e-07\n", "column_name": null}, "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_one_hot_encoder_ref_data_one_hot_encoder_expected_": {"raw_sql": "{{ config(severity='ERROR') }}{{ dbt_utils.test_equality(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": "dbt_utils", "name": "equality", "kwargs": {"compare_model": "ref('data_one_hot_encoder_expected')", "model": "{{ ref('test_one_hot_encoder') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "dbt_utils_equality_test_one_hot_encoder_ref_data_one_hot_encoder_expected_"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_one_hot_encoder_ref_data_one_hot_encoder_expected_", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\dbt_utils_equality_test_one_hot_encoder_da2ad043f2a5e4a91a39f0341dd1f768.sql", "original_file_path": "models\\sql\\schema.yml", "name": "dbt_utils_equality_test_one_hot_encoder_ref_data_one_hot_encoder_expected_", "resource_type": "test", "alias": "dbt_utils_equality_test_one_hot_encoder_ref_data_one_hot_encoder_expected_", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_one_hot_encoder_expected"], ["test_one_hot_encoder"]], "sources": [], "depends_on": {"macros": ["macro.dbt_utils.test_equality"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder_expected", "model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\dbt_utils_equality_test_one_hot_encoder_da2ad043f2a5e4a91a39f0341dd1f768.sql", "deferred": false, "compiled_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_one_hot_encoder\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_one_hot_encoder_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\", \"IS_COLUMN_TO_ENCODE_C\", \"IS_COLUMN_TO_ENCODE_D\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\", \"IS_COLUMN_TO_ENCODE_C\", \"IS_COLUMN_TO_ENCODE_D\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\", \"IS_COLUMN_TO_ENCODE_C\", \"IS_COLUMN_TO_ENCODE_D\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\", \"IS_COLUMN_TO_ENCODE_C\", \"IS_COLUMN_TO_ENCODE_D\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_one_hot_encoder\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_one_hot_encoder_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\", \"IS_COLUMN_TO_ENCODE_C\", \"IS_COLUMN_TO_ENCODE_D\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\", \"IS_COLUMN_TO_ENCODE_C\", \"IS_COLUMN_TO_ENCODE_D\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\", \"IS_COLUMN_TO_ENCODE_C\", \"IS_COLUMN_TO_ENCODE_D\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\", \"IS_COLUMN_TO_ENCODE_C\", \"IS_COLUMN_TO_ENCODE_D\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "column_name": null}, "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_one_hot_encoder_category_selected_ref_data_one_hot_encoder_category_selected_expected_": {"raw_sql": "{{ config(severity='ERROR') }}{{ dbt_utils.test_equality(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": "dbt_utils", "name": "equality", "kwargs": {"compare_model": "ref('data_one_hot_encoder_category_selected_expected')", "model": "{{ ref('test_one_hot_encoder_category_selected') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "dbt_utils_equality_test_one_hot_encoder_category_selected_ref_data_one_hot_encoder_category_selected_expected_"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_one_hot_encoder_category_selected_ref_data_one_hot_encoder_category_selected_expected_", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\dbt_utils_equality_test_one_hot_encoder_category_selected_9cd22166ba568c5d87e33592ffe7f657.sql", "original_file_path": "models\\sql\\schema.yml", "name": "dbt_utils_equality_test_one_hot_encoder_category_selected_ref_data_one_hot_encoder_category_selected_expected_", "resource_type": "test", "alias": "dbt_utils_equality_test_one_hot_encoder_category_selected_ref_data_one_hot_encoder_category_selected_expected_", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_one_hot_encoder_category_selected_expected"], ["test_one_hot_encoder_category_selected"]], "sources": [], "depends_on": {"macros": ["macro.dbt_utils.test_equality"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder_category_selected_expected", "model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder_category_selected"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\dbt_utils_equality_test_one_hot_encoder_category_selected_9cd22166ba568c5d87e33592ffe7f657.sql", "deferred": false, "compiled_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_one_hot_encoder_category_selected\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_one_hot_encoder_category_selected_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_one_hot_encoder_category_selected\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_one_hot_encoder_category_selected_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COLUMN_TO_ENCODE\", \"IS_COLUMN_TO_ENCODE_A\", \"IS_COLUMN_TO_ENCODE_B\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "column_name": null}, "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_robust_scaler_ref_data_robust_scaler_expected_": {"raw_sql": "{{ config(severity='ERROR') }}{{ dbt_utils.test_equality(**_dbt_schema_test_kwargs) }}", "test_metadata": {"namespace": "dbt_utils", "name": "equality", "kwargs": {"compare_model": "ref('data_robust_scaler_expected')", "model": "{{ ref('test_robust_scaler') }}"}}, "compiled": true, "database": "DEMO_DB", "schema": "DBT_MACRO", "fqn": ["dbt_ml_preprocessing_integration_tests", "schema_test", "dbt_utils_equality_test_robust_scaler_ref_data_robust_scaler_expected_"], "unique_id": "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_robust_scaler_ref_data_robust_scaler_expected_", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "schema_test\\dbt_utils_equality_test_robust_scaler_ref_data_robust_scaler_expected_.sql", "original_file_path": "models\\sql\\schema.yml", "name": "dbt_utils_equality_test_robust_scaler_ref_data_robust_scaler_expected_", "resource_type": "test", "alias": "dbt_utils_equality_test_robust_scaler_ref_data_robust_scaler_expected_", "checksum": {"name": "none", "checksum": ""}, "config": {"enabled": true, "materialized": "view", "persist_docs": {}, "post-hook": [], "pre-hook": [], "vars": {}, "quoting": {}, "column_types": {}, "alias": null, "schema": null, "database": null, "tags": [], "full_refresh": null, "severity": "ERROR"}, "tags": ["schema"], "refs": [["data_robust_scaler_expected"], ["test_robust_scaler"]], "sources": [], "depends_on": {"macros": ["macro.dbt_utils.test_equality"], "nodes": ["seed.dbt_ml_preprocessing_integration_tests.data_robust_scaler_expected", "model.dbt_ml_preprocessing_integration_tests.test_robust_scaler"]}, "description": "", "columns": {}, "meta": {}, "docs": {"show": true}, "patch_path": null, "build_path": "target\\compiled\\dbt_ml_preprocessing_integration_tests\\models\\sql\\schema.yml\\schema_test\\dbt_utils_equality_test_robust_scaler_ref_data_robust_scaler_expected_.sql", "deferred": false, "compiled_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_robust_scaler\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_robust_scaler_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "extra_ctes_injected": true, "extra_ctes": [], "injected_sql": "\n\n-- setup\n\n\n\nwith a as (\n\n    select * from DEMO_DB.DBT_MACRO.test_robust_scaler\n\n),\n\nb as (\n\n    select * from DEMO_DB.DBT_MACRO.data_robust_scaler_expected\n\n),\n\na_minus_b as (\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from a\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from b\n\n),\n\nb_minus_a as (\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from b\n    \n  \n\n    except\n\n\n\n    select \"ID_COL\", \"COL_TO_SCALE\", \"COL_TO_SCALE_SCALED\" from a\n\n),\n\nunioned as (\n\n    select * from a_minus_b\n    union all\n    select * from b_minus_a\n\n),\n\nfinal as (\n\n    select (select count(*) from unioned) +\n        (select abs(\n            (select count(*) from a_minus_b) -\n            (select count(*) from b_minus_a)\n            ))\n        as count\n\n)\n\nselect count from final\n\n", "column_name": null}}, "sources": {}, "macros": {"macro.dbt_ml_preprocessing_integration_tests.test_equality_with_numeric_tolerance": {"unique_id": "macro.dbt_ml_preprocessing_integration_tests.test_equality_with_numeric_tolerance", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "macros\\equality_with_numeric_tolerance.sql", "original_file_path": "macros\\equality_with_numeric_tolerance.sql", "name": "test_equality_with_numeric_tolerance", "macro_sql": "{% macro test_equality_with_numeric_tolerance(model) %}\r\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\r\n{%- if not execute -%}\r\n    {{ return('') }}\r\n{% endif %}\r\n{%- do dbt_utils._is_relation(model, 'test_equality') -%}\r\n\r\n{#-\r\nIf the compare_cols arg is provided, we can run this test without querying the\r\ninformation schema \u2014 this allows the model to be an ephemeral model\r\n-#}\r\n{%- set compare_columns = kwargs.get('compare_columns', None) -%}\r\n\r\n{%- if not compare_columns -%}\r\n    {%- do dbt_utils._is_ephemeral(model, 'test_equality_with_numeric_tolerance') -%}\r\n    {%- set compare_columns = adapter.get_columns_in_relation(model) | map(attribute='quoted') -%}\r\n{%- endif -%}\r\n\r\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\r\n{% set source_join_column = kwargs.get('source_join_column', kwargs.get('arg')) %}\r\n{% set target_join_column = kwargs.get('target_join_column', kwargs.get('arg')) %}\r\n{% set source_numeric_column_name = kwargs.get('source_numeric_column_name', kwargs.get('arg')) %}\r\n{% set target_numeric_column_name = kwargs.get('target_numeric_column_name', kwargs.get('arg')) %}\r\n{% set percentage_tolerance = kwargs.get('percentage_tolerance', kwargs.get('arg')) %}\r\n\r\n{{ return(adapter.dispatch('test_equality_with_numeric_tolerance')(model,compare_model,source_join_column,target_join_column,source_numeric_column_name,target_numeric_column_name,percentage_tolerance)) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_ml_preprocessing_integration_tests.default__test_equality_with_numeric_tolerance": {"unique_id": "macro.dbt_ml_preprocessing_integration_tests.default__test_equality_with_numeric_tolerance", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "macros\\equality_with_numeric_tolerance.sql", "original_file_path": "macros\\equality_with_numeric_tolerance.sql", "name": "default__test_equality_with_numeric_tolerance", "macro_sql": "{% macro default__test_equality_with_numeric_tolerance(model,compare_model,source_join_column,target_join_column,source_numeric_column_name,target_numeric_column_name,percentage_tolerance,output_all_rows=False) %}\r\n{% set compare_cols_csv = compare_columns | join(', ') %}\r\nwith a as (\r\n    select * from {{ model }}\r\n),\r\nb as (\r\n    select * from {{ compare_model }}\r\n),\r\njoined as(\r\n    select a.*,\r\n        b.{{ target_numeric_column_name }},\r\n        a.{{ source_numeric_column_name }}-b.{{ target_numeric_column_name }} as difference,\r\n        if((a.{{ source_numeric_column_name }}-b.{{ target_numeric_column_name }})>0,\r\n            (a.{{ source_numeric_column_name }}-b.{{ target_numeric_column_name }})/b.{{ target_numeric_column_name }},\r\n            0\r\n        )*100 as percent_difference\r\n  from a\r\n  join b on a.{{ source_join_column }}=b.{{ target_join_column }}\r\n)\r\nselect {% if output_all_rows %}\r\n        *\r\n       {% else %}\r\n       count(*) \r\n       {% endif %}\r\nfrom joined\r\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \r\n-- the values do not end up exactly the same as those output from python\r\nwhere percent_difference > {{ percentage_tolerance }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_ml_preprocessing_integration_tests.snowflake__test_equality_with_numeric_tolerance": {"unique_id": "macro.dbt_ml_preprocessing_integration_tests.snowflake__test_equality_with_numeric_tolerance", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "macros\\equality_with_numeric_tolerance.sql", "original_file_path": "macros\\equality_with_numeric_tolerance.sql", "name": "snowflake__test_equality_with_numeric_tolerance", "macro_sql": "{% macro snowflake__test_equality_with_numeric_tolerance(model,compare_model,source_join_column,target_join_column,source_numeric_column_name,target_numeric_column_name,percentage_tolerance,output_all_rows=False) %}\r\n{% set compare_cols_csv = compare_columns | join(', ') %}\r\nwith a as (\r\n    select * from {{ model }}\r\n),\r\nb as (\r\n    select * from {{ compare_model }}\r\n),\r\njoined as(\r\n    select round(a.{{ source_numeric_column_name }},6) as actual,\r\n        round(b.{{ target_numeric_column_name }},6) as expected,\r\n        abs(actual-expected) as difference,\r\n        iff(difference>0,difference/b.{{ target_numeric_column_name }},0)*100 as percent_difference\r\n  from a\r\n  join b on a.{{ source_join_column }}=b.{{ target_join_column }}\r\n  )\r\nselect {% if output_all_rows %}\r\n        *\r\n       {% else %}\r\n       count(*) \r\n       {% endif %}\r\nfrom joined\r\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \r\n-- the values do not end up exactly the same as those output from python\r\nwhere percent_difference > {{ percentage_tolerance }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_ml_preprocessing_integration_tests.redshift__test_equality_with_numeric_tolerance": {"unique_id": "macro.dbt_ml_preprocessing_integration_tests.redshift__test_equality_with_numeric_tolerance", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "macros\\equality_with_numeric_tolerance.sql", "original_file_path": "macros\\equality_with_numeric_tolerance.sql", "name": "redshift__test_equality_with_numeric_tolerance", "macro_sql": "{% macro redshift__test_equality_with_numeric_tolerance(model,compare_model,source_join_column,target_join_column,source_numeric_column_name,target_numeric_column_name,percentage_tolerance,output_all_rows=False) %}\r\n{% set compare_cols_csv = compare_columns | join(', ') %}\r\nwith a as (\r\n    select * from {{ model }}\r\n),\r\nb as (\r\n    select * from {{ compare_model }}\r\n),\r\njoined as(\r\n    select a.*,\r\n        b.{{ target_numeric_column_name }},\r\n        a.{{ source_numeric_column_name }}-b.{{ target_numeric_column_name }} as difference,\r\n        case \r\n            when (a.{{ source_numeric_column_name }}-b.{{ target_numeric_column_name }})>0\r\n            then\r\n            (a.{{ source_numeric_column_name }}-b.{{ target_numeric_column_name }})/b.{{ target_numeric_column_name }}\r\n            else 0\r\n            end\r\n        *100 as percent_difference\r\n  from a\r\n  join b on a.{{ source_join_column }}=b.{{ target_join_column }}\r\n)\r\nselect {% if output_all_rows %}\r\n        *\r\n       {% else %}\r\n       count(*) \r\n       {% endif %}\r\nfrom joined\r\n-- The reason we tolerate tiny differences here is because of the floating point arithmetic, \r\n-- the values do not end up exactly the same as those output from python\r\nwhere percent_difference > {{ percentage_tolerance }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_ml_preprocessing_integration_tests.snowflake__quantile_transformer_model_macro": {"unique_id": "macro.dbt_ml_preprocessing_integration_tests.snowflake__quantile_transformer_model_macro", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "macros\\quantile_transformer_model_macro.sql", "original_file_path": "macros\\quantile_transformer_model_macro.sql", "name": "snowflake__quantile_transformer_model_macro", "macro_sql": "{% macro snowflake__quantile_transformer_model_macro() %}\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.quantile_transformer( ref('data_quantile_transformer') ,'col_to_transform') }}\r\n\r\n)\r\nselect * from data\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_ml_preprocessing_integration_tests.bigquery__quantile_transformer_model_macro": {"unique_id": "macro.dbt_ml_preprocessing_integration_tests.bigquery__quantile_transformer_model_macro", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "macros\\quantile_transformer_model_macro.sql", "original_file_path": "macros\\quantile_transformer_model_macro.sql", "name": "bigquery__quantile_transformer_model_macro", "macro_sql": "{% macro bigquery__quantile_transformer_model_macro() %}\r\nwith data as (\r\n\r\n    {{ dbt_ml_preprocessing.quantile_transformer( ref('data_quantile_transformer') ,'col_to_transform') }}\r\n\r\n)\r\nselect * from data\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_ml_preprocessing_integration_tests.default__quantile_transformer_model_macro": {"unique_id": "macro.dbt_ml_preprocessing_integration_tests.default__quantile_transformer_model_macro", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "macros\\quantile_transformer_model_macro.sql", "original_file_path": "macros\\quantile_transformer_model_macro.sql", "name": "default__quantile_transformer_model_macro", "macro_sql": "{% macro default__quantile_transformer_model_macro() %}\r\nselect 1 as empty_result from (select 1) where 1=2\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_ml_preprocessing_integration_tests.snowflake__test_quantile_transformer_result_with_tolerance": {"unique_id": "macro.dbt_ml_preprocessing_integration_tests.snowflake__test_quantile_transformer_result_with_tolerance", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "macros\\test_quantile_transformer_result_with_tolerance.sql", "original_file_path": "macros\\test_quantile_transformer_result_with_tolerance.sql", "name": "snowflake__test_quantile_transformer_result_with_tolerance", "macro_sql": "{% macro snowflake__test_quantile_transformer_result_with_tolerance() %}\r\n\r\n{{ snowflake__test_equality_with_numeric_tolerance('test_quantile_transformer',\r\n                                                    'data_quantile_transformer_expected',\r\n                                                    'id_col',\r\n                                                    'id_col',\r\n                                                    'col_to_transform_transformed',\r\n                                                    'col_to_transform_transformed',\r\n                                                    '0.005',\r\n                                                    output_all_rows=True) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_ml_preprocessing_integration_tests.default__test_quantile_transformer_result_with_tolerance": {"unique_id": "macro.dbt_ml_preprocessing_integration_tests.default__test_quantile_transformer_result_with_tolerance", "package_name": "dbt_ml_preprocessing_integration_tests", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests", "path": "macros\\test_quantile_transformer_result_with_tolerance.sql", "original_file_path": "macros\\test_quantile_transformer_result_with_tolerance.sql", "name": "default__test_quantile_transformer_result_with_tolerance", "macro_sql": "{% macro default__test_quantile_transformer_result_with_tolerance() %}\r\nselect 1 from (select 1) where 1=2 -- empty result set so that test passes\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__create_table_as": {"unique_id": "macro.dbt_snowflake.snowflake__create_table_as", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__create_table_as", "macro_sql": "{% macro snowflake__create_table_as(temporary, relation, sql) -%}\n  {%- set transient = config.get('transient', default=true) -%}\n  {%- set cluster_by_keys = config.get('cluster_by', default=none) -%}\n  {%- set enable_automatic_clustering = config.get('automatic_clustering', default=false) -%}\n  {%- set copy_grants = config.get('copy_grants', default=false) -%}\n\n  {%- if cluster_by_keys is not none and cluster_by_keys is string -%}\n    {%- set cluster_by_keys = [cluster_by_keys] -%}\n  {%- endif -%}\n  {%- if cluster_by_keys is not none -%}\n    {%- set cluster_by_string = cluster_by_keys|join(\", \")-%}\n  {% else %}\n    {%- set cluster_by_string = none -%}\n  {%- endif -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n      create or replace {% if temporary -%}\n        temporary\n      {%- elif transient -%}\n        transient\n      {%- endif %} table {{ relation }} {% if copy_grants and not temporary -%} copy grants {%- endif %} as\n      (\n        {%- if cluster_by_string is not none -%}\n          select * from(\n            {{ sql }}\n            ) order by ({{ cluster_by_string }})\n        {%- else -%}\n          {{ sql }}\n        {%- endif %}\n      );\n    {% if cluster_by_string is not none and not temporary -%}\n      alter table {{relation}} cluster by ({{cluster_by_string}});\n    {%- endif -%}\n    {% if enable_automatic_clustering and cluster_by_string is not none and not temporary  -%}\n      alter table {{relation}} resume recluster;\n    {%- endif -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__create_view_as": {"unique_id": "macro.dbt_snowflake.snowflake__create_view_as", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__create_view_as", "macro_sql": "{% macro snowflake__create_view_as(relation, sql) -%}\n  {%- set secure = config.get('secure', default=false) -%}\n  {%- set copy_grants = config.get('copy_grants', default=false) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create or replace {% if secure -%}\n    secure\n  {%- endif %} view {{ relation }} {% if copy_grants -%} copy grants {%- endif %} as (\n    {{ sql }}\n  );\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__get_columns_in_relation": {"unique_id": "macro.dbt_snowflake.snowflake__get_columns_in_relation", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__get_columns_in_relation", "macro_sql": "{% macro snowflake__get_columns_in_relation(relation) -%}\n  {%- set sql -%}\n    describe table {{ relation }}\n  {%- endset -%}\n  {%- set result = run_query(sql) -%}\n\n  {% set maximum = 10000 %}\n  {% if (result | length) >= maximum %}\n    {% set msg %}\n      Too many columns in relation {{ relation }}! dbt can only get\n      information about relations with fewer than {{ maximum }} columns.\n    {% endset %}\n    {% do exceptions.raise_compiler_error(msg) %}\n  {% endif %}\n\n  {% set columns = [] %}\n  {% for row in result %}\n    {% do columns.append(api.Column.from_description(row['name'], row['type'])) %}\n  {% endfor %}\n  {% do return(columns) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__list_schemas": {"unique_id": "macro.dbt_snowflake.snowflake__list_schemas", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__list_schemas", "macro_sql": "{% macro snowflake__list_schemas(database) -%}\n  {# 10k limit from here: https://docs.snowflake.net/manuals/sql-reference/sql/show-schemas.html#usage-notes #}\n  {% set maximum = 10000 %}\n  {% set sql -%}\n    show terse schemas in database {{ database }}\n    limit {{ maximum }}\n  {%- endset %}\n  {% set result = run_query(sql) %}\n  {% if (result | length) >= maximum %}\n    {% set msg %}\n      Too many schemas in database {{ database }}! dbt can only get\n      information about databases with fewer than {{ maximum }} schemas.\n    {% endset %}\n    {% do exceptions.raise_compiler_error(msg) %}\n  {% endif %}\n  {{ return(result) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__list_relations_without_caching": {"unique_id": "macro.dbt_snowflake.snowflake__list_relations_without_caching", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__list_relations_without_caching", "macro_sql": "{% macro snowflake__list_relations_without_caching(schema_relation) %}\n  {%- set sql -%}\n    show terse objects in {{ schema_relation }}\n  {%- endset -%}\n\n  {%- set result = run_query(sql) -%}\n  {% set maximum = 10000 %}\n  {% if (result | length) >= maximum %}\n    {% set msg %}\n      Too many schemas in schema  {{ schema_relation }}! dbt can only get\n      information about schemas with fewer than {{ maximum }} objects.\n    {% endset %}\n    {% do exceptions.raise_compiler_error(msg) %}\n  {% endif %}\n  {%- do return(result) -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__check_schema_exists": {"unique_id": "macro.dbt_snowflake.snowflake__check_schema_exists", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__check_schema_exists", "macro_sql": "{% macro snowflake__check_schema_exists(information_schema, schema) -%}\n  {% call statement('check_schema_exists', fetch_result=True) -%}\n        select count(*)\n        from {{ information_schema }}.schemata\n        where upper(schema_name) = upper('{{ schema }}')\n            and upper(catalog_name) = upper('{{ information_schema.database }}')\n  {%- endcall %}\n  {{ return(load_result('check_schema_exists').table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__current_timestamp": {"unique_id": "macro.dbt_snowflake.snowflake__current_timestamp", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__current_timestamp", "macro_sql": "{% macro snowflake__current_timestamp() -%}\n  convert_timezone('UTC', current_timestamp())\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__snapshot_string_as_time": {"unique_id": "macro.dbt_snowflake.snowflake__snapshot_string_as_time", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__snapshot_string_as_time", "macro_sql": "{% macro snowflake__snapshot_string_as_time(timestamp) -%}\n    {%- set result = \"to_timestamp_ntz('\" ~ timestamp ~ \"')\" -%}\n    {{ return(result) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__snapshot_get_time": {"unique_id": "macro.dbt_snowflake.snowflake__snapshot_get_time", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__snapshot_get_time", "macro_sql": "{% macro snowflake__snapshot_get_time() -%}\n  to_timestamp_ntz({{ current_timestamp() }})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__rename_relation": {"unique_id": "macro.dbt_snowflake.snowflake__rename_relation", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__rename_relation", "macro_sql": "{% macro snowflake__rename_relation(from_relation, to_relation) -%}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ to_relation }}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__alter_column_type": {"unique_id": "macro.dbt_snowflake.snowflake__alter_column_type", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__alter_column_type", "macro_sql": "{% macro snowflake__alter_column_type(relation, column_name, new_column_type) -%}\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} alter {{ adapter.quote(column_name) }} set data type {{ new_column_type }};\n  {% endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__alter_relation_comment": {"unique_id": "macro.dbt_snowflake.snowflake__alter_relation_comment", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__alter_relation_comment", "macro_sql": "{% macro snowflake__alter_relation_comment(relation, relation_comment) -%}\n  comment on {{ relation.type }} {{ relation }} IS $${{ relation_comment | replace('$', '[$]') }}$$;\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__alter_column_comment": {"unique_id": "macro.dbt_snowflake.snowflake__alter_column_comment", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "snowflake__alter_column_comment", "macro_sql": "{% macro snowflake__alter_column_comment(relation, column_dict) -%}\n    alter {{ relation.type }} {{ relation }} alter\n    {% for column_name in column_dict %}\n        {{ adapter.quote(column_name) if column_dict[column_name]['quote'] else column_name }} COMMENT $${{ column_dict[column_name]['description'] | replace('$', '[$]') }}$$ {{ ',' if not loop.last else ';' }}\n    {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.get_current_query_tag": {"unique_id": "macro.dbt_snowflake.get_current_query_tag", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "get_current_query_tag", "macro_sql": "{% macro get_current_query_tag() -%}\n  {{ return(run_query(\"show parameters like 'query_tag' in session\").rows[0]['value']) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.set_query_tag": {"unique_id": "macro.dbt_snowflake.set_query_tag", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "set_query_tag", "macro_sql": "{% macro set_query_tag() -%}\n  {% set new_query_tag = config.get('query_tag') %}\n  {% if new_query_tag %}\n    {% set original_query_tag = get_current_query_tag() %}\n    {{ log(\"Setting query_tag to '\" ~ new_query_tag ~ \"'. Will reset to '\" ~ original_query_tag ~ \"' after materialization.\") }}\n    {% do run_query(\"alter session set query_tag = '{}'\".format(new_query_tag)) %}\n    {{ return(original_query_tag)}}\n  {% endif %}\n  {{ return(none)}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.unset_query_tag": {"unique_id": "macro.dbt_snowflake.unset_query_tag", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\adapters.sql", "original_file_path": "macros\\adapters.sql", "name": "unset_query_tag", "macro_sql": "{% macro unset_query_tag(original_query_tag) -%}\n  {% set new_query_tag = config.get('query_tag') %}\n  {% if new_query_tag %}\n    {% if original_query_tag %}\n      {{ log(\"Resetting query_tag to '\" ~ original_query_tag ~ \"'.\") }}\n      {% do run_query(\"alter session set query_tag = '{}'\".format(original_query_tag)) %}\n    {% else %}\n      {{ log(\"No original query_tag, unsetting parameter.\") }}\n      {% do run_query(\"alter session unset query_tag\") %}\n    {% endif %}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__get_catalog": {"unique_id": "macro.dbt_snowflake.snowflake__get_catalog", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\catalog.sql", "original_file_path": "macros\\catalog.sql", "name": "snowflake__get_catalog", "macro_sql": "{% macro snowflake__get_catalog(information_schema, schemas) -%}\n  {% set query %}\n      with tables as (\n\n          select\n              table_catalog as \"table_database\",\n              table_schema as \"table_schema\",\n              table_name as \"table_name\",\n              table_type as \"table_type\",\n              comment as \"table_comment\",\n\n              -- note: this is the _role_ that owns the table\n              table_owner as \"table_owner\",\n\n              'Clustering Key' as \"stats:clustering_key:label\",\n              clustering_key as \"stats:clustering_key:value\",\n              'The key used to cluster this table' as \"stats:clustering_key:description\",\n              (clustering_key is not null) as \"stats:clustering_key:include\",\n\n              'Row Count' as \"stats:row_count:label\",\n              row_count as \"stats:row_count:value\",\n              'An approximate count of rows in this table' as \"stats:row_count:description\",\n              (row_count is not null) as \"stats:row_count:include\",\n\n              'Approximate Size' as \"stats:bytes:label\",\n              bytes as \"stats:bytes:value\",\n              'Approximate size of the table as reported by Snowflake' as \"stats:bytes:description\",\n              (bytes is not null) as \"stats:bytes:include\",\n\n              'Last Modified' as \"stats:last_modified:label\",\n              to_varchar(convert_timezone('UTC', last_altered), 'yyyy-mm-dd HH24:MI'||'UTC') as \"stats:last_modified:value\",\n              'The timestamp for last update/change' as \"stats:last_modified:description\",\n              (last_altered is not null and table_type='BASE TABLE') as \"stats:last_modified:include\"\n\n          from {{ information_schema }}.tables\n\n      ),\n\n      columns as (\n\n          select\n              table_catalog as \"table_database\",\n              table_schema as \"table_schema\",\n              table_name as \"table_name\",\n\n              column_name as \"column_name\",\n              ordinal_position as \"column_index\",\n              data_type as \"column_type\",\n              comment as \"column_comment\"\n\n          from {{ information_schema }}.columns\n      )\n\n      select *\n      from tables\n      join columns using (\"table_database\", \"table_schema\", \"table_name\")\n      where (\n        {%- for schema in schemas -%}\n          upper(\"table_schema\") = upper('{{ schema }}'){%- if not loop.last %} or {% endif -%}\n        {%- endfor -%}\n      )\n      order by \"column_index\"\n    {%- endset -%}\n\n  {{ return(run_query(query)) }}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.dbt_snowflake_validate_get_incremental_strategy": {"unique_id": "macro.dbt_snowflake.dbt_snowflake_validate_get_incremental_strategy", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\materializations\\incremental.sql", "original_file_path": "macros\\materializations\\incremental.sql", "name": "dbt_snowflake_validate_get_incremental_strategy", "macro_sql": "{% macro dbt_snowflake_validate_get_incremental_strategy(config) %}\n  {#-- Find and validate the incremental strategy #}\n  {%- set strategy = config.get(\"incremental_strategy\", default=\"merge\") -%}\n\n  {% set invalid_strategy_msg -%}\n    Invalid incremental strategy provided: {{ strategy }}\n    Expected one of: 'merge', 'delete+insert'\n  {%- endset %}\n  {% if strategy not in ['merge', 'delete+insert'] %}\n    {% do exceptions.raise_compiler_error(invalid_strategy_msg) %}\n  {% endif %}\n\n  {% do return(strategy) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.dbt_snowflake_get_incremental_sql": {"unique_id": "macro.dbt_snowflake.dbt_snowflake_get_incremental_sql", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\materializations\\incremental.sql", "original_file_path": "macros\\materializations\\incremental.sql", "name": "dbt_snowflake_get_incremental_sql", "macro_sql": "{% macro dbt_snowflake_get_incremental_sql(strategy, tmp_relation, target_relation, unique_key, dest_columns) %}\n  {% if strategy == 'merge' %}\n    {% do return(get_merge_sql(target_relation, tmp_relation, unique_key, dest_columns)) %}\n  {% elif strategy == 'delete+insert' %}\n    {% do return(get_delete_insert_merge_sql(target_relation, tmp_relation, unique_key, dest_columns)) %}\n  {% else %}\n    {% do exceptions.raise_compiler_error('invalid strategy: ' ~ strategy) %}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.materialization_incremental_snowflake": {"unique_id": "macro.dbt_snowflake.materialization_incremental_snowflake", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\materializations\\incremental.sql", "original_file_path": "macros\\materializations\\incremental.sql", "name": "materialization_incremental_snowflake", "macro_sql": "{% materialization incremental, adapter='snowflake' -%}\n\n  {% set original_query_tag = set_query_tag() %}\n\n  {%- set unique_key = config.get('unique_key') -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {% set target_relation = this %}\n  {% set existing_relation = load_relation(this) %}\n  {% set tmp_relation = make_temp_relation(this) %}\n\n  {#-- Validate early so we don't run SQL if the strategy is invalid --#}\n  {% set strategy = dbt_snowflake_validate_get_incremental_strategy(config) -%}\n\n  -- setup\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% if existing_relation is none %}\n    {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view %}\n    {#-- Can't overwrite a view with a table - we must drop --#}\n    {{ log(\"Dropping relation \" ~ target_relation ~ \" because it is a view and this model is a table.\") }}\n    {% do adapter.drop_relation(existing_relation) %}\n    {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif full_refresh_mode %}\n    {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% else %}\n    {% do run_query(create_table_as(True, tmp_relation, sql)) %}\n    {% do adapter.expand_target_column_types(\n           from_relation=tmp_relation,\n           to_relation=target_relation) %}\n    {% set dest_columns = adapter.get_columns_in_relation(target_relation) %}\n    {% set build_sql = dbt_snowflake_get_incremental_sql(strategy, tmp_relation, target_relation, unique_key, dest_columns) %}\n  {% endif %}\n\n  {%- call statement('main') -%}\n    {{ build_sql }}\n  {%- endcall -%}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% set target_relation = target_relation.incorporate(type='table') %}\n  {% do persist_docs(target_relation, model) %}\n\n  {% do unset_query_tag(original_query_tag) %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.snowflake__get_merge_sql": {"unique_id": "macro.dbt_snowflake.snowflake__get_merge_sql", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\materializations\\merge.sql", "original_file_path": "macros\\materializations\\merge.sql", "name": "snowflake__get_merge_sql", "macro_sql": "{% macro snowflake__get_merge_sql(target, source_sql, unique_key, dest_columns, predicates) -%}\n\n    {#\n       Workaround for Snowflake not being happy with a merge on a constant-false predicate.\n       When no unique_key is provided, this macro will do a regular insert. If a unique_key\n       is provided, then this macro will do a proper merge instead.\n    #}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute='name')) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {%- if unique_key is none -%}\n\n        {{ sql_header if sql_header is not none }}\n\n        insert into {{ target }} ({{ dest_cols_csv }})\n        (\n            select {{ dest_cols_csv }}\n            from {{ source_sql }}\n        );\n\n    {%- else -%}\n\n        {{ default__get_merge_sql(target, source_sql, unique_key, dest_columns, predicates) }}\n\n    {%- endif -%}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.materialization_table_snowflake": {"unique_id": "macro.dbt_snowflake.materialization_table_snowflake", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\materializations\\table.sql", "original_file_path": "macros\\materializations\\table.sql", "name": "materialization_table_snowflake", "macro_sql": "{% materialization table, adapter='snowflake' %}\n\n  {% set original_query_tag = set_query_tag() %}\n\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database, type='table') -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {#-- Drop the relation if it was a view to \"convert\" it in a table. This may lead to\n    -- downtime, but it should be a relatively infrequent occurrence  #}\n  {% if old_relation is not none and not old_relation.is_table %}\n    {{ log(\"Dropping relation \" ~ old_relation ~ \" because it is of type \" ~ old_relation.type) }}\n    {{ drop_relation_if_exists(old_relation) }}\n  {% endif %}\n\n  --build model\n  {% call statement('main') -%}\n    {{ create_table_as(false, target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {% do unset_query_tag(original_query_tag) %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_snowflake.materialization_view_snowflake": {"unique_id": "macro.dbt_snowflake.materialization_view_snowflake", "package_name": "dbt_snowflake", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\snowflake", "path": "macros\\materializations\\view.sql", "original_file_path": "macros\\materializations\\view.sql", "name": "materialization_view_snowflake", "macro_sql": "{% materialization view, adapter='snowflake' -%}\n\n    {% set original_query_tag = set_query_tag() %}\n    {% set to_return = create_or_replace_view() %}\n\n    {% set target_relation = this.incorporate(type='view') %}\n    {% do persist_docs(target_relation, model, for_columns=false) %}\n\n    {% do return(to_return) %}\n\n    {% do unset_query_tag(original_query_tag) %}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.statement": {"unique_id": "macro.dbt.statement", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\core.sql", "original_file_path": "macros\\core.sql", "name": "statement", "macro_sql": "{% macro statement(name=None, fetch_result=False, auto_begin=True) -%}\n  {%- if execute: -%}\n    {%- set sql = caller() -%}\n\n    {%- if name == 'main' -%}\n      {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n      {{ write(sql) }}\n    {%- endif -%}\n\n    {%- set status, res = adapter.execute(sql, auto_begin=auto_begin, fetch=fetch_result) -%}\n    {%- if name is not none -%}\n      {{ store_result(name, status=status, agate_table=res) }}\n    {%- endif -%}\n\n  {%- endif -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.noop_statement": {"unique_id": "macro.dbt.noop_statement", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\core.sql", "original_file_path": "macros\\core.sql", "name": "noop_statement", "macro_sql": "{% macro noop_statement(name=None, status=None, res=None) -%}\n  {%- set sql = caller() -%}\n\n  {%- if name == 'main' -%}\n    {{ log('Writing runtime SQL for node \"{}\"'.format(model['unique_id'])) }}\n    {{ write(sql) }}\n  {%- endif -%}\n\n  {%- if name is not none -%}\n    {{ store_result(name, status=status, agate_table=res) }}\n  {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_columns_in_query": {"unique_id": "macro.dbt.get_columns_in_query", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "get_columns_in_query", "macro_sql": "{% macro get_columns_in_query(select_sql) -%}\n  {{ return(adapter.dispatch('get_columns_in_query')(select_sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_columns_in_query": {"unique_id": "macro.dbt.default__get_columns_in_query", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__get_columns_in_query", "macro_sql": "{% macro default__get_columns_in_query(select_sql) %}\n    {% call statement('get_columns_in_query', fetch_result=True, auto_begin=False) -%}\n        select * from (\n            {{ select_sql }}\n        ) as __dbt_sbq\n        where false\n        limit 0\n    {% endcall %}\n\n    {{ return(load_result('get_columns_in_query').table.columns | map(attribute='name') | list) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.create_schema": {"unique_id": "macro.dbt.create_schema", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "create_schema", "macro_sql": "{% macro create_schema(relation) -%}\n  {{ adapter.dispatch('create_schema')(relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_schema": {"unique_id": "macro.dbt.default__create_schema", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__create_schema", "macro_sql": "{% macro default__create_schema(relation) -%}\n  {%- call statement('create_schema') -%}\n    create schema if not exists {{ relation.without_identifier() }}\n  {% endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.drop_schema": {"unique_id": "macro.dbt.drop_schema", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "drop_schema", "macro_sql": "{% macro drop_schema(relation) -%}\n  {{ adapter.dispatch('drop_schema')(relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__drop_schema": {"unique_id": "macro.dbt.default__drop_schema", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__drop_schema", "macro_sql": "{% macro default__drop_schema(relation) -%}\n  {%- call statement('drop_schema') -%}\n    drop schema if exists {{ relation.without_identifier() }} cascade\n  {% endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.create_table_as": {"unique_id": "macro.dbt.create_table_as", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "create_table_as", "macro_sql": "{% macro create_table_as(temporary, relation, sql) -%}\n  {{ adapter.dispatch('create_table_as')(temporary, relation, sql) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_table_as": {"unique_id": "macro.dbt.default__create_table_as", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__create_table_as", "macro_sql": "{% macro default__create_table_as(temporary, relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n\n  create {% if temporary: -%}temporary{%- endif %} table\n    {{ relation.include(database=(not temporary), schema=(not temporary)) }}\n  as (\n    {{ sql }}\n  );\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.create_view_as": {"unique_id": "macro.dbt.create_view_as", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "create_view_as", "macro_sql": "{% macro create_view_as(relation, sql) -%}\n  {{ adapter.dispatch('create_view_as')(relation, sql) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_view_as": {"unique_id": "macro.dbt.default__create_view_as", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__create_view_as", "macro_sql": "{% macro default__create_view_as(relation, sql) -%}\n  {%- set sql_header = config.get('sql_header', none) -%}\n\n  {{ sql_header if sql_header is not none }}\n  create view {{ relation }} as (\n    {{ sql }}\n  );\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_catalog": {"unique_id": "macro.dbt.get_catalog", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "get_catalog", "macro_sql": "{% macro get_catalog(information_schema, schemas) -%}\n  {{ return(adapter.dispatch('get_catalog')(information_schema, schemas)) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_snowflake.snowflake__get_catalog"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_catalog": {"unique_id": "macro.dbt.default__get_catalog", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__get_catalog", "macro_sql": "{% macro default__get_catalog(information_schema, schemas) -%}\n\n  {% set typename = adapter.type() %}\n  {% set msg -%}\n    get_catalog not implemented for {{ typename }}\n  {%- endset %}\n\n  {{ exceptions.raise_compiler_error(msg) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_columns_in_relation": {"unique_id": "macro.dbt.get_columns_in_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "get_columns_in_relation", "macro_sql": "{% macro get_columns_in_relation(relation) -%}\n  {{ return(adapter.dispatch('get_columns_in_relation')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_snowflake.snowflake__get_columns_in_relation"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.sql_convert_columns_in_relation": {"unique_id": "macro.dbt.sql_convert_columns_in_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "sql_convert_columns_in_relation", "macro_sql": "{% macro sql_convert_columns_in_relation(table) -%}\n  {% set columns = [] %}\n  {% for row in table %}\n    {% do columns.append(api.Column(*row)) %}\n  {% endfor %}\n  {{ return(columns) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_columns_in_relation": {"unique_id": "macro.dbt.default__get_columns_in_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__get_columns_in_relation", "macro_sql": "{% macro default__get_columns_in_relation(relation) -%}\n  {{ exceptions.raise_not_implemented(\n    'get_columns_in_relation macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.alter_column_type": {"unique_id": "macro.dbt.alter_column_type", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "alter_column_type", "macro_sql": "{% macro alter_column_type(relation, column_name, new_column_type) -%}\n  {{ return(adapter.dispatch('alter_column_type')(relation, column_name, new_column_type)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.alter_column_comment": {"unique_id": "macro.dbt.alter_column_comment", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "alter_column_comment", "macro_sql": "{% macro alter_column_comment(relation, column_dict) -%}\n  {{ return(adapter.dispatch('alter_column_comment')(relation, column_dict)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__alter_column_comment": {"unique_id": "macro.dbt.default__alter_column_comment", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__alter_column_comment", "macro_sql": "{% macro default__alter_column_comment(relation, column_dict) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_column_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.alter_relation_comment": {"unique_id": "macro.dbt.alter_relation_comment", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "alter_relation_comment", "macro_sql": "{% macro alter_relation_comment(relation, relation_comment) -%}\n  {{ return(adapter.dispatch('alter_relation_comment')(relation, relation_comment)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__alter_relation_comment": {"unique_id": "macro.dbt.default__alter_relation_comment", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__alter_relation_comment", "macro_sql": "{% macro default__alter_relation_comment(relation, relation_comment) -%}\n  {{ exceptions.raise_not_implemented(\n    'alter_relation_comment macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.persist_docs": {"unique_id": "macro.dbt.persist_docs", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "persist_docs", "macro_sql": "{% macro persist_docs(relation, model, for_relation=true, for_columns=true) -%}\n  {{ return(adapter.dispatch('persist_docs')(relation, model, for_relation, for_columns)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__persist_docs": {"unique_id": "macro.dbt.default__persist_docs", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__persist_docs", "macro_sql": "{% macro default__persist_docs(relation, model, for_relation, for_columns) -%}\n  {% if for_relation and config.persist_relation_docs() and model.description %}\n    {% do run_query(alter_relation_comment(relation, model.description)) %}\n  {% endif %}\n\n  {% if for_columns and config.persist_column_docs() and model.columns %}\n    {% do run_query(alter_column_comment(relation, model.columns)) %}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__alter_column_type": {"unique_id": "macro.dbt.default__alter_column_type", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__alter_column_type", "macro_sql": "{% macro default__alter_column_type(relation, column_name, new_column_type) -%}\n  {#\n    1. Create a new column (w/ temp name and correct type)\n    2. Copy data over to it\n    3. Drop the existing column (cascade!)\n    4. Rename the new column to existing column\n  #}\n  {%- set tmp_column = column_name + \"__dbt_alter\" -%}\n\n  {% call statement('alter_column_type') %}\n    alter table {{ relation }} add column {{ adapter.quote(tmp_column) }} {{ new_column_type }};\n    update {{ relation }} set {{ adapter.quote(tmp_column) }} = {{ adapter.quote(column_name) }};\n    alter table {{ relation }} drop column {{ adapter.quote(column_name) }} cascade;\n    alter table {{ relation }} rename column {{ adapter.quote(tmp_column) }} to {{ adapter.quote(column_name) }}\n  {% endcall %}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.drop_relation": {"unique_id": "macro.dbt.drop_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "drop_relation", "macro_sql": "{% macro drop_relation(relation) -%}\n  {{ return(adapter.dispatch('drop_relation')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__drop_relation": {"unique_id": "macro.dbt.default__drop_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__drop_relation", "macro_sql": "{% macro default__drop_relation(relation) -%}\n  {% call statement('drop_relation', auto_begin=False) -%}\n    drop {{ relation.type }} if exists {{ relation }} cascade\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.truncate_relation": {"unique_id": "macro.dbt.truncate_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "truncate_relation", "macro_sql": "{% macro truncate_relation(relation) -%}\n  {{ return(adapter.dispatch('truncate_relation')(relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__truncate_relation": {"unique_id": "macro.dbt.default__truncate_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__truncate_relation", "macro_sql": "{% macro default__truncate_relation(relation) -%}\n  {% call statement('truncate_relation') -%}\n    truncate table {{ relation }}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.rename_relation": {"unique_id": "macro.dbt.rename_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "rename_relation", "macro_sql": "{% macro rename_relation(from_relation, to_relation) -%}\n  {{ return(adapter.dispatch('rename_relation')(from_relation, to_relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__rename_relation": {"unique_id": "macro.dbt.default__rename_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__rename_relation", "macro_sql": "{% macro default__rename_relation(from_relation, to_relation) -%}\n  {% set target_name = adapter.quote_as_configured(to_relation.identifier, 'identifier') %}\n  {% call statement('rename_relation') -%}\n    alter table {{ from_relation }} rename to {{ target_name }}\n  {%- endcall %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.information_schema_name": {"unique_id": "macro.dbt.information_schema_name", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "information_schema_name", "macro_sql": "{% macro information_schema_name(database) %}\n  {{ return(adapter.dispatch('information_schema_name')(database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__information_schema_name": {"unique_id": "macro.dbt.default__information_schema_name", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__information_schema_name", "macro_sql": "{% macro default__information_schema_name(database) -%}\n  {%- if database -%}\n    {{ database }}.INFORMATION_SCHEMA\n  {%- else -%}\n    INFORMATION_SCHEMA\n  {%- endif -%}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.list_schemas": {"unique_id": "macro.dbt.list_schemas", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "list_schemas", "macro_sql": "{% macro list_schemas(database) -%}\n  {{ return(adapter.dispatch('list_schemas')(database)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__list_schemas": {"unique_id": "macro.dbt.default__list_schemas", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__list_schemas", "macro_sql": "{% macro default__list_schemas(database) -%}\n  {% set sql %}\n    select distinct schema_name\n    from {{ information_schema_name(database) }}.SCHEMATA\n    where catalog_name ilike '{{ database }}'\n  {% endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.check_schema_exists": {"unique_id": "macro.dbt.check_schema_exists", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "check_schema_exists", "macro_sql": "{% macro check_schema_exists(information_schema, schema) -%}\n  {{ return(adapter.dispatch('check_schema_exists')(information_schema, schema)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__check_schema_exists": {"unique_id": "macro.dbt.default__check_schema_exists", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__check_schema_exists", "macro_sql": "{% macro default__check_schema_exists(information_schema, schema) -%}\n  {% set sql -%}\n        select count(*)\n        from {{ information_schema.replace(information_schema_view='SCHEMATA') }}\n        where catalog_name='{{ information_schema.database }}'\n          and schema_name='{{ schema }}'\n  {%- endset %}\n  {{ return(run_query(sql)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.list_relations_without_caching": {"unique_id": "macro.dbt.list_relations_without_caching", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "list_relations_without_caching", "macro_sql": "{% macro list_relations_without_caching(schema_relation) %}\n  {{ return(adapter.dispatch('list_relations_without_caching')(schema_relation)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt_snowflake.snowflake__list_relations_without_caching"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__list_relations_without_caching": {"unique_id": "macro.dbt.default__list_relations_without_caching", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__list_relations_without_caching", "macro_sql": "{% macro default__list_relations_without_caching(schema_relation) %}\n  {{ exceptions.raise_not_implemented(\n    'list_relations_without_caching macro not implemented for adapter '+adapter.type()) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.current_timestamp": {"unique_id": "macro.dbt.current_timestamp", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() -%}\n  {{ adapter.dispatch('current_timestamp')() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__current_timestamp": {"unique_id": "macro.dbt.default__current_timestamp", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() -%}\n  {{ exceptions.raise_not_implemented(\n    'current_timestamp macro not implemented for adapter '+adapter.type()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.collect_freshness": {"unique_id": "macro.dbt.collect_freshness", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "collect_freshness", "macro_sql": "{% macro collect_freshness(source, loaded_at_field, filter) %}\n  {{ return(adapter.dispatch('collect_freshness')(source, loaded_at_field, filter))}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__collect_freshness": {"unique_id": "macro.dbt.default__collect_freshness", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__collect_freshness", "macro_sql": "{% macro default__collect_freshness(source, loaded_at_field, filter) %}\n  {% call statement('collect_freshness', fetch_result=True, auto_begin=False) -%}\n    select\n      max({{ loaded_at_field }}) as max_loaded_at,\n      {{ current_timestamp() }} as snapshotted_at\n    from {{ source }}\n    {% if filter %}\n    where {{ filter }}\n    {% endif %}\n  {% endcall %}\n  {{ return(load_result('collect_freshness').table) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.make_temp_relation": {"unique_id": "macro.dbt.make_temp_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "make_temp_relation", "macro_sql": "{% macro make_temp_relation(base_relation, suffix='__dbt_tmp') %}\n  {{ return(adapter.dispatch('make_temp_relation')(base_relation, suffix))}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__make_temp_relation": {"unique_id": "macro.dbt.default__make_temp_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "default__make_temp_relation", "macro_sql": "{% macro default__make_temp_relation(base_relation, suffix) %}\n    {% set tmp_identifier = base_relation.identifier ~ suffix %}\n    {% set tmp_relation = base_relation.incorporate(\n                                path={\"identifier\": tmp_identifier}) -%}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.set_sql_header": {"unique_id": "macro.dbt.set_sql_header", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\adapters\\common.sql", "original_file_path": "macros\\adapters\\common.sql", "name": "set_sql_header", "macro_sql": "{% macro set_sql_header(config) -%}\n  {{ config.set('sql_header', caller()) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.convert_datetime": {"unique_id": "macro.dbt.convert_datetime", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\datetime.sql", "original_file_path": "macros\\etc\\datetime.sql", "name": "convert_datetime", "macro_sql": "{% macro convert_datetime(date_str, date_fmt) %}\n\n  {% set error_msg -%}\n      The provided partition date '{{ date_str }}' does not match the expected format '{{ date_fmt }}'\n  {%- endset %}\n\n  {% set res = try_or_compiler_error(error_msg, modules.datetime.datetime.strptime, date_str.strip(), date_fmt) %}\n  {{ return(res) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.dates_in_range": {"unique_id": "macro.dbt.dates_in_range", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\datetime.sql", "original_file_path": "macros\\etc\\datetime.sql", "name": "dates_in_range", "macro_sql": "{% macro dates_in_range(start_date_str, end_date_str=none, in_fmt=\"%Y%m%d\", out_fmt=\"%Y%m%d\") %}\n    {% set end_date_str = start_date_str if end_date_str is none else end_date_str %}\n\n    {% set start_date = convert_datetime(start_date_str, in_fmt) %}\n    {% set end_date = convert_datetime(end_date_str, in_fmt) %}\n\n    {% set day_count = (end_date - start_date).days %}\n    {% if day_count < 0 %}\n        {% set msg -%}\n            Partiton start date is after the end date ({{ start_date }}, {{ end_date }})\n        {%- endset %}\n\n        {{ exceptions.raise_compiler_error(msg, model) }}\n    {% endif %}\n\n    {% set date_list = [] %}\n    {% for i in range(0, day_count + 1) %}\n        {% set the_date = (modules.datetime.timedelta(days=i) + start_date) %}\n        {% if not out_fmt %}\n            {% set _ = date_list.append(the_date) %}\n        {% else %}\n            {% set _ = date_list.append(the_date.strftime(out_fmt)) %}\n        {% endif %}\n    {% endfor %}\n\n    {{ return(date_list) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.partition_range": {"unique_id": "macro.dbt.partition_range", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\datetime.sql", "original_file_path": "macros\\etc\\datetime.sql", "name": "partition_range", "macro_sql": "{% macro partition_range(raw_partition_date, date_fmt='%Y%m%d') %}\n    {% set partition_range = (raw_partition_date | string).split(\",\") %}\n\n    {% if (partition_range | length) == 1 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = none %}\n    {% elif (partition_range | length) == 2 %}\n      {% set start_date = partition_range[0] %}\n      {% set end_date = partition_range[1] %}\n    {% else %}\n      {{ exceptions.raise_compiler_error(\"Invalid partition time. Expected format: {Start Date}[,{End Date}]. Got: \" ~ raw_partition_date) }}\n    {% endif %}\n\n    {{ return(dates_in_range(start_date, end_date, in_fmt=date_fmt)) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.py_current_timestring": {"unique_id": "macro.dbt.py_current_timestring", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\datetime.sql", "original_file_path": "macros\\etc\\datetime.sql", "name": "py_current_timestring", "macro_sql": "{% macro py_current_timestring() %}\n    {% set dt = modules.datetime.datetime.now() %}\n    {% do return(dt.strftime(\"%Y%m%d%H%M%S%f\")) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.generate_alias_name": {"unique_id": "macro.dbt.generate_alias_name", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\get_custom_alias.sql", "original_file_path": "macros\\etc\\get_custom_alias.sql", "name": "generate_alias_name", "macro_sql": "{% macro generate_alias_name(custom_alias_name=none, node=none) -%}\n\n    {%- if custom_alias_name is none -%}\n\n        {{ node.name }}\n\n    {%- else -%}\n\n        {{ custom_alias_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.generate_database_name": {"unique_id": "macro.dbt.generate_database_name", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\get_custom_database.sql", "original_file_path": "macros\\etc\\get_custom_database.sql", "name": "generate_database_name", "macro_sql": "{% macro generate_database_name(custom_database_name=none, node=none) -%}\n    {% do return(adapter.dispatch('generate_database_name')(custom_database_name, node)) %}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": ["macro.dbt.default__generate_database_name"]}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__generate_database_name": {"unique_id": "macro.dbt.default__generate_database_name", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\get_custom_database.sql", "original_file_path": "macros\\etc\\get_custom_database.sql", "name": "default__generate_database_name", "macro_sql": "{% macro default__generate_database_name(custom_database_name=none, node=none) -%}\n    {%- set default_database = target.database -%}\n    {%- if custom_database_name is none -%}\n\n        {{ default_database }}\n\n    {%- else -%}\n\n        {{ custom_database_name }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.generate_schema_name": {"unique_id": "macro.dbt.generate_schema_name", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\get_custom_schema.sql", "original_file_path": "macros\\etc\\get_custom_schema.sql", "name": "generate_schema_name", "macro_sql": "{% macro generate_schema_name(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if custom_schema_name is none -%}\n\n        {{ default_schema }}\n\n    {%- else -%}\n\n        {{ default_schema }}_{{ custom_schema_name | trim }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.generate_schema_name_for_env": {"unique_id": "macro.dbt.generate_schema_name_for_env", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\get_custom_schema.sql", "original_file_path": "macros\\etc\\get_custom_schema.sql", "name": "generate_schema_name_for_env", "macro_sql": "{% macro generate_schema_name_for_env(custom_schema_name, node) -%}\n\n    {%- set default_schema = target.schema -%}\n    {%- if target.name == 'prod' and custom_schema_name is not none -%}\n\n        {{ custom_schema_name | trim }}\n\n    {%- else -%}\n\n        {{ default_schema }}\n\n    {%- endif -%}\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.is_incremental": {"unique_id": "macro.dbt.is_incremental", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\is_incremental.sql", "original_file_path": "macros\\etc\\is_incremental.sql", "name": "is_incremental", "macro_sql": "{% macro is_incremental() %}\n    {#-- do not run introspective queries in parsing #}\n    {% if not execute %}\n        {{ return(False) }}\n    {% else %}\n        {% set relation = adapter.get_relation(this.database, this.schema, this.table) %}\n        {{ return(relation is not none\n                  and relation.type == 'table'\n                  and model.config.materialized == 'incremental'\n                  and not should_full_refresh()) }}\n    {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.run_query": {"unique_id": "macro.dbt.run_query", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\etc\\query.sql", "original_file_path": "macros\\etc\\query.sql", "name": "run_query", "macro_sql": "{% macro run_query(sql) %}\n  {% call statement(\"run_query_statement\", fetch_result=true, auto_begin=false) %}\n    {{ sql }}\n  {% endcall %}\n\n  {% do return(load_result(\"run_query_statement\").table) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.run_hooks": {"unique_id": "macro.dbt.run_hooks", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "run_hooks", "macro_sql": "{% macro run_hooks(hooks, inside_transaction=True) %}\n  {% for hook in hooks | selectattr('transaction', 'equalto', inside_transaction)  %}\n    {% if not inside_transaction and loop.first %}\n      {% call statement(auto_begin=inside_transaction) %}\n        commit;\n      {% endcall %}\n    {% endif %}\n    {% set rendered = render(hook.get('sql')) | trim %}\n    {% if (rendered | length) > 0 %}\n      {% call statement(auto_begin=inside_transaction) %}\n        {{ rendered }}\n      {% endcall %}\n    {% endif %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.column_list": {"unique_id": "macro.dbt.column_list", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "column_list", "macro_sql": "{% macro column_list(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {% if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.column_list_for_create_table": {"unique_id": "macro.dbt.column_list_for_create_table", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "column_list_for_create_table", "macro_sql": "{% macro column_list_for_create_table(columns) %}\n  {%- for col in columns %}\n    {{ col.name }} {{ col.data_type }} {%- if not loop.last %},{% endif %}\n  {% endfor -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.make_hook_config": {"unique_id": "macro.dbt.make_hook_config", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "make_hook_config", "macro_sql": "{% macro make_hook_config(sql, inside_transaction) %}\n    {{ tojson({\"sql\": sql, \"transaction\": inside_transaction}) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.before_begin": {"unique_id": "macro.dbt.before_begin", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "before_begin", "macro_sql": "{% macro before_begin(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.in_transaction": {"unique_id": "macro.dbt.in_transaction", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "in_transaction", "macro_sql": "{% macro in_transaction(sql) %}\n    {{ make_hook_config(sql, inside_transaction=True) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.after_commit": {"unique_id": "macro.dbt.after_commit", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "after_commit", "macro_sql": "{% macro after_commit(sql) %}\n    {{ make_hook_config(sql, inside_transaction=False) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.drop_relation_if_exists": {"unique_id": "macro.dbt.drop_relation_if_exists", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "drop_relation_if_exists", "macro_sql": "{% macro drop_relation_if_exists(relation) %}\n  {% if relation is not none %}\n    {{ adapter.drop_relation(relation) }}\n  {% endif %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.load_relation": {"unique_id": "macro.dbt.load_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "load_relation", "macro_sql": "{% macro load_relation(relation) %}\n  {% do return(adapter.get_relation(\n    database=relation.database,\n    schema=relation.schema,\n    identifier=relation.identifier\n  )) -%}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.should_full_refresh": {"unique_id": "macro.dbt.should_full_refresh", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\helpers.sql", "original_file_path": "macros\\materializations\\helpers.sql", "name": "should_full_refresh", "macro_sql": "{% macro should_full_refresh() %}\n  {% set config_full_refresh = config.get('full_refresh') %}\n  {% if config_full_refresh is none %}\n    {% set config_full_refresh = flags.FULL_REFRESH %}\n  {% endif %}\n  {% do return(config_full_refresh) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_merge_sql": {"unique_id": "macro.dbt.get_merge_sql", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "get_merge_sql", "macro_sql": "{% macro get_merge_sql(target, source, unique_key, dest_columns, predicates=none) -%}\n  {{ adapter.dispatch('get_merge_sql')(target, source, unique_key, dest_columns, predicates) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_delete_insert_merge_sql": {"unique_id": "macro.dbt.get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "get_delete_insert_merge_sql", "macro_sql": "{% macro get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n  {{ adapter.dispatch('get_delete_insert_merge_sql')(target, source, unique_key, dest_columns) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_insert_overwrite_merge_sql": {"unique_id": "macro.dbt.get_insert_overwrite_merge_sql", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "get_insert_overwrite_merge_sql", "macro_sql": "{% macro get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header=false) -%}\n  {{ adapter.dispatch('get_insert_overwrite_merge_sql')(target, source, dest_columns, predicates, include_sql_header) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_merge_sql": {"unique_id": "macro.dbt.default__get_merge_sql", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "default__get_merge_sql", "macro_sql": "{% macro default__get_merge_sql(target, source, unique_key, dest_columns, predicates) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {% if unique_key %}\n        {% set unique_key_match %}\n            DBT_INTERNAL_SOURCE.{{ unique_key }} = DBT_INTERNAL_DEST.{{ unique_key }}\n        {% endset %}\n        {% do predicates.append(unique_key_match) %}\n    {% else %}\n        {% do predicates.append('FALSE') %}\n    {% endif %}\n\n    {{ sql_header if sql_header is not none }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on {{ predicates | join(' and ') }}\n\n    {% if unique_key %}\n    when matched then update set\n        {% for column in dest_columns -%}\n            {{ adapter.quote(column.name) }} = DBT_INTERNAL_SOURCE.{{ adapter.quote(column.name) }}\n            {%- if not loop.last %}, {%- endif %}\n        {%- endfor %}\n    {% endif %}\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_quoted_csv": {"unique_id": "macro.dbt.get_quoted_csv", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "get_quoted_csv", "macro_sql": "{% macro get_quoted_csv(column_names) %}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote(col)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.common_get_delete_insert_merge_sql": {"unique_id": "macro.dbt.common_get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "common_get_delete_insert_merge_sql", "macro_sql": "{% macro common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n\n    {% if unique_key is not none %}\n    delete from {{ target }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ source }}\n    );\n    {% endif %}\n\n    insert into {{ target }} ({{ dest_cols_csv }})\n    (\n        select {{ dest_cols_csv }}\n        from {{ source }}\n    );\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_delete_insert_merge_sql": {"unique_id": "macro.dbt.default__get_delete_insert_merge_sql", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "default__get_delete_insert_merge_sql", "macro_sql": "{% macro default__get_delete_insert_merge_sql(target, source, unique_key, dest_columns) -%}\n    {{ common_get_delete_insert_merge_sql(target, source, unique_key, dest_columns) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__get_insert_overwrite_merge_sql": {"unique_id": "macro.dbt.default__get_insert_overwrite_merge_sql", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\common\\merge.sql", "original_file_path": "macros\\materializations\\common\\merge.sql", "name": "default__get_insert_overwrite_merge_sql", "macro_sql": "{% macro default__get_insert_overwrite_merge_sql(target, source, dest_columns, predicates, include_sql_header) -%}\n    {%- set predicates = [] if predicates is none else [] + predicates -%}\n    {%- set dest_cols_csv = get_quoted_csv(dest_columns | map(attribute=\"name\")) -%}\n    {%- set sql_header = config.get('sql_header', none) -%}\n\n    {{ sql_header if sql_header is not none and include_sql_header }}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n        using {{ source }} as DBT_INTERNAL_SOURCE\n        on FALSE\n\n    when not matched by source\n        {% if predicates %} and {{ predicates | join(' and ') }} {% endif %}\n        then delete\n\n    when not matched then insert\n        ({{ dest_cols_csv }})\n    values\n        ({{ dest_cols_csv }})\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.incremental_upsert": {"unique_id": "macro.dbt.incremental_upsert", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\incremental\\helpers.sql", "original_file_path": "macros\\materializations\\incremental\\helpers.sql", "name": "incremental_upsert", "macro_sql": "{% macro incremental_upsert(tmp_relation, target_relation, unique_key=none, statement_name=\"main\") %}\n    {%- set dest_columns = adapter.get_columns_in_relation(target_relation) -%}\n    {%- set dest_cols_csv = dest_columns | map(attribute='quoted') | join(', ') -%}\n\n    {%- if unique_key is not none -%}\n    delete\n    from {{ target_relation }}\n    where ({{ unique_key }}) in (\n        select ({{ unique_key }})\n        from {{ tmp_relation }}\n    );\n    {%- endif %}\n\n    insert into {{ target_relation }} ({{ dest_cols_csv }})\n    (\n       select {{ dest_cols_csv }}\n       from {{ tmp_relation }}\n    );\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_incremental_default": {"unique_id": "macro.dbt.materialization_incremental_default", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\incremental\\incremental.sql", "original_file_path": "macros\\materializations\\incremental\\incremental.sql", "name": "materialization_incremental_default", "macro_sql": "{% materialization incremental, default -%}\n\n  {% set unique_key = config.get('unique_key') %}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {% set existing_relation = load_relation(this) %}\n  {% set tmp_relation = make_temp_relation(this) %}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set to_drop = [] %}\n  {% if existing_relation is none %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n  {% elif existing_relation.is_view or should_full_refresh() %}\n      {#-- Make sure the backup doesn't exist so we don't encounter issues with the rename below #}\n      {% set backup_identifier = existing_relation.identifier ~ \"__dbt_backup\" %}\n      {% set backup_relation = existing_relation.incorporate(path={\"identifier\": backup_identifier}) %}\n      {% do adapter.drop_relation(backup_relation) %}\n\n      {% do adapter.rename_relation(target_relation, backup_relation) %}\n      {% set build_sql = create_table_as(False, target_relation, sql) %}\n      {% do to_drop.append(backup_relation) %}\n  {% else %}\n      {% set tmp_relation = make_temp_relation(target_relation) %}\n      {% do run_query(create_table_as(True, tmp_relation, sql)) %}\n      {% do adapter.expand_target_column_types(\n             from_relation=tmp_relation,\n             to_relation=target_relation) %}\n      {% set build_sql = incremental_upsert(tmp_relation, target_relation, unique_key=unique_key) %}\n  {% endif %}\n\n  {% call statement(\"main\") %}\n      {{ build_sql }}\n  {% endcall %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {% do adapter.commit() %}\n\n  {% for rel in to_drop %}\n      {% do adapter.drop_relation(rel) %}\n  {% endfor %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.create_csv_table": {"unique_id": "macro.dbt.create_csv_table", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "create_csv_table", "macro_sql": "{% macro create_csv_table(model, agate_table) -%}\n  {{ adapter.dispatch('create_csv_table')(model, agate_table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.reset_csv_table": {"unique_id": "macro.dbt.reset_csv_table", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "reset_csv_table", "macro_sql": "{% macro reset_csv_table(model, full_refresh, old_relation, agate_table) -%}\n  {{ adapter.dispatch('reset_csv_table')(model, full_refresh, old_relation, agate_table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.load_csv_rows": {"unique_id": "macro.dbt.load_csv_rows", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "load_csv_rows", "macro_sql": "{% macro load_csv_rows(model, agate_table) -%}\n  {{ adapter.dispatch('load_csv_rows')(model, agate_table) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_csv_table": {"unique_id": "macro.dbt.default__create_csv_table", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "default__create_csv_table", "macro_sql": "{% macro default__create_csv_table(model, agate_table) %}\n  {%- set column_override = model['config'].get('column_types', {}) -%}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n\n  {% set sql %}\n    create table {{ this.render() }} (\n        {%- for col_name in agate_table.column_names -%}\n            {%- set inferred_type = adapter.convert_type(agate_table, loop.index0) -%}\n            {%- set type = column_override.get(col_name, inferred_type) -%}\n            {%- set column_name = (col_name | string) -%}\n            {{ adapter.quote_seed_column(column_name, quote_seed_column) }} {{ type }} {%- if not loop.last -%}, {%- endif -%}\n        {%- endfor -%}\n    )\n  {% endset %}\n\n  {% call statement('_') -%}\n    {{ sql }}\n  {%- endcall %}\n\n  {{ return(sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__reset_csv_table": {"unique_id": "macro.dbt.default__reset_csv_table", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "default__reset_csv_table", "macro_sql": "{% macro default__reset_csv_table(model, full_refresh, old_relation, agate_table) %}\n    {% set sql = \"\" %}\n    {% if full_refresh %}\n        {{ adapter.drop_relation(old_relation) }}\n        {% set sql = create_csv_table(model, agate_table) %}\n    {% else %}\n        {{ adapter.truncate_relation(old_relation) }}\n        {% set sql = \"truncate table \" ~ old_relation %}\n    {% endif %}\n\n    {{ return(sql) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_seed_column_quoted_csv": {"unique_id": "macro.dbt.get_seed_column_quoted_csv", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "get_seed_column_quoted_csv", "macro_sql": "{% macro get_seed_column_quoted_csv(model, column_names) %}\n  {%- set quote_seed_column = model['config'].get('quote_columns', None) -%}\n    {% set quoted = [] %}\n    {% for col in column_names -%}\n        {%- do quoted.append(adapter.quote_seed_column(col, quote_seed_column)) -%}\n    {%- endfor %}\n\n    {%- set dest_cols_csv = quoted | join(', ') -%}\n    {{ return(dest_cols_csv) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.basic_load_csv_rows": {"unique_id": "macro.dbt.basic_load_csv_rows", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "basic_load_csv_rows", "macro_sql": "{% macro basic_load_csv_rows(model, batch_size, agate_table) %}\n    {% set cols_sql = get_seed_column_quoted_csv(model, agate_table.column_names) %}\n    {% set bindings = [] %}\n\n    {% set statements = [] %}\n\n    {% for chunk in agate_table.rows | batch(batch_size) %}\n        {% set bindings = [] %}\n\n        {% for row in chunk %}\n            {% do bindings.extend(row) %}\n        {% endfor %}\n\n        {% set sql %}\n            insert into {{ this.render() }} ({{ cols_sql }}) values\n            {% for row in chunk -%}\n                ({%- for column in agate_table.column_names -%}\n                    %s\n                    {%- if not loop.last%},{%- endif %}\n                {%- endfor -%})\n                {%- if not loop.last%},{%- endif %}\n            {%- endfor %}\n        {% endset %}\n\n        {% do adapter.add_query(sql, bindings=bindings, abridge_sql_log=True) %}\n\n        {% if loop.index0 == 0 %}\n            {% do statements.append(sql) %}\n        {% endif %}\n    {% endfor %}\n\n    {# Return SQL so we can render it out into the compiled files #}\n    {{ return(statements[0]) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__load_csv_rows": {"unique_id": "macro.dbt.default__load_csv_rows", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "default__load_csv_rows", "macro_sql": "{% macro default__load_csv_rows(model, agate_table) %}\n  {{ return(basic_load_csv_rows(model, 10000, agate_table) )}}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_seed_default": {"unique_id": "macro.dbt.materialization_seed_default", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\seed\\seed.sql", "original_file_path": "macros\\materializations\\seed\\seed.sql", "name": "materialization_seed_default", "macro_sql": "{% materialization seed, default %}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set full_refresh_mode = (should_full_refresh()) -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set agate_table = load_agate_table() -%}\n  {%- do store_result('agate_table', status='OK', agate_table=agate_table) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% set create_table_sql = \"\" %}\n  {% if exists_as_view %}\n    {{ exceptions.raise_compiler_error(\"Cannot seed to '{}', it is a view\".format(old_relation)) }}\n  {% elif exists_as_table %}\n    {% set create_table_sql = reset_csv_table(model, full_refresh_mode, old_relation, agate_table) %}\n  {% else %}\n    {% set create_table_sql = create_csv_table(model, agate_table) %}\n  {% endif %}\n\n  {% set status = 'CREATE' if full_refresh_mode else 'INSERT' %}\n  {% set num_rows = (agate_table.rows | length) %}\n  {% set sql = load_csv_rows(model, agate_table) %}\n\n  {% call noop_statement('main', status ~ ' ' ~ num_rows) %}\n    {{ create_table_sql }};\n    -- dbt seed --\n    {{ sql }}\n  {% endcall %}\n\n  {% set target_relation = this.incorporate(type='table') %}\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.create_columns": {"unique_id": "macro.dbt.create_columns", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "create_columns", "macro_sql": "{% macro create_columns(relation, columns) %}\n  {{ adapter.dispatch('create_columns')(relation, columns) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__create_columns": {"unique_id": "macro.dbt.default__create_columns", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "default__create_columns", "macro_sql": "{% macro default__create_columns(relation, columns) %}\n  {% for column in columns %}\n    {% call statement() %}\n      alter table {{ relation }} add column \"{{ column.name }}\" {{ column.data_type }};\n    {% endcall %}\n  {% endfor %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.post_snapshot": {"unique_id": "macro.dbt.post_snapshot", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "post_snapshot", "macro_sql": "{% macro post_snapshot(staging_relation) %}\n  {{ adapter.dispatch('post_snapshot')(staging_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__post_snapshot": {"unique_id": "macro.dbt.default__post_snapshot", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "default__post_snapshot", "macro_sql": "{% macro default__post_snapshot(staging_relation) %}\n    {# no-op #}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_staging_table": {"unique_id": "macro.dbt.snapshot_staging_table", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "snapshot_staging_table", "macro_sql": "{% macro snapshot_staging_table(strategy, source_sql, target_relation) -%}\n\n    with snapshot_query as (\n\n        {{ source_sql }}\n\n    ),\n\n    snapshotted_data as (\n\n        select *,\n            {{ strategy.unique_key }} as dbt_unique_key\n\n        from {{ target_relation }}\n\n    ),\n\n    insertions_source_data as (\n\n        select\n            *,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to,\n            {{ strategy.scd_id }} as dbt_scd_id\n\n        from snapshot_query\n    ),\n\n    updates_source_data as (\n\n        select\n            *,\n            {{ strategy.unique_key }} as dbt_unique_key,\n            {{ strategy.updated_at }} as dbt_updated_at,\n            {{ strategy.updated_at }} as dbt_valid_from,\n            {{ strategy.updated_at }} as dbt_valid_to\n\n        from snapshot_query\n    ),\n\n    insertions as (\n\n        select\n            'insert' as dbt_change_type,\n            source_data.*\n\n        from insertions_source_data as source_data\n        left outer join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_unique_key is null\n           or (\n                snapshotted_data.dbt_unique_key is not null\n            and snapshotted_data.dbt_valid_to is null\n            and (\n                {{ strategy.row_changed }}\n            )\n        )\n\n    ),\n\n    updates as (\n\n        select\n            'update' as dbt_change_type,\n            source_data.*,\n            snapshotted_data.dbt_scd_id\n\n        from updates_source_data as source_data\n        join snapshotted_data on snapshotted_data.dbt_unique_key = source_data.dbt_unique_key\n        where snapshotted_data.dbt_valid_to is null\n        and (\n            {{ strategy.row_changed }}\n        )\n    )\n\n    select * from insertions\n    union all\n    select * from updates\n\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.build_snapshot_table": {"unique_id": "macro.dbt.build_snapshot_table", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "build_snapshot_table", "macro_sql": "{% macro build_snapshot_table(strategy, sql) %}\n\n    select *,\n        {{ strategy.scd_id }} as dbt_scd_id,\n        {{ strategy.updated_at }} as dbt_updated_at,\n        {{ strategy.updated_at }} as dbt_valid_from,\n        nullif({{ strategy.updated_at }}, {{ strategy.updated_at }}) as dbt_valid_to\n    from (\n        {{ sql }}\n    ) sbq\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.get_or_create_relation": {"unique_id": "macro.dbt.get_or_create_relation", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "get_or_create_relation", "macro_sql": "{% macro get_or_create_relation(database, schema, identifier, type) %}\n  {%- set target_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) %}\n\n  {% if target_relation %}\n    {% do return([true, target_relation]) %}\n  {% endif %}\n\n  {%- set new_relation = api.Relation.create(\n      database=database,\n      schema=schema,\n      identifier=identifier,\n      type=type\n  ) -%}\n  {% do return([false, new_relation]) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.build_snapshot_staging_table": {"unique_id": "macro.dbt.build_snapshot_staging_table", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "build_snapshot_staging_table", "macro_sql": "{% macro build_snapshot_staging_table(strategy, sql, target_relation) %}\n    {% set tmp_relation = make_temp_relation(target_relation) %}\n\n    {% set select = snapshot_staging_table(strategy, sql, target_relation) %}\n\n    {% call statement('build_snapshot_staging_relation') %}\n        {{ create_table_as(True, tmp_relation, select) }}\n    {% endcall %}\n\n    {% do return(tmp_relation) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_snapshot_default": {"unique_id": "macro.dbt.materialization_snapshot_default", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot.sql", "name": "materialization_snapshot_default", "macro_sql": "{% materialization snapshot, default %}\n  {%- set config = model['config'] -%}\n\n  {%- set target_table = model.get('alias', model.get('name')) -%}\n\n  {%- set strategy_name = config.get('strategy') -%}\n  {%- set unique_key = config.get('unique_key') %}\n\n  {% if not adapter.check_schema_exists(model.database, model.schema) %}\n    {% do create_schema(model.database, model.schema) %}\n  {% endif %}\n\n  {% set target_relation_exists, target_relation = get_or_create_relation(\n          database=model.database,\n          schema=model.schema,\n          identifier=target_table,\n          type='table') -%}\n\n  {%- if not target_relation.is_table -%}\n    {% do exceptions.relation_wrong_type(target_relation, 'table') %}\n  {%- endif -%}\n\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  {% set strategy_macro = strategy_dispatch(strategy_name) %}\n  {% set strategy = strategy_macro(model, \"snapshotted_data\", \"source_data\", config, target_relation_exists) %}\n\n  {% if not target_relation_exists %}\n\n      {% set build_sql = build_snapshot_table(strategy, model['injected_sql']) %}\n      {% set final_sql = create_table_as(False, target_relation, build_sql) %}\n\n  {% else %}\n\n      {{ adapter.valid_snapshot_target(target_relation) }}\n\n      {% set staging_table = build_snapshot_staging_table(strategy, sql, target_relation) %}\n\n      -- this may no-op if the database does not require column expansion\n      {% do adapter.expand_target_column_types(from_relation=staging_table,\n                                               to_relation=target_relation) %}\n\n      {% set missing_columns = adapter.get_missing_columns(staging_table, target_relation)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% do create_columns(target_relation, missing_columns) %}\n\n      {% set source_columns = adapter.get_columns_in_relation(staging_table)\n                                   | rejectattr('name', 'equalto', 'dbt_change_type')\n                                   | rejectattr('name', 'equalto', 'DBT_CHANGE_TYPE')\n                                   | rejectattr('name', 'equalto', 'dbt_unique_key')\n                                   | rejectattr('name', 'equalto', 'DBT_UNIQUE_KEY')\n                                   | list %}\n\n      {% set quoted_source_columns = [] %}\n      {% for column in source_columns %}\n        {% do quoted_source_columns.append(adapter.quote(column.name)) %}\n      {% endfor %}\n\n      {% set final_sql = snapshot_merge_sql(\n            target = target_relation,\n            source = staging_table,\n            insert_cols = quoted_source_columns\n         )\n      %}\n\n  {% endif %}\n\n  {% call statement('main') %}\n      {{ final_sql }}\n  {% endcall %}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if staging_table is defined %}\n      {% do post_snapshot(staging_table) %}\n  {% endif %}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_merge_sql": {"unique_id": "macro.dbt.snapshot_merge_sql", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot_merge.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot_merge.sql", "name": "snapshot_merge_sql", "macro_sql": "{% macro snapshot_merge_sql(target, source, insert_cols) -%}\n  {{ adapter.dispatch('snapshot_merge_sql')(target, source, insert_cols) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_merge_sql": {"unique_id": "macro.dbt.default__snapshot_merge_sql", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\snapshot_merge.sql", "original_file_path": "macros\\materializations\\snapshot\\snapshot_merge.sql", "name": "default__snapshot_merge_sql", "macro_sql": "{% macro default__snapshot_merge_sql(target, source, insert_cols) -%}\n    {%- set insert_cols_csv = insert_cols | join(', ') -%}\n\n    merge into {{ target }} as DBT_INTERNAL_DEST\n    using {{ source }} as DBT_INTERNAL_SOURCE\n    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id\n\n    when matched\n     and DBT_INTERNAL_DEST.dbt_valid_to is null\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'update'\n        then update\n        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to\n\n    when not matched\n     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'\n        then insert ({{ insert_cols_csv }})\n        values ({{ insert_cols_csv }})\n    ;\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.strategy_dispatch": {"unique_id": "macro.dbt.strategy_dispatch", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "strategy_dispatch", "macro_sql": "{% macro strategy_dispatch(name) -%}\n{% set original_name = name %}\n  {% if '.' in name %}\n    {% set package_name, name = name.split(\".\", 1) %}\n  {% else %}\n    {% set package_name = none %}\n  {% endif %}\n\n  {% if package_name is none %}\n    {% set package_context = context %}\n  {% elif package_name in context %}\n    {% set package_context = context[package_name] %}\n  {% else %}\n    {% set error_msg %}\n        Could not find package '{{package_name}}', called with '{{original_name}}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n\n  {%- set search_name = 'snapshot_' ~ name ~ '_strategy' -%}\n\n  {% if search_name not in package_context %}\n    {% set error_msg %}\n        The specified strategy macro '{{name}}' was not found in package '{{ package_name }}'\n    {% endset %}\n    {{ exceptions.raise_compiler_error(error_msg | trim) }}\n  {% endif %}\n  {{ return(package_context[search_name]) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_hash_arguments": {"unique_id": "macro.dbt.snapshot_hash_arguments", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "snapshot_hash_arguments", "macro_sql": "{% macro snapshot_hash_arguments(args) -%}\n  {{ adapter.dispatch('snapshot_hash_arguments')(args) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_hash_arguments": {"unique_id": "macro.dbt.default__snapshot_hash_arguments", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "default__snapshot_hash_arguments", "macro_sql": "{% macro default__snapshot_hash_arguments(args) -%}\n    md5({%- for arg in args -%}\n        coalesce(cast({{ arg }} as varchar ), '')\n        {% if not loop.last %} || '|' || {% endif %}\n    {%- endfor -%})\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_get_time": {"unique_id": "macro.dbt.snapshot_get_time", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "snapshot_get_time", "macro_sql": "{% macro snapshot_get_time() -%}\n  {{ adapter.dispatch('snapshot_get_time')() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_get_time": {"unique_id": "macro.dbt.default__snapshot_get_time", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "default__snapshot_get_time", "macro_sql": "{% macro default__snapshot_get_time() -%}\n  {{ current_timestamp() }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_timestamp_strategy": {"unique_id": "macro.dbt.snapshot_timestamp_strategy", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "snapshot_timestamp_strategy", "macro_sql": "{% macro snapshot_timestamp_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set primary_key = config['unique_key'] %}\n    {% set updated_at = config['updated_at'] %}\n\n    {#/*\n        The snapshot relation might not have an {{ updated_at }} value if the\n        snapshot strategy is changed from `check` to `timestamp`. We\n        should use a dbt-created column for the comparison in the snapshot\n        table instead of assuming that the user-supplied {{ updated_at }}\n        will be present in the historical data.\n\n        See https://github.com/fishtown-analytics/dbt/issues/2350\n    */ #}\n    {% set row_changed_expr -%}\n        ({{ snapshotted_rel }}.dbt_valid_from < {{ current_rel }}.{{ updated_at }})\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_string_as_time": {"unique_id": "macro.dbt.snapshot_string_as_time", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "snapshot_string_as_time", "macro_sql": "{% macro snapshot_string_as_time(timestamp) -%}\n    {{ adapter.dispatch('snapshot_string_as_time')(timestamp) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__snapshot_string_as_time": {"unique_id": "macro.dbt.default__snapshot_string_as_time", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "default__snapshot_string_as_time", "macro_sql": "{% macro default__snapshot_string_as_time(timestamp) %}\n    {% do exceptions.raise_not_implemented(\n        'snapshot_string_as_time macro not implemented for adapter '+adapter.type()\n    ) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_check_all_get_existing_columns": {"unique_id": "macro.dbt.snapshot_check_all_get_existing_columns", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "snapshot_check_all_get_existing_columns", "macro_sql": "{% macro snapshot_check_all_get_existing_columns(node, target_exists) -%}\n    {%- set query_columns = get_columns_in_query(node['injected_sql']) -%}\n    {%- if not target_exists -%}\n        {# no table yet -> return whatever the query does #}\n        {{ return([false, query_columns]) }}\n    {%- endif -%}\n    {# handle any schema changes #}\n    {%- set target_table = node.get('alias', node.get('name')) -%}\n    {%- set target_relation = adapter.get_relation(database=node.database, schema=node.schema, identifier=target_table) -%}\n    {%- set existing_cols = get_columns_in_query('select * from ' ~ target_relation) -%}\n    {%- set ns = namespace() -%} {# handle for-loop scoping with a namespace #}\n    {%- set ns.column_added = false -%}\n\n    {%- set intersection = [] -%}\n    {%- for col in query_columns -%}\n        {%- if col in existing_cols -%}\n            {%- do intersection.append(col) -%}\n        {%- else -%}\n            {% set ns.column_added = true %}\n        {%- endif -%}\n    {%- endfor -%}\n    {{ return([ns.column_added, intersection]) }}\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.snapshot_check_strategy": {"unique_id": "macro.dbt.snapshot_check_strategy", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\snapshot\\strategies.sql", "original_file_path": "macros\\materializations\\snapshot\\strategies.sql", "name": "snapshot_check_strategy", "macro_sql": "{% macro snapshot_check_strategy(node, snapshotted_rel, current_rel, config, target_exists) %}\n    {% set check_cols_config = config['check_cols'] %}\n    {% set primary_key = config['unique_key'] %}\n    {% set select_current_time -%}\n        select {{ snapshot_get_time() }} as snapshot_start\n    {%- endset %}\n\n    {#-- don't access the column by name, to avoid dealing with casing issues on snowflake #}\n    {%- set now = run_query(select_current_time)[0][0] -%}\n    {% if now is none or now is undefined -%}\n        {%- do exceptions.raise_compiler_error('Could not get a snapshot start time from the database') -%}\n    {%- endif %}\n    {% set updated_at = snapshot_string_as_time(now) %}\n\n    {% set column_added = false %}\n\n    {% if check_cols_config == 'all' %}\n        {% set column_added, check_cols = snapshot_check_all_get_existing_columns(node, target_exists) %}\n    {% elif check_cols_config is iterable and (check_cols_config | length) > 0 %}\n        {% set check_cols = check_cols_config %}\n    {% else %}\n        {% do exceptions.raise_compiler_error(\"Invalid value for 'check_cols': \" ~ check_cols_config) %}\n    {% endif %}\n\n    {%- set row_changed_expr -%}\n    (\n    {%- if column_added -%}\n        TRUE\n    {%- else -%}\n    {%- for col in check_cols -%}\n        {{ snapshotted_rel }}.{{ col }} != {{ current_rel }}.{{ col }}\n        or\n        ({{ snapshotted_rel }}.{{ col }} is null) != ({{ current_rel }}.{{ col }} is null)\n        {%- if not loop.last %} or {% endif -%}\n    {%- endfor -%}\n    {%- endif -%}\n    )\n    {%- endset %}\n\n    {% set scd_id_expr = snapshot_hash_arguments([primary_key, updated_at]) %}\n\n    {% do return({\n        \"unique_key\": primary_key,\n        \"updated_at\": updated_at,\n        \"row_changed\": row_changed_expr,\n        \"scd_id\": scd_id_expr\n    }) %}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_table_default": {"unique_id": "macro.dbt.materialization_table_default", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\table\\table.sql", "original_file_path": "macros\\materializations\\table\\table.sql", "name": "materialization_table_default", "macro_sql": "{% materialization table, default %}\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type='table') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema,\n                                                      database=database,\n                                                      type='table') -%}\n\n  /*\n      See ../view/view.sql for more information about this relation.\n  */\n  {%- set backup_relation_type = 'table' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema,\n                                                database=database,\n                                                type=backup_relation_type) -%}\n\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n\n  -- drop the temp relations if they exists for some reason\n  {{ adapter.drop_relation(intermediate_relation) }}\n  {{ adapter.drop_relation(backup_relation) }}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_table_as(False, intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  {% if old_relation is not none %}\n      {{ adapter.rename_relation(target_relation, backup_relation) }}\n  {% endif %}\n\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {% do persist_docs(target_relation, model) %}\n\n  -- `COMMIT` happens here\n  {{ adapter.commit() }}\n\n  -- finally, drop the existing/backup relation after the commit\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n{% endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.handle_existing_table": {"unique_id": "macro.dbt.handle_existing_table", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\view\\create_or_replace_view.sql", "original_file_path": "macros\\materializations\\view\\create_or_replace_view.sql", "name": "handle_existing_table", "macro_sql": "{% macro handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.dispatch(\"handle_existing_table\", packages=['dbt'])(full_refresh, old_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__handle_existing_table": {"unique_id": "macro.dbt.default__handle_existing_table", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\view\\create_or_replace_view.sql", "original_file_path": "macros\\materializations\\view\\create_or_replace_view.sql", "name": "default__handle_existing_table", "macro_sql": "{% macro default__handle_existing_table(full_refresh, old_relation) %}\n    {{ adapter.drop_relation(old_relation) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.create_or_replace_view": {"unique_id": "macro.dbt.create_or_replace_view", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\view\\create_or_replace_view.sql", "original_file_path": "macros\\materializations\\view\\create_or_replace_view.sql", "name": "create_or_replace_view", "macro_sql": "{% macro create_or_replace_view(run_outside_transaction_hooks=True) %}\n  {%- set identifier = model['alias'] -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {%- set target_relation = api.Relation.create(\n      identifier=identifier, schema=schema, database=database,\n      type='view') -%}\n\n  {% if run_outside_transaction_hooks %}\n      -- no transactions on BigQuery\n      {{ run_hooks(pre_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  -- `BEGIN` happens here on Snowflake\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- If there's a table with the same name and we weren't told to full refresh,\n  -- that's an error. If we were told to full refresh, drop it. This behavior differs\n  -- for Snowflake and BigQuery, so multiple dispatch is used.\n  {%- if old_relation is not none and old_relation.is_table -%}\n    {{ handle_existing_table(should_full_refresh(), old_relation) }}\n  {%- endif -%}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(target_relation, sql) }}\n  {%- endcall %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {% if run_outside_transaction_hooks %}\n      -- No transactions on BigQuery\n      {{ run_hooks(post_hooks, inside_transaction=False) }}\n  {% endif %}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.materialization_view_default": {"unique_id": "macro.dbt.materialization_view_default", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\materializations\\view\\view.sql", "original_file_path": "macros\\materializations\\view\\view.sql", "name": "materialization_view_default", "macro_sql": "{%- materialization view, default -%}\n\n  {%- set identifier = model['alias'] -%}\n  {%- set tmp_identifier = model['name'] + '__dbt_tmp' -%}\n  {%- set backup_identifier = model['name'] + '__dbt_backup' -%}\n\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, database=database,\n                                                type='view') -%}\n  {%- set intermediate_relation = api.Relation.create(identifier=tmp_identifier,\n                                                      schema=schema, database=database, type='view') -%}\n\n  /*\n     This relation (probably) doesn't exist yet. If it does exist, it's a leftover from\n     a previous run, and we're going to try to drop it immediately. At the end of this\n     materialization, we're going to rename the \"old_relation\" to this identifier,\n     and then we're going to drop it. In order to make sure we run the correct one of:\n       - drop view ...\n       - drop table ...\n\n     We need to set the type of this relation to be the type of the old_relation, if it exists,\n     or else \"view\" as a sane default if it does not. Note that if the old_relation does not\n     exist, then there is nothing to move out of the way and subsequentally drop. In that case,\n     this relation will be effectively unused.\n  */\n  {%- set backup_relation_type = 'view' if old_relation is none else old_relation.type -%}\n  {%- set backup_relation = api.Relation.create(identifier=backup_identifier,\n                                                schema=schema, database=database,\n                                                type=backup_relation_type) -%}\n\n  {%- set exists_as_view = (old_relation is not none and old_relation.is_view) -%}\n\n  {{ run_hooks(pre_hooks, inside_transaction=False) }}\n\n  -- drop the temp relations if they exists for some reason\n  {{ adapter.drop_relation(intermediate_relation) }}\n  {{ adapter.drop_relation(backup_relation) }}\n\n  -- `BEGIN` happens here:\n  {{ run_hooks(pre_hooks, inside_transaction=True) }}\n\n  -- build model\n  {% call statement('main') -%}\n    {{ create_view_as(intermediate_relation, sql) }}\n  {%- endcall %}\n\n  -- cleanup\n  -- move the existing view out of the way\n  {% if old_relation is not none %}\n    {{ adapter.rename_relation(target_relation, backup_relation) }}\n  {% endif %}\n  {{ adapter.rename_relation(intermediate_relation, target_relation) }}\n\n  {% do persist_docs(target_relation, model) %}\n\n  {{ run_hooks(post_hooks, inside_transaction=True) }}\n\n  {{ adapter.commit() }}\n\n  {{ drop_relation_if_exists(backup_relation) }}\n\n  {{ run_hooks(post_hooks, inside_transaction=False) }}\n\n  {{ return({'relations': [target_relation]}) }}\n\n{%- endmaterialization -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__test_accepted_values": {"unique_id": "macro.dbt.default__test_accepted_values", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\accepted_values.sql", "original_file_path": "macros\\schema_tests\\accepted_values.sql", "name": "default__test_accepted_values", "macro_sql": "{% macro default__test_accepted_values(model, values) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('field')) %}\n{% set quote_values = kwargs.get('quote', True) %}\n\nwith all_values as (\n\n    select distinct\n        {{ column_name }} as value_field\n\n    from {{ model }}\n\n),\n\nvalidation_errors as (\n\n    select\n        value_field\n\n    from all_values\n    where value_field not in (\n        {% for value in values -%}\n            {% if quote_values -%}\n            '{{ value }}'\n            {%- else -%}\n            {{ value }}\n            {%- endif -%}\n            {%- if not loop.last -%},{%- endif %}\n        {%- endfor %}\n    )\n)\n\nselect count(*) as validation_errors\nfrom validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.test_accepted_values": {"unique_id": "macro.dbt.test_accepted_values", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\accepted_values.sql", "original_file_path": "macros\\schema_tests\\accepted_values.sql", "name": "test_accepted_values", "macro_sql": "{% macro test_accepted_values(model, values) %}\n    {% set macro = adapter.dispatch('test_accepted_values') %}\n    {{ macro(model, values, **kwargs) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__test_not_null": {"unique_id": "macro.dbt.default__test_not_null", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\not_null.sql", "original_file_path": "macros\\schema_tests\\not_null.sql", "name": "default__test_not_null", "macro_sql": "{% macro default__test_not_null(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*) as validation_errors\nfrom {{ model }}\nwhere {{ column_name }} is null\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.test_not_null": {"unique_id": "macro.dbt.test_not_null", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\not_null.sql", "original_file_path": "macros\\schema_tests\\not_null.sql", "name": "test_not_null", "macro_sql": "{% macro test_not_null(model) %}\n    {% set macro = adapter.dispatch('test_not_null') %}\n    {{ macro(model, **kwargs) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__test_relationships": {"unique_id": "macro.dbt.default__test_relationships", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\relationships.sql", "original_file_path": "macros\\schema_tests\\relationships.sql", "name": "default__test_relationships", "macro_sql": "{% macro default__test_relationships(model, to, field) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\n\n\nselect count(*) as validation_errors\nfrom (\n    select {{ column_name }} as id from {{ model }}\n) as child\nleft join (\n    select {{ field }} as id from {{ to }}\n) as parent on parent.id = child.id\nwhere child.id is not null\n  and parent.id is null\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.test_relationships": {"unique_id": "macro.dbt.test_relationships", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\relationships.sql", "original_file_path": "macros\\schema_tests\\relationships.sql", "name": "test_relationships", "macro_sql": "{% macro test_relationships(model, to, field) %}\n    {% set macro = adapter.dispatch('test_relationships') %}\n    {{ macro(model, to, field, **kwargs) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.default__test_unique": {"unique_id": "macro.dbt.default__test_unique", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\unique.sql", "original_file_path": "macros\\schema_tests\\unique.sql", "name": "default__test_unique", "macro_sql": "{% macro default__test_unique(model) %}\n\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\n\nselect count(*) as validation_errors\nfrom (\n\n    select\n        {{ column_name }}\n\n    from {{ model }}\n    where {{ column_name }} is not null\n    group by {{ column_name }}\n    having count(*) > 1\n\n) validation_errors\n\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt.test_unique": {"unique_id": "macro.dbt.test_unique", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "macros\\schema_tests\\unique.sql", "original_file_path": "macros\\schema_tests\\unique.sql", "name": "test_unique", "macro_sql": "{% macro test_unique(model) %}\n    {% set macro = adapter.dispatch('test_unique') %}\n    {{ macro(model, **kwargs) }}\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_ml_preprocessing.k_bins_discretizer": {"unique_id": "macro.dbt_ml_preprocessing.k_bins_discretizer", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\k_bins_discretizer.sql", "original_file_path": "macros\\k_bins_discretizer.sql", "name": "k_bins_discretizer", "macro_sql": "{% macro k_bins_discretizer(source_table,source_columns,include_columns='*',n_bins=20,encode='ordinal',strategy='uniform') %}\r\n{%- if encode!='ordinal' -%}\r\n    {% set error_message %}\r\nThe `k_bins_discretizer` macro only supports an 'encode' value of 'ordinal' at this time.\r\n    {% endset %}\r\n    {%- do exceptions.raise_compiler_error(error_message) -%}\r\n{%- endif -%}\r\n{%- if strategy!='uniform' -%}\r\n    {% set error_message %}\r\nThe `k_bins_discretizer` macro only supports an 'strategy' value of 'uniform' at this time.\r\n    {% endset %}\r\n    {%- do exceptions.raise_compiler_error(error_message) -%}\r\n{%- endif -%}\r\n{% if source_columns is not iterable or source_columns is string or source_columns is mapping %}\r\n    {% set error_message %}\r\nThe `source_columns` parameter must contain a list of column names.\r\n    {% endset %}\r\n    {%- do exceptions.raise_compiler_error(error_message) -%}\r\n{%- endif -%}\r\n{%- if include_columns=='*' -%}\r\n{%- set all_source_columns = adapter.get_columns_in_relation(source_table) | map(attribute='quoted') -%}\r\n{% set include_columns = all_source_columns %}\r\n{%- endif -%}\r\n\r\n-- generate a CTE for each source column, a single row containing the aggregates\r\nwith \r\n{% for source_column in source_columns %}\r\n    {{ source_column }}_aggregates as(\r\n        select\r\n            min({{ source_column }}) as min_value,\r\n            max({{ source_column }}) as max_value\r\n        from {{ source_table }}\r\n    )\r\n{% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\n{{ adapter.dispatch('k_bins_discretizer',packages=['dbt_ml_preprocessing'])(source_table,source_columns,include_columns,n_bins,encode,strategy) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Bin continuous data into intervals. See scikit-learn's [KBinsDiscretizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer) for full documentation.\n\nWill append a new column with the name &lt;source column&gt;_binned\n\nExample usage:\n#### **`models\\customer_features.yml:`**\n```\n{{ config(materialized='view') }}\n\n{{ dbt_ml_preprocessing.k_bins_discretizer( ref('customer') ,'age') }}\n\n```\nWill produce a model named customer_features, with a new column named ```age_binned``` containing the binned values.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\k_bins_discretizer.yml", "arguments": [{"name": "source_table", "type": "string", "description": "Pass in a ref to the table containing the data you want to transform"}, {"name": "source_columns", "type": "list", "description": "The columns containing the data you want to transform"}, {"name": "include_columns", "type": "string", "description": "Other columns from the source table to be included in the model (defaults to '*' and brings all columns across)"}, {"name": "n_bins", "type": "string", "description": "The number of bins to produce"}, {"name": "encode", "type": "string", "description": "The method used to encode the result, currently only 'ordinal' is supported"}, {"name": "strategy", "type": "string", "description": "Strategy used to define the widths of the bins, currently only 'uniform' is supported"}]}, "macro.dbt_ml_preprocessing.snowflake__k_bins_discretizer": {"unique_id": "macro.dbt_ml_preprocessing.snowflake__k_bins_discretizer", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\k_bins_discretizer.sql", "original_file_path": "macros\\k_bins_discretizer.sql", "name": "snowflake__k_bins_discretizer", "macro_sql": "{% macro snowflake__k_bins_discretizer(source_table,source_columns,include_columns,n_bins,encode,strategy) %}\r\nselect \r\n{% for column in include_columns %}\r\nsource_table.{{ column }},\r\n{% endfor %}\r\n\r\n{% for source_column in source_columns %}\r\n    least(width_bucket({{ source_column }},{{ source_column }}_aggregates.min_value,{{ source_column }}_aggregates.max_value,{{ n_bins }}) - 1,{{ n_bins - 1 }}) as {{ source_column }}_binned\r\n    {% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\nfrom \r\n  {% for source_column in source_columns %}\r\n      {{ source_column }}_aggregates,\r\n  {% endfor %}\r\n  {{ source_table }} as source_table\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\k_bins_discretizer.yml", "arguments": []}, "macro.dbt_ml_preprocessing.bigquery__k_bins_discretizer": {"unique_id": "macro.dbt_ml_preprocessing.bigquery__k_bins_discretizer", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\k_bins_discretizer.sql", "original_file_path": "macros\\k_bins_discretizer.sql", "name": "bigquery__k_bins_discretizer", "macro_sql": "{% macro bigquery__k_bins_discretizer(source_table,source_columns,include_columns,n_bins,encode,strategy) %}\r\nselect \r\n{% for column in include_columns %}\r\nsource_table.{{ column }},\r\n{% endfor %}\r\n\r\n{% for source_column in source_columns %}\r\n    least(RANGE_BUCKET({{ source_column }}, GENERATE_ARRAY({{ source_column }}_aggregates.min_value, {{ source_column }}_aggregates.max_value, ({{ source_column }}_aggregates.max_value - {{ source_column }}_aggregates.min_value)/{{ n_bins }}))-1,{{ n_bins - 1 }}) as {{ source_column }}_binned\r\n    {% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\nfrom \r\n  {% for source_column in source_columns %}\r\n      {{ source_column }}_aggregates,\r\n  {% endfor %}\r\n  {{ source_table }} as source_table\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\k_bins_discretizer.yml", "arguments": []}, "macro.dbt_ml_preprocessing.default__k_bins_discretizer": {"unique_id": "macro.dbt_ml_preprocessing.default__k_bins_discretizer", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\k_bins_discretizer.sql", "original_file_path": "macros\\k_bins_discretizer.sql", "name": "default__k_bins_discretizer", "macro_sql": "{% macro default__k_bins_discretizer(source_table,source_columns,include_columns,n_bins,encode,strategy) %}\r\nselect \r\n{% for column in include_columns %}\r\nsource_table.{{ column }},\r\n{% endfor %}\r\n{% for source_column in source_columns %}\r\nleast(\r\n      floor(\r\n          cast({{ source_column }} - {{ source_column }}_aggregates.min_value as decimal)/ cast( {{ source_column }}_aggregates.max_value - {{ source_column }}_aggregates.min_value as decimal ) * {{ n_bins }} \r\n      ),\r\n      {{ n_bins - 1 }}\r\n  ) as {{ source_column }}_binned\r\n    {% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\nfrom   \r\n  {% for source_column in source_columns %}\r\n      {{ source_column }}_aggregates,\r\n  {% endfor %}\r\n  {{ source_table }} as source_table\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\k_bins_discretizer.yml", "arguments": []}, "macro.dbt_ml_preprocessing.label_encoder": {"unique_id": "macro.dbt_ml_preprocessing.label_encoder", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\label_encoder.sql", "original_file_path": "macros\\label_encoder.sql", "name": "label_encoder", "macro_sql": "{% macro label_encoder(source_table,source_column, include_columns='*') %}\r\n{{ adapter.dispatch('label_encoder',packages=['dbt_ml_preprocessing'])(source_table,source_column,include_columns) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Encode target labels with value between 0 and n_classes-1. See scikit-learn's [LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder) for full documentation.\n\nWill append a new column with the name &lt;source column&gt;_encoded\n\nExample usage:\n#### **`models\\customer_features.yml:`**\n```\n{{ config(materialized='view') }}\n\n{{ dbt_ml_preprocessing.label_encoder( ref('customer') ,'city') }}\n\n```\nWill produce a model named customer_features, with a new column named ```city_encoded``` containing the encoded values.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\label_encoder.yml", "arguments": [{"name": "source_table", "type": "string", "description": "Pass in a ref to the table containing the data you want to transform"}, {"name": "source_column", "type": "string", "description": "The column containing the data you want to transform"}, {"name": "include_columns", "type": "string", "description": "Other columns from the source table to be included in the model (defaults to '*' and brings all columns across)"}]}, "macro.dbt_ml_preprocessing.default__label_encoder": {"unique_id": "macro.dbt_ml_preprocessing.default__label_encoder", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\label_encoder.sql", "original_file_path": "macros\\label_encoder.sql", "name": "default__label_encoder", "macro_sql": "{% macro default__label_encoder(source_table,source_column,include_columns) %}\r\nwith distinct_values as (\r\n    select array_agg(distinct {{ source_column }}) within group (order by {{ source_column }} asc) as all_values_array from {{ source_table }}\r\n)\r\nselect \r\n{% for column in include_columns %}\r\n{{ source_table }}.{{ column }},\r\n{% endfor %}\r\narray_position({{ source_column }}::variant,all_values_array) as {{ source_column }}_encoded\r\nfrom distinct_values,{{ source_table }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\label_encoder.yml", "arguments": []}, "macro.dbt_ml_preprocessing.bigquery__label_encoder": {"unique_id": "macro.dbt_ml_preprocessing.bigquery__label_encoder", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\label_encoder.sql", "original_file_path": "macros\\label_encoder.sql", "name": "bigquery__label_encoder", "macro_sql": "{% macro bigquery__label_encoder(source_table,source_column,include_columns) %}\r\nwith distinct_values as (\r\n    select array_agg(distinct {{ source_column }} order by {{ source_column }} asc) as all_values_array from {{ source_table }}\r\n),\r\ndistinct_values_unnested as (\r\nSELECT *\r\nFROM distinct_values\r\nCROSS JOIN UNNEST(distinct_values.all_values_array) AS element\r\nWITH OFFSET AS offset\r\nORDER BY offset\r\n)\r\nselect \r\n{% for column in include_columns %}\r\nsource_table.{{ column }},\r\n{% endfor %}\r\n(select offset from distinct_values_unnested where element={{ source_column }}) as {{ source_column }}_encoded\r\nfrom distinct_values,{{ source_table }} as source_table\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\label_encoder.yml", "arguments": []}, "macro.dbt_ml_preprocessing.redshift__label_encoder": {"unique_id": "macro.dbt_ml_preprocessing.redshift__label_encoder", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\label_encoder.sql", "original_file_path": "macros\\label_encoder.sql", "name": "redshift__label_encoder", "macro_sql": "{% macro redshift__label_encoder(source_table,source_column,include_columns) %}\r\nwith distinct_values as (\r\n    select distinct {{ source_column }} as distinct_value \r\n    from {{ source_table }}\r\n),\r\nnumbered_distinct_values as(\r\n  select distinct_value,\r\n  row_number() over (order by distinct_value) - 1 as row_num\r\n  from distinct_values)\r\nselect \r\n{% for column in include_columns %}\r\n{{ source_table }}.{{ column }},\r\n{% endfor %}\r\n(select row_num from numbered_distinct_values where distinct_value={{ source_column }}) as {{ source_column }}_encoded\r\nfrom {{ source_table }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\label_encoder.yml", "arguments": []}, "macro.dbt_ml_preprocessing.max_abs_scaler": {"unique_id": "macro.dbt_ml_preprocessing.max_abs_scaler", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\max_abs_scaler.sql", "original_file_path": "macros\\max_abs_scaler.sql", "name": "max_abs_scaler", "macro_sql": "{% macro max_abs_scaler(source_table,source_columns, include_columns='*') %}\r\n\r\n{% if source_columns is not iterable or source_columns is string or source_columns is mapping %}\r\n    {% set error_message %}\r\nThe `source_columns` parameter must contain a list of column names.\r\n    {% endset %}\r\n    {%- do exceptions.raise_compiler_error(error_message) -%}\r\n{%- endif -%}\r\n\r\n{%- if include_columns=='*' -%}\r\n{%- set all_source_columns = adapter.get_columns_in_relation(source_table) | map(attribute='quoted') -%}\r\n{% set include_columns = all_source_columns %}\r\n{%- endif -%}\r\n\r\n-- generate a CTE for each source column, a single row containing the aggregates\r\nwith \r\n{% for source_column in source_columns %}\r\n    {{ source_column }}_aggregates as(\r\n        select\r\n            max(abs({{ source_column }})) as max_abs_value\r\n        from {{ source_table }}\r\n    )\r\n{% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\n\r\nselect \r\n{% for column in include_columns %}\r\nsource_table.{{ column }},\r\n{% endfor %}\r\n{% for source_column in source_columns %}\r\n    {{ source_column }} / {{ source_column }}_aggregates.max_abs_value AS {{ source_column }}_scaled\r\n    {% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\n\r\nfrom \r\n    {% for source_column in source_columns %}\r\n        {{ source_column }}_aggregates,\r\n    {% endfor %}\r\n    {{ source_table }} as source_table\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Scale each feature by its maximum absolute value. See scikit-learn's [MaxAbsScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler) for full documentation.\n\nWill append a new column with the name &lt;source column&gt;_scaled\n\nExample usage:\n#### **`models\\customer_features.yml:`**\n```\n{{ config(materialized='view') }}\n\n{{ dbt_ml_preprocessing.max_abs_scaler( ref('customer') ,'age') }}\n\n```\nWill produce a model named customer_features, with a new column named ```age_scaled``` containing the encoded values.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\max_abs_scaler.yml", "arguments": [{"name": "source_table", "type": "string", "description": "Pass in a ref to the table containing the data you want to transform"}, {"name": "source_columns", "type": "list", "description": "The columns containing the data you want to transform"}, {"name": "include_columns", "type": "string", "description": "Other columns from the source table to be included in the model (defaults to '*' and brings all columns across)"}]}, "macro.dbt_ml_preprocessing.min_max_scaler": {"unique_id": "macro.dbt_ml_preprocessing.min_max_scaler", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\min_max_scaler.sql", "original_file_path": "macros\\min_max_scaler.sql", "name": "min_max_scaler", "macro_sql": "{% macro min_max_scaler(source_table,source_columns, include_columns='*') %}\r\n\r\n{% if source_columns is not iterable or source_columns is string or source_columns is mapping %}\r\n    {% set error_message %}\r\nThe `source_columns` parameter must contain a list of column names.\r\n    {% endset %}\r\n    {%- do exceptions.raise_compiler_error(error_message) -%}\r\n{%- endif -%}\r\n\r\n{%- if include_columns=='*' -%}\r\n{%- set all_source_columns = adapter.get_columns_in_relation(source_table) | map(attribute='quoted') -%}\r\n{% set include_columns = all_source_columns %}\r\n{%- endif -%}\r\n\r\n-- generate a CTE for each source column, a single row containing the aggregates\r\nwith \r\n{% for source_column in source_columns %}\r\n    {{ source_column }}_aggregates as(\r\n        select\r\n            min({{ source_column }}) as min_value,\r\n            max({{ source_column }}) as max_value\r\n        from {{ source_table }}\r\n    )\r\n{% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\n\r\nselect \r\n{% for column in include_columns %}\r\nsource_table.{{ column }},\r\n{% endfor %}\r\n{% for source_column in source_columns %}\r\n    ({{ source_column }} - {{ source_column }}_aggregates.min_value) / ({{ source_column }}_aggregates.max_value - {{ source_column }}_aggregates.min_value) AS {{ source_column }}_scaled\r\n    {% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\n\r\nfrom  \r\n    {% for source_column in source_columns %}\r\n        {{ source_column }}_aggregates,\r\n    {% endfor %}\r\n    {{ source_table }} as source_table\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Transform features by scaling each feature to a given range. See scikit-learn's [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler) for full documentation.\n\nWill append a new column with the name &lt;source column&gt;_scaled\n\nExample usage:\n#### **`models\\customer_features.yml:`**\n```\n{{ config(materialized='view') }}\n\n{{ dbt_ml_preprocessing.min_max_scaler( ref('customer') ,'age') }}\n\n```\nWill produce a model named customer_features, with a new column named ```age_scaled``` containing the encoded values.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\min_max_scaler.yml", "arguments": [{"name": "source_table", "type": "string", "description": "Pass in a ref to the table containing the data you want to transform"}, {"name": "source_columns", "type": "list", "description": "The columns containing the data you want to transform"}, {"name": "include_columns", "type": "string", "description": "Other columns from the source table to be included in the model (defaults to '*' and brings all columns across)"}]}, "macro.dbt_ml_preprocessing.normalizer": {"unique_id": "macro.dbt_ml_preprocessing.normalizer", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\normalizer.sql", "original_file_path": "macros\\normalizer.sql", "name": "normalizer", "macro_sql": "{% macro normalizer(source_table,source_columns, include_columns='*') %}\r\n{%- if include_columns=='*' -%}\r\n{%- set all_source_columns = adapter.get_columns_in_relation(source_table) | map(attribute='quoted') -%}\r\n{% set include_columns = all_source_columns %}\r\n{%- endif -%}\r\n\r\nwith magnitude_calcs as (\r\n    select \r\n        {% for column in include_columns %}\r\n        source_table.{{ column }},\r\n        {% endfor %}\r\n        SQRT(\r\n            {% for source_column in source_columns %}\r\n            {{ source_column }}*{{ source_column }}\r\n            {% if not loop.last %} + {% endif %}\r\n            {% endfor %}\r\n        ) as magnitude_calc\r\n    from {{ source_table }} as source_table\r\n)\r\nselect \r\n{% for source_column in source_columns %}\r\ncase magnitude_calc\r\n    when 0 then 0\r\n    else {{ source_column }}/magnitude_calc\r\n    end as {{ source_column }}_normalized\r\n{% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\nfrom magnitude_calcs\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Normalize samples individually to unit norm. See scikit-learn's [Normalizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer) for full documentation.\n\nWill append a new column with the name &lt;source column&gt;_normalized\n\nExample usage:\n#### **`models\\customer_features.yml:`**\n```\n{{ config(materialized='view') }}\n\n{{ dbt_ml_preprocessing.normalizer( ref('customer') ,'age') }}\n\n```\nWill produce a model named customer_features, with a new column named ```age_normalized``` containing the encoded values.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\normalizer.yml", "arguments": [{"name": "source_table", "type": "string", "description": "Pass in a ref to the table containing the data you want to transform"}, {"name": "source_columns", "type": "list", "description": "The columns containing the data you want to transform"}, {"name": "include_columns", "type": "string", "description": "Other columns from the source table to be included in the model (defaults to '*' and brings all columns across)"}]}, "macro.dbt_ml_preprocessing.one_hot_encoder": {"unique_id": "macro.dbt_ml_preprocessing.one_hot_encoder", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\one_hot_encoder.sql", "original_file_path": "macros\\one_hot_encoder.sql", "name": "one_hot_encoder", "macro_sql": "{% macro one_hot_encoder(source_table, source_column, categories='auto', handle_unknown='error',include_columns='*', exclude_columns=none) %}\r\n\r\n    {%- if categories=='auto' -%}\r\n        {% set category_values_query %}\r\n            select distinct\r\n                {{ source_column }}\r\n            from\r\n                {{ source_table }}\r\n            order by 1\r\n        {% endset %}\r\n        {% set results = run_query(category_values_query) %}\r\n        {% if execute %}\r\n            {# Return the first column #}\r\n            {% set category_values = results.columns[0].values() %}\r\n        {% else %}\r\n            {% set category_values = [] %}\r\n        {% endif %}\r\n    {% elif categories is not iterable or categories is string or categories is mapping %}\r\n        {% set error_message %}\r\n    The `categories` parameter must contain a list of category values.\r\n        {% endset %}\r\n        {%- do exceptions.raise_compiler_error(error_message) -%}\r\n    {%- else -%}\r\n        {% set category_values = categories %}\r\n    {%- endif -%}\r\n\r\n    {%- if handle_unknown!='ignore' and handle_unknown!='error' -%}\r\n        {% set error_message %}\r\n    The 'handle_unknown' parameter requires a value of either 'ignore' (when unknown value occurs, all output columns are false) or 'error' (when unknown value occurs, raise an error).\r\n        {% endset %}\r\n        {%- do exceptions.raise_compiler_error(error_message) -%}\r\n    {%- endif -%}\r\n\r\n    {%- if include_columns!='*' and exclude_columns is not none -%}\r\n        {% set error_message %}\r\n    If the 'exclude_columns' parameter is set, providing 'include_columns' is invalid and must be left at its default value.\r\n        {% endset %}\r\n        {%- do exceptions.raise_compiler_error(error_message) -%}\r\n    {%- endif -%}\r\n\r\n    {%- if exclude_columns is not none and (exclude_columns is not iterable or exclude_columns is string or exclude_columns is mapping) -%}\r\n        {% set error_message %}\r\n    The 'exclude_columns' parameter value contain a list of column names.\r\n        {% endset %}\r\n    {%- do exceptions.raise_compiler_error(error_message) -%}\r\n    {%- endif -%}\r\n\r\n    {%- if include_columns!='*' and (include_columns is not iterable or include_columns is string or include_columns is mapping) -%}\r\n        {% set error_message %}\r\n    The 'include_columns' parameter value must contain either the string '*' (for all columns in source), or a list of column names.\r\n        {% endset %}\r\n    {%- do exceptions.raise_compiler_error(error_message) -%}\r\n    {%- endif -%}\r\n\r\n    {{ adapter.dispatch('one_hot_encoder',packages=['dbt_ml_preprocessing'])(source_table, source_column, category_values, handle_unknown, include_columns, exclude_columns) }}\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Encode categorical features as a one-hot numeric array. See scikit-learn's [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder) for full documentation.\n\nWill append a new boolean column for every category present in the data with the name is_&lt;source column&gt;_&lt;category value&gt;.\n\nExample usage:\n#### **`models\\customer_features.yml:`**\n```\n{{ config(materialized='view') }}\n\n{{ dbt_ml_preprocessing.one_hot_encoder( ref('customer') ,'gender') }}\n\n```\nIf the column contained values 'male' and 'female, it will produce a model named customer_features with two new boolean columns named ```is_gender_male``` and ```is_gender_female```.\n\nAny spaces in the category values will be replaced with underscores, for ease of querying.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\one_hot_encoder.yml", "arguments": [{"name": "source_table", "type": "string", "description": "Pass in a ref to the table containing the data you want to transform"}, {"name": "source_column", "type": "string", "description": "The column containing the data you want to transform"}, {"name": "include_columns", "type": "string", "description": "Other columns from the source table to be included in the model (defaults to '*' and brings all columns across)"}, {"name": "exclude_columns", "type": "string", "description": "A list of columns from the source table to be excluded in the model. Cannot be used in conjunction with 'include_columns'"}, {"name": "categories", "type": "string", "description": "The categories of each feature determined during fitting. Defaults to 'auto', which will encode all values."}, {"name": "handle_unknown", "type": "string", "description": "Whether to raise an error or ignore if an unknown categorical feature is present during transform, defaults to 'error'. If 'ignore' is set and an unknown value is encountered, all output columns will be false."}]}, "macro.dbt_ml_preprocessing.default__one_hot_encoder": {"unique_id": "macro.dbt_ml_preprocessing.default__one_hot_encoder", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\one_hot_encoder.sql", "original_file_path": "macros\\one_hot_encoder.sql", "name": "default__one_hot_encoder", "macro_sql": "{% macro default__one_hot_encoder(source_table, source_column, category_values, handle_unknown, include_columns, exclude_columns) %}\r\n    {% set columns = adapter.get_columns_in_relation( source_table ) %}\r\n\r\n\r\n\r\n\r\n    with binary_output as (\r\n    select\r\n        {%- if include_columns=='*' and exclude_columns is none -%}\r\n            {% for column in columns %}\r\n                {{ column.name }},\r\n            {%- endfor -%}\r\n        {%- elif include_columns !='*'-%}\r\n            {% for column in include_columns %}\r\n                {{ source_table }}.{{ column }},\r\n            {%- endfor -%}\r\n        {%- else -%}\r\n            {% for column in columns %}\r\n            {%- if column.name | lower not in exclude_columns | lower %}\r\n                {{ column.name }},\r\n            {%- endif -%}\r\n            {%- endfor -%}\r\n        {%- endif -%}\r\n        {% for category in category_values %}\r\n            {% set no_whitespace_column_name = category | replace( \" \", \"_\") -%}\r\n                {%- if handle_unknown=='ignore' %}\r\n                    case \r\n                        when {{ source_column }} = '{{ category }}' then true \r\n                        else false\r\n                    end as is_{{ source_column }}_{{ no_whitespace_column_name }}\r\n                {% endif %}\r\n                {%- if handle_unknown=='error' %}\r\n                    case \r\n                        when {{ source_column }} = '{{ category }}' then true \r\n                        when {{ source_column }} in ('{{ category_values | join(\"','\") }}') then false\r\n                        else cast('Error: unknown value found and handle_unknown parameter was \"error\"' as boolean)\r\n                    end as is_{{ source_column }}_{{ no_whitespace_column_name }}\r\n                {% endif %}\r\n            {%- if not loop.last %},{% endif -%}\r\n        {% endfor %}\r\n    from {{ source_table }}\r\n    )\r\n\r\n    select * from binary_output\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\one_hot_encoder.yml", "arguments": []}, "macro.dbt_ml_preprocessing.quantile_transformer": {"unique_id": "macro.dbt_ml_preprocessing.quantile_transformer", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\quantile_transformer.sql", "original_file_path": "macros\\quantile_transformer.sql", "name": "quantile_transformer", "macro_sql": "{% macro quantile_transformer(source_table,source_column,n_quantiles=10,output_distribution='uniform',subsample=1000,include_columns='*') %}\r\n{%- if include_columns=='*' -%}\r\n{%- set all_source_columns = adapter.get_columns_in_relation(source_table) | map(attribute='quoted') -%}\r\n{% set include_columns = all_source_columns | join(', ') %}\r\n{%- endif -%}\r\n{{ adapter.dispatch('quantile_transformer',packages=['dbt_ml_preprocessing'])(source_table,source_column,n_quantiles,output_distribution,subsample,include_columns) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Transform features using quantiles information. See scikit-learn's [QuantileTransformer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer) for full documentation.\n\nWill append a new column with the name &lt;source column&gt;_transformed.\n\nExample usage:\n#### **`models\\customer_features.yml:`**\n```\n{{ config(materialized='view') }}\n\n{{ dbt_ml_preprocessing.quantile_transformer( ref('customer') ,'age') }}\n\n```\nWill produce a model named customer_features, with a new column named ```age_transformed``` containing the encoded values.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\quantile_transformer.yml", "arguments": [{"name": "source_table", "type": "string", "description": "Pass in a ref to the table containing the data you want to transform"}, {"name": "source_column", "type": "string", "description": "The column containing the data you want to transform"}, {"name": "include_columns", "type": "string", "description": "Other columns from the source table to be included in the model (defaults to '*' and brings all columns across)"}, {"name": "n_quantiles", "type": "string", "description": "Number of quantiles to be computed, defaults to 10."}, {"name": "output_distribution", "type": "string", "description": "Marginal distribution for the transformed data. Only supports the default value of 'uniform' at this time."}, {"name": "subsample", "type": "string", "description": "Maximum number of samples used to estimate the quantiles for computational efficiency, defaults to 1000."}]}, "macro.dbt_ml_preprocessing.snowflake__quantile_transformer": {"unique_id": "macro.dbt_ml_preprocessing.snowflake__quantile_transformer", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\quantile_transformer.sql", "original_file_path": "macros\\quantile_transformer.sql", "name": "snowflake__quantile_transformer", "macro_sql": "{% macro snowflake__quantile_transformer(source_table,source_column,n_quantiles,output_distribution,subsample,include_columns) %}\r\nwith quantile_values as(\r\n  {% for quartile_index in range(n_quantiles) %}\r\n    {% set quartile = quartile_index / (n_quantiles-1) %}\r\n    select {{ quartile }} as quantile,percentile_cont({{ quartile }})  within group (order by {{ source_column }})as quantile_value from {{ source_table }}\r\n    {% if not loop.last %} union all {% endif %}\r\n  {% endfor %}\r\n),\r\n-- prepare to apply linear interpolation formula\r\nlinear_interpolation_variables as(\r\n  select \r\n    {{include_columns}},\r\n    {{ source_column }} as x,\r\n    (select max(b.quantile) from quantile_values b where b.quantile_value<a.{{ source_column }}) as y1,\r\n    (select min(b.quantile) from quantile_values b where b.quantile_value>=a.{{ source_column }}) as y2,\r\n    (select max(b.quantile_value) from quantile_values b where b.quantile_value<a.{{ source_column }}) as x1,\r\n    (select min(b.quantile_value) from quantile_values b where b.quantile_value>=a.{{ source_column }}) as x2\r\n  from {{ source_table }} a\r\n  where {{ source_column }} is not null\r\n  order by {{ source_column }}\r\n)\r\nselect\r\n{{include_columns}},\r\ncoalesce(y1 + ((x-x1)/(x2-x1)) * (y2-y1),0) as {{ source_column }}_transformed\r\nfrom linear_interpolation_variables\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\quantile_transformer.yml", "arguments": []}, "macro.dbt_ml_preprocessing.bigquery__quantile_transformer": {"unique_id": "macro.dbt_ml_preprocessing.bigquery__quantile_transformer", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\quantile_transformer.sql", "original_file_path": "macros\\quantile_transformer.sql", "name": "bigquery__quantile_transformer", "macro_sql": "{% macro bigquery__quantile_transformer(source_table,source_column,n_quantiles,output_distribution,subsample,include_columns) %}\r\nwith quantile_values as(\r\n  {% for quartile_index in range(n_quantiles) %}\r\n    {% set quartile = quartile_index / (n_quantiles-1) %}\r\n    select distinct {{ quartile }} as quantile,percentile_cont({{ source_column }},{{ quartile }}) OVER() as quantile_value from {{ source_table }}\r\n    {% if not loop.last %} union all {% endif %}\r\n  {% endfor %}\r\n),\r\n-- fold all quantiles and quantile values into a single row, an array of structs that we can safely cross join on\r\nquantile_values_array as(\r\nselect ARRAY_AGG(struct (quantile, quantile_value)) as quantile_values from quantile_values\r\n),\r\n-- prepare to apply linear interpolation formula\r\nlinear_interpolation_variables as(\r\n  select \r\n    {{include_columns}},\r\n    {{ source_column }} as x,\r\n    (select max(b.quantile) from UNNEST(quantile_values) b where b.quantile_value<a.{{ source_column }}) as y1,\r\n    (select min(b.quantile) from UNNEST(quantile_values) b where b.quantile_value>=a.{{ source_column }}) as y2,\r\n    (select max(b.quantile_value) from UNNEST(quantile_values) b where b.quantile_value<a.{{ source_column }}) as x1,\r\n    (select min(b.quantile_value) from UNNEST(quantile_values) b where b.quantile_value>=a.{{ source_column }}) as x2\r\n  from {{ source_table }} a,\r\n  quantile_values_array\r\n  where {{ source_column }} is not null\r\n  order by {{ source_column }}\r\n)\r\nselect\r\n{{include_columns}},\r\ncoalesce(y1 + ((x-x1)/(x2-x1)) * (y2-y1),0) as {{ source_column }}_transformed\r\nfrom linear_interpolation_variables\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\quantile_transformer.yml", "arguments": []}, "macro.dbt_ml_preprocessing.default__quantile_transformer": {"unique_id": "macro.dbt_ml_preprocessing.default__quantile_transformer", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\quantile_transformer.sql", "original_file_path": "macros\\quantile_transformer.sql", "name": "default__quantile_transformer", "macro_sql": "{% macro default__quantile_transformer(source_table,source_column,n_quantiles,output_distribution,subsample,include_columns) %}\r\n\r\n{% set error_message %}\r\nThe `quantile_transformer` macro is only supported on Snowflake and BigQuery at this time. It should work on other DBs, it just requires some rework.\r\n{% endset %}\r\n{%- do exceptions.raise_compiler_error(error_message) -%}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\quantile_transformer.yml", "arguments": []}, "macro.dbt_ml_preprocessing.robust_scaler": {"unique_id": "macro.dbt_ml_preprocessing.robust_scaler", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\robust_scaler.sql", "original_file_path": "macros\\robust_scaler.sql", "name": "robust_scaler", "macro_sql": "{% macro robust_scaler(source_table,source_columns,include_columns='*',with_centering=False,quantile_range=[25,75]) %}\r\n{%- if with_centering!=False -%}\r\n    {% set error_message %}\r\nThe `robust_scaler` macro only supports a 'with_centering' value of 'False' at this time.\r\n    {% endset %}\r\n    {%- do exceptions.raise_compiler_error(error_message) -%}\r\n{%- endif -%}\r\n{%- if quantile_range | length !=2 -%}\r\n    {% set error_message %}\r\nThe `robust_scaler` macro only supports a 'quantile_range' value with exactly two values.\r\n    {% endset %}\r\n    {%- do exceptions.raise_compiler_error(error_message) -%}\r\n{%- endif -%}\r\n{% if source_columns is not iterable or source_columns is string or source_columns is mapping %}\r\n    {% set error_message %}\r\nThe `source_columns` parameter must contain a list of column names.\r\n    {% endset %}\r\n    {%- do exceptions.raise_compiler_error(error_message) -%}\r\n{%- endif -%}\r\n\r\n{%- if include_columns=='*' -%}\r\n{%- set all_source_columns = adapter.get_columns_in_relation(source_table) | map(attribute='quoted') -%}\r\n{% set include_columns = all_source_columns %}\r\n{%- endif -%}\r\n{{ adapter.dispatch('robust_scaler',packages=['dbt_ml_preprocessing'])(source_table,source_columns,include_columns,with_centering,quantile_range) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Scale features using statistics that are robust to outliers. See scikit-learn's [RobustScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler) for full documentation.\n\nWill append a new column with the name &lt;source column&gt;_scaled.\n\nExample usage:\n#### **`models\\customer_features.yml:`**\n```\n{{ config(materialized='view') }}\n\n{{ dbt_ml_preprocessing.robust_scaler( ref('customer') ,'age') }}\n\n```\nWill produce a model named customer_features, with a new column named ```age_scaled``` containing the scaled values.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\robust_scaler.yml", "arguments": [{"name": "source_table", "type": "string", "description": "Pass in a ref to the table containing the data you want to transform"}, {"name": "source_columns", "type": "list", "description": "The columns containing the data you want to transform"}, {"name": "include_columns", "type": "string", "description": "Other columns from the source table to be included in the model (defaults to '*' and brings all columns across)"}, {"name": "with_centering", "type": "string", "description": "If True, center the data before scaling. Only supports the default value of 'False' at this time."}, {"name": "quantile_range", "type": "string", "description": "Quantile range, must be a two-item array containing the first quartile threshold and the third quartile threshold. Defaults to Interquartile Range, which is [25,75]"}]}, "macro.dbt_ml_preprocessing.default__robust_scaler": {"unique_id": "macro.dbt_ml_preprocessing.default__robust_scaler", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\robust_scaler.sql", "original_file_path": "macros\\robust_scaler.sql", "name": "default__robust_scaler", "macro_sql": "{% macro default__robust_scaler(source_table,source_columns,include_columns,with_centering,quantile_range) %}\r\nwith \r\n{% for source_column in source_columns %}\r\n    {{ source_column }}_quartiles as(\r\n        select\r\n            percentile_cont({{ quantile_range[0] / 100 }}) within group (order by {{ source_column }}) as first_quartile,\r\n            percentile_cont({{ quantile_range[1] / 100 }}) within group (order by {{ source_column }}) as third_quartile\r\n        from {{ source_table }}\r\n    )\r\n{% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\nselect \r\n{% for column in include_columns %}\r\nsource_table.{{ column }},\r\n{% endfor %}\r\n{% for source_column in source_columns %}\r\n    ({{ source_column }} / ({{ source_column }}_quartiles.third_quartile - {{ source_column }}_quartiles.first_quartile)) as {{ source_column }}_scaled\r\n    {% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\nfrom \r\n    {% for source_column in source_columns %}\r\n        {{ source_column }}_quartiles,\r\n    {% endfor %}\r\n    {{ source_table }} as source_table\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\robust_scaler.yml", "arguments": []}, "macro.dbt_ml_preprocessing.bigquery__robust_scaler": {"unique_id": "macro.dbt_ml_preprocessing.bigquery__robust_scaler", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\robust_scaler.sql", "original_file_path": "macros\\robust_scaler.sql", "name": "bigquery__robust_scaler", "macro_sql": "{% macro bigquery__robust_scaler(source_table,source_columns,include_columns,with_centering,quantile_range) %}\r\nwith \r\n{% for source_column in source_columns %}\r\n    {{ source_column }}_quartiles as(\r\n        select\r\n            percentile_cont({{ source_column }},{{ quantile_range[0] / 100 }}) OVER() as first_quartile,\r\n            percentile_cont({{ source_column }},{{ quantile_range[1] / 100 }}) OVER() as third_quartile\r\n        from {{ source_table }}\r\n    )\r\n{% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\nselect \r\n{% for column in include_columns %}\r\nsource_table.{{ column }},\r\n{% endfor %}\r\n{% for source_column in source_columns %}\r\n    ({{ source_column }} / ({{ source_column }}_quartiles.third_quartile - {{ source_column }}_quartiles.first_quartile)) as {{ source_column }}_scaled\r\n    {% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\nfrom \r\n    {% for source_column in source_columns %}\r\n        {{ source_column }}_quartiles,\r\n    {% endfor %}\r\n    {{ source_table }} as source_table\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\robust_scaler.yml", "arguments": []}, "macro.dbt_ml_preprocessing.redshift__robust_scaler": {"unique_id": "macro.dbt_ml_preprocessing.redshift__robust_scaler", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\robust_scaler.sql", "original_file_path": "macros\\robust_scaler.sql", "name": "redshift__robust_scaler", "macro_sql": "{% macro redshift__robust_scaler(source_table,source_columns,include_columns,with_centering,quantile_range) %}\r\nwith \r\n{% for source_column in source_columns %}\r\n    {{ source_column }}_quartiles as(\r\n        select\r\n            percentile_cont({{ quantile_range[0] / 100 }}) within group (order by {{ source_column }}) as first_quartile,\r\n            percentile_cont({{ quantile_range[1] / 100 }}) within group (order by {{ source_column }}) as third_quartile\r\n        from {{ source_table }}\r\n    )\r\n{% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\nselect \r\n{% for column in include_columns %}\r\nsource_table.{{ column }},\r\n{% endfor %}\r\n{% for source_column in source_columns %}\r\n    ({{ source_column }} / ({{ source_column }}_quartiles.third_quartile - {{ source_column }}_quartiles.first_quartile)) as {{ source_column }}_scaled\r\n    {% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\nfrom \r\n    {% for source_column in source_columns %}\r\n        {{ source_column }}_quartiles,\r\n    {% endfor %}\r\n    {{ source_table }} as source_table\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": false}, "patch_path": "macros\\robust_scaler.yml", "arguments": []}, "macro.dbt_ml_preprocessing.standard_scaler": {"unique_id": "macro.dbt_ml_preprocessing.standard_scaler", "package_name": "dbt_ml_preprocessing", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_ml_preprocessing", "path": "macros\\standard_scaler.sql", "original_file_path": "macros\\standard_scaler.sql", "name": "standard_scaler", "macro_sql": "{% macro standard_scaler(source_table,source_columns,include_columns='*',with_mean=True) %}\r\n{%- if with_mean!=True -%}\r\n    {% set error_message %}\r\nThe `standard_scaler` macro only supports a 'with_mean' value of 'True' at this time.\r\n    {% endset %}\r\n    {%- do exceptions.raise_compiler_error(error_message) -%}\r\n{%- endif -%}\r\n{% if source_columns is not iterable or source_columns is string or source_columns is mapping %}\r\n    {% set error_message %}\r\nThe `source_columns` parameter must contain a list of column names.\r\n    {% endset %}\r\n    {%- do exceptions.raise_compiler_error(error_message) -%}\r\n{%- endif -%}\r\n\r\n{%- if include_columns=='*' -%}\r\n{%- set all_source_columns = adapter.get_columns_in_relation(source_table) | map(attribute='quoted') -%}\r\n{% set include_columns = all_source_columns %}\r\n{%- endif -%}\r\n\r\n-- generate a CTE for each source column, a single row containing the aggregates\r\nwith \r\n{% for source_column in source_columns %}\r\n    {{ source_column }}_aggregates as(\r\n        select\r\n            avg({{ source_column }}) as avg_value,\r\n            stddev_pop({{ source_column }}) as stddev_value\r\n        from {{ source_table }}\r\n    )\r\n{% if not loop.last %}, {% endif %}\r\n{% endfor %}\r\n\r\nselect \r\n    {% for column in include_columns %}\r\n        source_table.{{ column }},\r\n    {% endfor %}\r\n    {% for source_column in source_columns %}\r\n        ({{ source_column }} - {{ source_column }}_aggregates.avg_value) / {{ source_column }}_aggregates.stddev_value as {{ source_column }}_scaled\r\n        {% if not loop.last %}, {% endif %}\r\n    {% endfor %}\r\nfrom \r\n    {% for source_column in source_columns %}\r\n        {{ source_column }}_aggregates,\r\n    {% endfor %}\r\n    {{ source_table }} as source_table\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "Standardize features by removing the mean and scaling to unit variance. See scikit-learn's [StandardScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) for full documentation.\n\nWill append a new column with the name &lt;source column&gt;_scaled.\n\nExample usage:\n#### **`models\\customer_features.yml:`**\n```\n{{ config(materialized='view') }}\n\n{{ dbt_ml_preprocessing.standard_scaler( ref('customer') ,'age') }}\n\n```\nWill produce a model named customer_features, with a new column named ```age_scaled``` containing the scaled values.", "meta": {}, "docs": {"show": true}, "patch_path": "macros\\standard_scaler.yml", "arguments": [{"name": "source_table", "type": "string", "description": "Pass in a ref to the table containing the data you want to transform"}, {"name": "source_column", "type": "list", "description": "The columns containing the data you want to transform"}, {"name": "include_columns", "type": "string", "description": "Other columns from the source table to be included in the model (defaults to '*' and brings all columns across)"}, {"name": "with_mean", "type": "string", "description": "If True, center the data before scaling. Only supports the default value of 'True' at this time."}]}, "macro.dbt_utils.concat": {"unique_id": "macro.dbt_utils.concat", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\concat.sql", "original_file_path": "macros\\cross_db_utils\\concat.sql", "name": "concat", "macro_sql": "{% macro concat(fields) -%}\r\n  {{ adapter.dispatch('concat', packages = dbt_utils._get_utils_namespaces())(fields) }}\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__concat": {"unique_id": "macro.dbt_utils.default__concat", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\concat.sql", "original_file_path": "macros\\cross_db_utils\\concat.sql", "name": "default__concat", "macro_sql": "{% macro default__concat(fields) -%}\r\n    concat({{ fields|join(', ') }})\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.alternative_concat": {"unique_id": "macro.dbt_utils.alternative_concat", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\concat.sql", "original_file_path": "macros\\cross_db_utils\\concat.sql", "name": "alternative_concat", "macro_sql": "{% macro alternative_concat(fields) %}\r\n    {{ fields|join(' || ') }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__concat": {"unique_id": "macro.dbt_utils.redshift__concat", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\concat.sql", "original_file_path": "macros\\cross_db_utils\\concat.sql", "name": "redshift__concat", "macro_sql": "{% macro redshift__concat(fields) %}\r\n    {{ dbt_utils.alternative_concat(fields) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__concat": {"unique_id": "macro.dbt_utils.snowflake__concat", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\concat.sql", "original_file_path": "macros\\cross_db_utils\\concat.sql", "name": "snowflake__concat", "macro_sql": "{% macro snowflake__concat(fields) %}\r\n    {{ dbt_utils.alternative_concat(fields) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.current_timestamp": {"unique_id": "macro.dbt_utils.current_timestamp", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "current_timestamp", "macro_sql": "{% macro current_timestamp() -%}\r\n  {{ adapter.dispatch('current_timestamp', packages = dbt_utils._get_utils_namespaces())() }}\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__current_timestamp": {"unique_id": "macro.dbt_utils.default__current_timestamp", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "default__current_timestamp", "macro_sql": "{% macro default__current_timestamp() %}\r\n    current_timestamp::{{dbt_utils.type_timestamp()}}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__current_timestamp": {"unique_id": "macro.dbt_utils.redshift__current_timestamp", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "redshift__current_timestamp", "macro_sql": "{% macro redshift__current_timestamp() %}\r\n    getdate()\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__current_timestamp": {"unique_id": "macro.dbt_utils.bigquery__current_timestamp", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "bigquery__current_timestamp", "macro_sql": "{% macro bigquery__current_timestamp() %}\r\n    current_timestamp\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "current_timestamp_in_utc", "macro_sql": "{% macro current_timestamp_in_utc() -%}\r\n  {{ adapter.dispatch('current_timestamp_in_utc', packages = dbt_utils._get_utils_namespaces())() }}\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.default__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "default__current_timestamp_in_utc", "macro_sql": "{% macro default__current_timestamp_in_utc() %}\r\n    {{dbt_utils.current_timestamp()}}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.snowflake__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "snowflake__current_timestamp_in_utc", "macro_sql": "{% macro snowflake__current_timestamp_in_utc() %}\r\n    convert_timezone('UTC', {{dbt_utils.current_timestamp()}})::{{dbt_utils.type_timestamp()}}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__current_timestamp_in_utc": {"unique_id": "macro.dbt_utils.postgres__current_timestamp_in_utc", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\current_timestamp.sql", "original_file_path": "macros\\cross_db_utils\\current_timestamp.sql", "name": "postgres__current_timestamp_in_utc", "macro_sql": "{% macro postgres__current_timestamp_in_utc() %}\r\n    (current_timestamp at time zone 'utc')::{{dbt_utils.type_timestamp()}}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_string": {"unique_id": "macro.dbt_utils.type_string", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "type_string", "macro_sql": "\r\n\r\n{%- macro type_string() -%}\r\n  {{ adapter.dispatch('type_string', packages = dbt_utils._get_utils_namespaces())() }}\r\n{%- endmacro -%}\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_string": {"unique_id": "macro.dbt_utils.default__type_string", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "default__type_string", "macro_sql": "{% macro default__type_string() %}\r\n    string\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__type_string": {"unique_id": "macro.dbt_utils.redshift__type_string", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "redshift__type_string", "macro_sql": "\r\n\r\n{%- macro redshift__type_string() -%}\r\n    varchar\r\n{%- endmacro -%}\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__type_string": {"unique_id": "macro.dbt_utils.postgres__type_string", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "postgres__type_string", "macro_sql": "{% macro postgres__type_string() %}\r\n    varchar\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__type_string": {"unique_id": "macro.dbt_utils.snowflake__type_string", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "snowflake__type_string", "macro_sql": "{% macro snowflake__type_string() %}\r\n    varchar\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_timestamp": {"unique_id": "macro.dbt_utils.type_timestamp", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "type_timestamp", "macro_sql": "\r\n\r\n{%- macro type_timestamp() -%}\r\n  {{ adapter.dispatch('type_timestamp', packages = dbt_utils._get_utils_namespaces())() }}\r\n{%- endmacro -%}\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_timestamp": {"unique_id": "macro.dbt_utils.default__type_timestamp", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "default__type_timestamp", "macro_sql": "{% macro default__type_timestamp() %}\r\n    timestamp\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__type_timestamp": {"unique_id": "macro.dbt_utils.snowflake__type_timestamp", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "snowflake__type_timestamp", "macro_sql": "{% macro snowflake__type_timestamp() %}\r\n    timestamp_ntz\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_float": {"unique_id": "macro.dbt_utils.type_float", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "type_float", "macro_sql": "\r\n\r\n{%- macro type_float() -%}\r\n  {{ adapter.dispatch('type_float', packages = dbt_utils._get_utils_namespaces())() }}\r\n{%- endmacro -%}\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_float": {"unique_id": "macro.dbt_utils.default__type_float", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "default__type_float", "macro_sql": "{% macro default__type_float() %}\r\n    float\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_float": {"unique_id": "macro.dbt_utils.bigquery__type_float", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "bigquery__type_float", "macro_sql": "{% macro bigquery__type_float() %}\r\n    float64\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_numeric": {"unique_id": "macro.dbt_utils.type_numeric", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "type_numeric", "macro_sql": "\r\n\r\n{%- macro type_numeric() -%}\r\n  {{ adapter.dispatch('type_numeric', packages = dbt_utils._get_utils_namespaces())() }}\r\n{%- endmacro -%}\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_numeric": {"unique_id": "macro.dbt_utils.default__type_numeric", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "default__type_numeric", "macro_sql": "{% macro default__type_numeric() %}\r\n    numeric(28, 6)\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_numeric": {"unique_id": "macro.dbt_utils.bigquery__type_numeric", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "bigquery__type_numeric", "macro_sql": "{% macro bigquery__type_numeric() %}\r\n    numeric\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_bigint": {"unique_id": "macro.dbt_utils.type_bigint", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "type_bigint", "macro_sql": "\r\n\r\n{%- macro type_bigint() -%}\r\n  {{ adapter.dispatch('type_bigint', packages = dbt_utils._get_utils_namespaces())() }}\r\n{%- endmacro -%}\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_bigint": {"unique_id": "macro.dbt_utils.default__type_bigint", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "default__type_bigint", "macro_sql": "{% macro default__type_bigint() %}\r\n    bigint\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_bigint": {"unique_id": "macro.dbt_utils.bigquery__type_bigint", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "bigquery__type_bigint", "macro_sql": "{% macro bigquery__type_bigint() %}\r\n    int64\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.type_int": {"unique_id": "macro.dbt_utils.type_int", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "type_int", "macro_sql": "\r\n\r\n{%- macro type_int() -%}\r\n  {{ adapter.dispatch('type_int', packages = dbt_utils._get_utils_namespaces())() }}\r\n{%- endmacro -%}\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__type_int": {"unique_id": "macro.dbt_utils.default__type_int", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "default__type_int", "macro_sql": "{% macro default__type_int() %}\r\n    int\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__type_int": {"unique_id": "macro.dbt_utils.bigquery__type_int", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datatypes.sql", "original_file_path": "macros\\cross_db_utils\\datatypes.sql", "name": "bigquery__type_int", "macro_sql": "{% macro bigquery__type_int() %}\r\n    int64\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.dateadd": {"unique_id": "macro.dbt_utils.dateadd", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\dateadd.sql", "original_file_path": "macros\\cross_db_utils\\dateadd.sql", "name": "dateadd", "macro_sql": "{% macro dateadd(datepart, interval, from_date_or_timestamp) %}\r\n  {{ adapter.dispatch('dateadd', packages = dbt_utils._get_utils_namespaces())(datepart, interval, from_date_or_timestamp) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__dateadd": {"unique_id": "macro.dbt_utils.default__dateadd", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\dateadd.sql", "original_file_path": "macros\\cross_db_utils\\dateadd.sql", "name": "default__dateadd", "macro_sql": "{% macro default__dateadd(datepart, interval, from_date_or_timestamp) %}\r\n\r\n    dateadd(\r\n        {{ datepart }},\r\n        {{ interval }},\r\n        {{ from_date_or_timestamp }}\r\n        )\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__dateadd": {"unique_id": "macro.dbt_utils.bigquery__dateadd", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\dateadd.sql", "original_file_path": "macros\\cross_db_utils\\dateadd.sql", "name": "bigquery__dateadd", "macro_sql": "{% macro bigquery__dateadd(datepart, interval, from_date_or_timestamp) %}\r\n\r\n        datetime_add(\r\n            cast( {{ from_date_or_timestamp }} as datetime),\r\n        interval {{ interval }} {{ datepart }}\r\n        )\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__dateadd": {"unique_id": "macro.dbt_utils.postgres__dateadd", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\dateadd.sql", "original_file_path": "macros\\cross_db_utils\\dateadd.sql", "name": "postgres__dateadd", "macro_sql": "{% macro postgres__dateadd(datepart, interval, from_date_or_timestamp) %}\r\n\r\n    {{ from_date_or_timestamp }} + ((interval '1 {{ datepart }}') * ({{ interval }}))\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.datediff": {"unique_id": "macro.dbt_utils.datediff", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datediff.sql", "original_file_path": "macros\\cross_db_utils\\datediff.sql", "name": "datediff", "macro_sql": "{% macro datediff(first_date, second_date, datepart) %}\r\n  {{ adapter.dispatch('datediff', packages = dbt_utils._get_utils_namespaces())(first_date, second_date, datepart) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__datediff": {"unique_id": "macro.dbt_utils.default__datediff", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datediff.sql", "original_file_path": "macros\\cross_db_utils\\datediff.sql", "name": "default__datediff", "macro_sql": "{% macro default__datediff(first_date, second_date, datepart) %}\r\n\r\n    datediff(\r\n        {{ datepart }},\r\n        {{ first_date }},\r\n        {{ second_date }}\r\n        )\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__datediff": {"unique_id": "macro.dbt_utils.bigquery__datediff", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datediff.sql", "original_file_path": "macros\\cross_db_utils\\datediff.sql", "name": "bigquery__datediff", "macro_sql": "{% macro bigquery__datediff(first_date, second_date, datepart) %}\r\n\r\n    datetime_diff(\r\n        cast({{second_date}} as datetime),\r\n        cast({{first_date}} as datetime),\r\n        {{datepart}}\r\n    )\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__datediff": {"unique_id": "macro.dbt_utils.postgres__datediff", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\datediff.sql", "original_file_path": "macros\\cross_db_utils\\datediff.sql", "name": "postgres__datediff", "macro_sql": "{% macro postgres__datediff(first_date, second_date, datepart) %}\r\n\r\n    {% if datepart == 'year' %}\r\n        (date_part('year', ({{second_date}})::date) - date_part('year', ({{first_date}})::date))\r\n    {% elif datepart == 'quarter' %}\r\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 4 + date_part('quarter', ({{second_date}})::date) - date_part('quarter', ({{first_date}})::date))\r\n    {% elif datepart == 'month' %}\r\n        ({{ dbt_utils.datediff(first_date, second_date, 'year') }} * 12 + date_part('month', ({{second_date}})::date) - date_part('month', ({{first_date}})::date))\r\n    {% elif datepart == 'day' %}\r\n        (({{second_date}})::date - ({{first_date}})::date)\r\n    {% elif datepart == 'week' %}\r\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} / 7 + case\r\n            when date_part('dow', ({{first_date}})::timestamp) <= date_part('dow', ({{second_date}})::timestamp) then\r\n                case when {{first_date}} <= {{second_date}} then 0 else -1 end\r\n            else\r\n                case when {{first_date}} <= {{second_date}} then 1 else 0 end\r\n        end)\r\n    {% elif datepart == 'hour' %}\r\n        ({{ dbt_utils.datediff(first_date, second_date, 'day') }} * 24 + date_part('hour', ({{second_date}})::timestamp) - date_part('hour', ({{first_date}})::timestamp))\r\n    {% elif datepart == 'minute' %}\r\n        ({{ dbt_utils.datediff(first_date, second_date, 'hour') }} * 60 + date_part('minute', ({{second_date}})::timestamp) - date_part('minute', ({{first_date}})::timestamp))\r\n    {% elif datepart == 'second' %}\r\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60 + floor(date_part('second', ({{second_date}})::timestamp)) - floor(date_part('second', ({{first_date}})::timestamp)))\r\n    {% elif datepart == 'millisecond' %}\r\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000 + floor(date_part('millisecond', ({{second_date}})::timestamp)) - floor(date_part('millisecond', ({{first_date}})::timestamp)))\r\n    {% elif datepart == 'microsecond' %}\r\n        ({{ dbt_utils.datediff(first_date, second_date, 'minute') }} * 60000000 + floor(date_part('microsecond', ({{second_date}})::timestamp)) - floor(date_part('microsecond', ({{first_date}})::timestamp)))\r\n    {% else %}\r\n        {{ exceptions.raise_compiler_error(\"Unsupported datepart for macro datediff in postgres: {!r}\".format(datepart)) }}\r\n    {% endif %}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.date_trunc": {"unique_id": "macro.dbt_utils.date_trunc", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\date_trunc.sql", "original_file_path": "macros\\cross_db_utils\\date_trunc.sql", "name": "date_trunc", "macro_sql": "{% macro date_trunc(datepart, date) -%}\r\n  {{ adapter.dispatch('date_trunc', packages = dbt_utils._get_utils_namespaces()) (datepart, date) }}\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__date_trunc": {"unique_id": "macro.dbt_utils.default__date_trunc", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\date_trunc.sql", "original_file_path": "macros\\cross_db_utils\\date_trunc.sql", "name": "default__date_trunc", "macro_sql": "{% macro default__date_trunc(datepart, date) %}\r\n    date_trunc('{{datepart}}', {{date}})\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__date_trunc": {"unique_id": "macro.dbt_utils.bigquery__date_trunc", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\date_trunc.sql", "original_file_path": "macros\\cross_db_utils\\date_trunc.sql", "name": "bigquery__date_trunc", "macro_sql": "{% macro bigquery__date_trunc(datepart, date) %}\r\n    timestamp_trunc(\r\n        cast({{date}} as timestamp),\r\n        {{datepart}}\r\n    )\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.except": {"unique_id": "macro.dbt_utils.except", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\except.sql", "original_file_path": "macros\\cross_db_utils\\except.sql", "name": "except", "macro_sql": "{% macro except() %}\r\n  {{ adapter.dispatch('except', packages = dbt_utils._get_utils_namespaces())() }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__except": {"unique_id": "macro.dbt_utils.default__except", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\except.sql", "original_file_path": "macros\\cross_db_utils\\except.sql", "name": "default__except", "macro_sql": "{% macro default__except() %}\r\n\r\n    except\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__except": {"unique_id": "macro.dbt_utils.bigquery__except", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\except.sql", "original_file_path": "macros\\cross_db_utils\\except.sql", "name": "bigquery__except", "macro_sql": "{% macro bigquery__except() %}\r\n\r\n    except distinct\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.hash": {"unique_id": "macro.dbt_utils.hash", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\hash.sql", "original_file_path": "macros\\cross_db_utils\\hash.sql", "name": "hash", "macro_sql": "{% macro hash(field) -%}\r\n  {{ adapter.dispatch('hash', packages = dbt_utils._get_utils_namespaces()) (field) }}\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__hash": {"unique_id": "macro.dbt_utils.default__hash", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\hash.sql", "original_file_path": "macros\\cross_db_utils\\hash.sql", "name": "default__hash", "macro_sql": "{% macro default__hash(field) -%}\r\n    md5(cast({{field}} as {{dbt_utils.type_string()}}))\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__hash": {"unique_id": "macro.dbt_utils.bigquery__hash", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\hash.sql", "original_file_path": "macros\\cross_db_utils\\hash.sql", "name": "bigquery__hash", "macro_sql": "{% macro bigquery__hash(field) -%}\r\n    to_hex({{dbt_utils.default__hash(field)}})\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.identifier": {"unique_id": "macro.dbt_utils.identifier", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\identifier.sql", "original_file_path": "macros\\cross_db_utils\\identifier.sql", "name": "identifier", "macro_sql": "{% macro identifier(value) %}\t\r\n  {%- set error_message = '\r\n    Warning: the `identifier` macro is no longer supported and will be deprecated in a future release of dbt-utils. \\\r\n    Use `adapter.quote` instead. The {}.{} model triggered this warning. \\\r\n    '.format(model.package_name, model.name) -%}\r\n  {%- do exceptions.warn(error_message) -%}\r\n  {{ adapter.dispatch('identifier', packages = dbt_utils._get_utils_namespaces()) (value) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__identifier": {"unique_id": "macro.dbt_utils.default__identifier", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\identifier.sql", "original_file_path": "macros\\cross_db_utils\\identifier.sql", "name": "default__identifier", "macro_sql": "{% macro default__identifier(value) -%}\t\r\n    \"{{ value }}\"\t\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__identifier": {"unique_id": "macro.dbt_utils.bigquery__identifier", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\identifier.sql", "original_file_path": "macros\\cross_db_utils\\identifier.sql", "name": "bigquery__identifier", "macro_sql": "{% macro bigquery__identifier(value) -%}\t\r\n    `{{ value }}`\t\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.intersect": {"unique_id": "macro.dbt_utils.intersect", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\intersect.sql", "original_file_path": "macros\\cross_db_utils\\intersect.sql", "name": "intersect", "macro_sql": "{% macro intersect() %}\r\n  {{ adapter.dispatch('intersect', packages = dbt_utils._get_utils_namespaces())() }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__intersect": {"unique_id": "macro.dbt_utils.default__intersect", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\intersect.sql", "original_file_path": "macros\\cross_db_utils\\intersect.sql", "name": "default__intersect", "macro_sql": "{% macro default__intersect() %}\r\n\r\n    intersect\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__intersect": {"unique_id": "macro.dbt_utils.bigquery__intersect", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\intersect.sql", "original_file_path": "macros\\cross_db_utils\\intersect.sql", "name": "bigquery__intersect", "macro_sql": "{% macro bigquery__intersect() %}\r\n\r\n    intersect distinct\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.last_day": {"unique_id": "macro.dbt_utils.last_day", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\last_day.sql", "original_file_path": "macros\\cross_db_utils\\last_day.sql", "name": "last_day", "macro_sql": "{% macro last_day(date, datepart) %}\r\n  {{ adapter.dispatch('last_day', packages = dbt_utils._get_utils_namespaces()) (date, datepart) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default_last_day": {"unique_id": "macro.dbt_utils.default_last_day", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\last_day.sql", "original_file_path": "macros\\cross_db_utils\\last_day.sql", "name": "default_last_day", "macro_sql": "\r\n\r\n\r\n{%- macro default_last_day(date, datepart) -%}\r\n    cast(\r\n        {{dbt_utils.dateadd('day', '-1',\r\n        dbt_utils.dateadd(datepart, '1', dbt_utils.date_trunc(datepart, date))\r\n        )}}\r\n        as date)\r\n{%- endmacro -%}\r\n\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__last_day": {"unique_id": "macro.dbt_utils.default__last_day", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\last_day.sql", "original_file_path": "macros\\cross_db_utils\\last_day.sql", "name": "default__last_day", "macro_sql": "{% macro default__last_day(date, datepart) -%}\r\n    {{dbt_utils.default_last_day(date, datepart)}}\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.postgres__last_day": {"unique_id": "macro.dbt_utils.postgres__last_day", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\last_day.sql", "original_file_path": "macros\\cross_db_utils\\last_day.sql", "name": "postgres__last_day", "macro_sql": "{% macro postgres__last_day(date, datepart) -%}\r\n\r\n    {%- if datepart == 'quarter' -%}\r\n    {{ exceptions.raise_compiler_error(\r\n        \"dbt_utils.last_day is not supported for datepart 'quarter' on this adapter\") }}\r\n    {%- else -%}\r\n    {{dbt_utils.default_last_day(date, datepart)}}\r\n    {%- endif -%}\r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.length": {"unique_id": "macro.dbt_utils.length", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\length.sql", "original_file_path": "macros\\cross_db_utils\\length.sql", "name": "length", "macro_sql": "{% macro length(expression) -%}\r\n    {{ adapter.dispatch('length', packages = dbt_utils._get_utils_namespaces()) (expression) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__length": {"unique_id": "macro.dbt_utils.default__length", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\length.sql", "original_file_path": "macros\\cross_db_utils\\length.sql", "name": "default__length", "macro_sql": "{% macro default__length(expression) %}\r\n    \r\n    length(\r\n        {{ expression }}\r\n    )\r\n    \r\n{%- endmacro -%}\r\n\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__length": {"unique_id": "macro.dbt_utils.redshift__length", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\length.sql", "original_file_path": "macros\\cross_db_utils\\length.sql", "name": "redshift__length", "macro_sql": "{% macro redshift__length(expression) %}\r\n\r\n    len(\r\n        {{ expression }}\r\n    )\r\n    \r\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.string_literal": {"unique_id": "macro.dbt_utils.string_literal", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\literal.sql", "original_file_path": "macros\\cross_db_utils\\literal.sql", "name": "string_literal", "macro_sql": "{%- macro string_literal(value) -%}\r\n  {{ adapter.dispatch('string_literal', packages = dbt_utils._get_utils_namespaces()) (value) }}\r\n{%- endmacro -%}\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__string_literal": {"unique_id": "macro.dbt_utils.default__string_literal", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\literal.sql", "original_file_path": "macros\\cross_db_utils\\literal.sql", "name": "default__string_literal", "macro_sql": "{% macro default__string_literal(value) -%}\r\n    '{{ value }}'\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.position": {"unique_id": "macro.dbt_utils.position", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\position.sql", "original_file_path": "macros\\cross_db_utils\\position.sql", "name": "position", "macro_sql": "{% macro position(substring_text, string_text) -%}\r\n    {{ adapter.dispatch('position', packages = dbt_utils._get_utils_namespaces()) (substring_text, string_text) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__position": {"unique_id": "macro.dbt_utils.default__position", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\position.sql", "original_file_path": "macros\\cross_db_utils\\position.sql", "name": "default__position", "macro_sql": "{% macro default__position(substring_text, string_text) %}\r\n\r\n    position(\r\n        {{ substring_text }} in {{ string_text }}\r\n    )\r\n    \r\n{%- endmacro -%}\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__position": {"unique_id": "macro.dbt_utils.bigquery__position", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\position.sql", "original_file_path": "macros\\cross_db_utils\\position.sql", "name": "bigquery__position", "macro_sql": "{% macro bigquery__position(substring_text, string_text) %}\r\n\r\n    strpos(\r\n        {{ string_text }},\r\n        {{ substring_text }}\r\n        \r\n    )\r\n    \r\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.replace": {"unique_id": "macro.dbt_utils.replace", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\replace.sql", "original_file_path": "macros\\cross_db_utils\\replace.sql", "name": "replace", "macro_sql": "{% macro replace(field, old_chars, new_chars) -%}\r\n    {{ adapter.dispatch('replace', packages = dbt_utils._get_utils_namespaces()) (field, old_chars, new_chars) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__replace": {"unique_id": "macro.dbt_utils.default__replace", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\replace.sql", "original_file_path": "macros\\cross_db_utils\\replace.sql", "name": "default__replace", "macro_sql": "{% macro default__replace(field, old_chars, new_chars) %}\r\n\r\n    replace(\r\n        {{ field }},\r\n        {{ old_chars }},\r\n        {{ new_chars }}\r\n    )\r\n    \r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.right": {"unique_id": "macro.dbt_utils.right", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\right.sql", "original_file_path": "macros\\cross_db_utils\\right.sql", "name": "right", "macro_sql": "{% macro right(string_text, length_expression) -%}\r\n    {{ adapter.dispatch('right', packages = dbt_utils._get_utils_namespaces()) (string_text, length_expression) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__right": {"unique_id": "macro.dbt_utils.default__right", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\right.sql", "original_file_path": "macros\\cross_db_utils\\right.sql", "name": "default__right", "macro_sql": "{% macro default__right(string_text, length_expression) %}\r\n\r\n    right(\r\n        {{ string_text }},\r\n        {{ length_expression }}\r\n    )\r\n    \r\n{%- endmacro -%}\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__right": {"unique_id": "macro.dbt_utils.bigquery__right", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\right.sql", "original_file_path": "macros\\cross_db_utils\\right.sql", "name": "bigquery__right", "macro_sql": "{% macro bigquery__right(string_text, length_expression) %}\r\n\r\n    case when {{ length_expression }} = 0 \r\n        then ''\r\n    else \r\n        substr(\r\n            {{ string_text }},\r\n            -1 * ({{ length_expression }})\r\n        )\r\n    end\r\n\r\n{%- endmacro -%}\r\n\r\n", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__right": {"unique_id": "macro.dbt_utils.snowflake__right", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\right.sql", "original_file_path": "macros\\cross_db_utils\\right.sql", "name": "snowflake__right", "macro_sql": "{% macro snowflake__right(string_text, length_expression) %}\r\n\r\n    case when {{ length_expression }} = 0 \r\n        then ''\r\n    else \r\n        right(\r\n            {{ string_text }},\r\n            {{ length_expression }}\r\n        )\r\n    end\r\n\r\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.safe_cast": {"unique_id": "macro.dbt_utils.safe_cast", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\safe_cast.sql", "original_file_path": "macros\\cross_db_utils\\safe_cast.sql", "name": "safe_cast", "macro_sql": "{% macro safe_cast(field, type) %}\r\n  {{ adapter.dispatch('safe_cast', packages = dbt_utils._get_utils_namespaces()) (field, type) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__safe_cast": {"unique_id": "macro.dbt_utils.default__safe_cast", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\safe_cast.sql", "original_file_path": "macros\\cross_db_utils\\safe_cast.sql", "name": "default__safe_cast", "macro_sql": "{% macro default__safe_cast(field, type) %}\r\n    {# most databases don't support this function yet\r\n    so we just need to use cast #}\r\n    cast({{field}} as {{type}})\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__safe_cast": {"unique_id": "macro.dbt_utils.snowflake__safe_cast", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\safe_cast.sql", "original_file_path": "macros\\cross_db_utils\\safe_cast.sql", "name": "snowflake__safe_cast", "macro_sql": "{% macro snowflake__safe_cast(field, type) %}\r\n    try_cast({{field}} as {{type}})\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__safe_cast": {"unique_id": "macro.dbt_utils.bigquery__safe_cast", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\safe_cast.sql", "original_file_path": "macros\\cross_db_utils\\safe_cast.sql", "name": "bigquery__safe_cast", "macro_sql": "{% macro bigquery__safe_cast(field, type) %}\r\n    safe_cast({{field}} as {{type}})\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.split_part": {"unique_id": "macro.dbt_utils.split_part", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\split_part.sql", "original_file_path": "macros\\cross_db_utils\\split_part.sql", "name": "split_part", "macro_sql": "{% macro split_part(string_text, delimiter_text, part_number) %}\r\n  {{ adapter.dispatch('split_part', packages = dbt_utils._get_utils_namespaces()) (string_text, delimiter_text, part_number) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__split_part": {"unique_id": "macro.dbt_utils.default__split_part", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\split_part.sql", "original_file_path": "macros\\cross_db_utils\\split_part.sql", "name": "default__split_part", "macro_sql": "{% macro default__split_part(string_text, delimiter_text, part_number) %}\r\n\r\n    split_part(\r\n        {{ string_text }},\r\n        {{ delimiter_text }},\r\n        {{ part_number }}\r\n        )\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__split_part": {"unique_id": "macro.dbt_utils.bigquery__split_part", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\split_part.sql", "original_file_path": "macros\\cross_db_utils\\split_part.sql", "name": "bigquery__split_part", "macro_sql": "{% macro bigquery__split_part(string_text, delimiter_text, part_number) %}\r\n\r\n    split(\r\n        {{ string_text }},\r\n        {{ delimiter_text }}\r\n        )[safe_offset({{ part_number - 1 }})]\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.width_bucket": {"unique_id": "macro.dbt_utils.width_bucket", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\width_bucket.sql", "original_file_path": "macros\\cross_db_utils\\width_bucket.sql", "name": "width_bucket", "macro_sql": "{% macro width_bucket(expr, min_value, max_value, num_buckets) %}\r\n  {{ adapter.dispatch('width_bucket', packages = dbt_utils._get_utils_namespaces()) (expr, min_value, max_value, num_buckets) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__width_bucket": {"unique_id": "macro.dbt_utils.default__width_bucket", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\width_bucket.sql", "original_file_path": "macros\\cross_db_utils\\width_bucket.sql", "name": "default__width_bucket", "macro_sql": "{% macro default__width_bucket(expr, min_value, max_value, num_buckets) -%}\r\n\r\n    {% set bin_size -%}\r\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\r\n    {%- endset %}\r\n    (\r\n        -- to break ties when the amount is eaxtly at the bucket egde\r\n        case\r\n            when\r\n                mod(\r\n                    {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }},\r\n                    {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\r\n                ) = 0\r\n            then 1\r\n            else 0\r\n        end\r\n    ) +\r\n      -- Anything over max_value goes the N+1 bucket\r\n    least(\r\n        ceil(\r\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\r\n        ),\r\n        {{ num_buckets }} + 1\r\n    )\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.redshift__width_bucket": {"unique_id": "macro.dbt_utils.redshift__width_bucket", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\width_bucket.sql", "original_file_path": "macros\\cross_db_utils\\width_bucket.sql", "name": "redshift__width_bucket", "macro_sql": "{% macro redshift__width_bucket(expr, min_value, max_value, num_buckets) -%}\r\n\r\n    {% set bin_size -%}\r\n    (( {{ max_value }} - {{ min_value }} ) / {{ num_buckets }} )\r\n    {%- endset %}\r\n    (\r\n        -- to break ties when the amount is exactly at the bucket edge\r\n        case\r\n            when\r\n                {{ dbt_utils.safe_cast(expr, dbt_utils.type_numeric() ) }} %\r\n                {{ dbt_utils.safe_cast(bin_size, dbt_utils.type_numeric() ) }}\r\n                 = 0\r\n            then 1\r\n            else 0\r\n        end\r\n    ) +\r\n      -- Anything over max_value goes the N+1 bucket\r\n    least(\r\n        ceil(\r\n            ({{ expr }} - {{ min_value }})/{{ bin_size }}\r\n        ),\r\n        {{ num_buckets }} + 1\r\n    )\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.snowflake__width_bucket": {"unique_id": "macro.dbt_utils.snowflake__width_bucket", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\width_bucket.sql", "original_file_path": "macros\\cross_db_utils\\width_bucket.sql", "name": "snowflake__width_bucket", "macro_sql": "{% macro snowflake__width_bucket(expr, min_value, max_value, num_buckets) %}\r\n    width_bucket({{ expr }}, {{ min_value }}, {{ max_value }}, {{ num_buckets }} )\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils._get_utils_namespaces": {"unique_id": "macro.dbt_utils._get_utils_namespaces", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\_get_utils_namespaces.sql", "original_file_path": "macros\\cross_db_utils\\_get_utils_namespaces.sql", "name": "_get_utils_namespaces", "macro_sql": "{% macro _get_utils_namespaces() %}\r\n  {% set override_namespaces = var('dbt_utils_dispatch_list', []) %}\r\n  {% do return(override_namespaces + ['dbt_utils']) %}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils._is_ephemeral": {"unique_id": "macro.dbt_utils._is_ephemeral", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\_is_ephemeral.sql", "original_file_path": "macros\\cross_db_utils\\_is_ephemeral.sql", "name": "_is_ephemeral", "macro_sql": "{% macro _is_ephemeral(obj, macro) %}\r\n    {%- if obj.is_cte -%}\r\n        {% set ephemeral_prefix = api.Relation.add_ephemeral_prefix('') %}\r\n        {% if obj.name.startswith(ephemeral_prefix) %}\r\n            {% set model_name = obj.name[(ephemeral_prefix|length):] %}\r\n        {% else %}\r\n            {% set model_name = obj.name %}\r\n        {%- endif -%}\r\n        {% set error_message %}\r\nThe `{{ macro }}` macro cannot be used with ephemeral models, as it relies on the information schema.\r\n\r\n`{{ model_name }}` is an ephemeral model. Consider making it a view or table instead.\r\n        {% endset %}\r\n        {%- do exceptions.raise_compiler_error(error_message) -%}\r\n    {%- endif -%}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils._is_relation": {"unique_id": "macro.dbt_utils._is_relation", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\cross_db_utils\\_is_relation.sql", "original_file_path": "macros\\cross_db_utils\\_is_relation.sql", "name": "_is_relation", "macro_sql": "{% macro _is_relation(obj, macro) %}\r\n    {%- if not (obj is mapping and obj.get('metadata', {}).get('type', '').endswith('Relation')) -%}\r\n        {%- do exceptions.raise_compiler_error(\"Macro \" ~ macro ~ \" expected a Relation but received the value: \" ~ obj) -%}\r\n    {%- endif -%}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_intervals_between": {"unique_id": "macro.dbt_utils.get_intervals_between", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\datetime\\date_spine.sql", "original_file_path": "macros\\datetime\\date_spine.sql", "name": "get_intervals_between", "macro_sql": "{% macro get_intervals_between(start_date, end_date, datepart) -%}\r\n\r\n    {%- call statement('get_intervals_between', fetch_result=True) %}\r\n\r\n        select {{dbt_utils.datediff(start_date, end_date, datepart)}}\r\n\r\n    {%- endcall -%}\r\n\r\n    {%- set value_list = load_result('get_intervals_between') -%}\r\n\r\n    {%- if value_list and value_list['data'] -%}\r\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\r\n        {{ return(values[0]) }}\r\n    {%- else -%}\r\n        {{ return(1) }}\r\n    {%- endif -%}\r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.date_spine": {"unique_id": "macro.dbt_utils.date_spine", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\datetime\\date_spine.sql", "original_file_path": "macros\\datetime\\date_spine.sql", "name": "date_spine", "macro_sql": "{% macro date_spine(datepart, start_date, end_date) %}\r\n\r\n/*\r\ncall as follows:\r\n\r\ndate_spine(\r\n    \"day\",\r\n    \"to_date('01/01/2016', 'mm/dd/yyyy')\",\r\n    \"dateadd(week, 1, current_date)\"\r\n)\r\n\r\n*/\r\n\r\nwith rawdata as (\r\n\r\n    {{dbt_utils.generate_series(\r\n        dbt_utils.get_intervals_between(start_date, end_date, datepart)\r\n    )}}\r\n\r\n),\r\n\r\nall_periods as (\r\n\r\n    select (\r\n        {{\r\n            dbt_utils.dateadd(\r\n                datepart,\r\n                \"row_number() over (order by 1) - 1\",\r\n                start_date\r\n            )\r\n        }}\r\n    ) as date_{{datepart}}\r\n    from rawdata\r\n\r\n),\r\n\r\nfiltered as (\r\n\r\n    select *\r\n    from all_periods\r\n    where date_{{datepart}} <= {{ end_date }}\r\n\r\n)\r\n\r\nselect * from filtered\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.haversine_distance": {"unique_id": "macro.dbt_utils.haversine_distance", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\geo\\haversine_distance.sql", "original_file_path": "macros\\geo\\haversine_distance.sql", "name": "haversine_distance", "macro_sql": "{% macro haversine_distance(lat1,lon1,lat2,lon2) -%}\r\n\r\n    2 * 3961 * asin(sqrt((sin(radians(({{lat2}} - {{lat1}}) / 2))) ^ 2 +\r\n    cos(radians({{lat1}})) * cos(radians({{lat2}})) *\r\n    (sin(radians(({{lon2}} - {{lon1}}) / 2))) ^ 2))\r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.log_info": {"unique_id": "macro.dbt_utils.log_info", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\logger\\log_info.sql", "original_file_path": "macros\\logger\\log_info.sql", "name": "log_info", "macro_sql": "{% macro log_info(message) %}\r\n\r\n    {{ log(dbt_utils.pretty_log_format(message), info=True) }}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.pretty_log_format": {"unique_id": "macro.dbt_utils.pretty_log_format", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\logger\\pretty_log_format.sql", "original_file_path": "macros\\logger\\pretty_log_format.sql", "name": "pretty_log_format", "macro_sql": "{% macro pretty_log_format(message) %}\r\n\r\n    {{ return( dbt_utils.pretty_time() ~ ' + ' ~ message) }}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.pretty_time": {"unique_id": "macro.dbt_utils.pretty_time", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\logger\\pretty_time.sql", "original_file_path": "macros\\logger\\pretty_time.sql", "name": "pretty_time", "macro_sql": "{% macro pretty_time(format='%H:%M:%S') %}\r\n\r\n    {{ return(modules.datetime.datetime.now().strftime(format)) }}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_period_boundaries": {"unique_id": "macro.dbt_utils.get_period_boundaries", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\materializations\\insert_by_period_materialization.sql", "original_file_path": "macros\\materializations\\insert_by_period_materialization.sql", "name": "get_period_boundaries", "macro_sql": "{% macro get_period_boundaries(target_schema, target_table, timestamp_field, start_date, stop_date, period) -%}\r\n\r\n  {% call statement('period_boundaries', fetch_result=True) -%}\r\n    with data as (\r\n      select\r\n          coalesce(max(\"{{timestamp_field}}\"), '{{start_date}}')::timestamp as start_timestamp,\r\n          coalesce(\r\n            {{dbt_utils.dateadd('millisecond',\r\n                                -1,\r\n                                \"nullif('\" ~ stop_date ~ \"','')::timestamp\")}},\r\n            {{dbt_utils.current_timestamp()}}\r\n          ) as stop_timestamp\r\n      from \"{{target_schema}}\".\"{{target_table}}\"\r\n    )\r\n\r\n    select\r\n      start_timestamp,\r\n      stop_timestamp,\r\n      {{dbt_utils.datediff('start_timestamp',\r\n                           'stop_timestamp',\r\n                           period)}}  + 1 as num_periods\r\n    from data\r\n  {%- endcall %}\r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_period_sql": {"unique_id": "macro.dbt_utils.get_period_sql", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\materializations\\insert_by_period_materialization.sql", "original_file_path": "macros\\materializations\\insert_by_period_materialization.sql", "name": "get_period_sql", "macro_sql": "{% macro get_period_sql(target_cols_csv, sql, timestamp_field, period, start_timestamp, stop_timestamp, offset) -%}\r\n\r\n  {%- set period_filter -%}\r\n    (\"{{timestamp_field}}\" >  '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' and\r\n     \"{{timestamp_field}}\" <= '{{start_timestamp}}'::timestamp + interval '{{offset}} {{period}}' + interval '1 {{period}}' and\r\n     \"{{timestamp_field}}\" <  '{{stop_timestamp}}'::timestamp)\r\n  {%- endset -%}\r\n\r\n  {%- set filtered_sql = sql | replace(\"__PERIOD_FILTER__\", period_filter) -%}\r\n\r\n  select\r\n    {{target_cols_csv}}\r\n  from (\r\n    {{filtered_sql}}\r\n  )\r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.materialization_insert_by_period_default": {"unique_id": "macro.dbt_utils.materialization_insert_by_period_default", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\materializations\\insert_by_period_materialization.sql", "original_file_path": "macros\\materializations\\insert_by_period_materialization.sql", "name": "materialization_insert_by_period_default", "macro_sql": "{% materialization insert_by_period, default -%}\r\n  {%- set timestamp_field = config.require('timestamp_field') -%}\r\n  {%- set start_date = config.require('start_date') -%}\r\n  {%- set stop_date = config.get('stop_date') or '' -%}}\r\n  {%- set period = config.get('period') or 'week' -%}\r\n\r\n  {%- if sql.find('__PERIOD_FILTER__') == -1 -%}\r\n    {%- set error_message -%}\r\n      Model '{{ model.unique_id }}' does not include the required string '__PERIOD_FILTER__' in its sql\r\n    {%- endset -%}\r\n    {{ exceptions.raise_compiler_error(error_message) }}\r\n  {%- endif -%}\r\n\r\n  {%- set identifier = model['name'] -%}\r\n\r\n  {%- set old_relation = adapter.get_relation(database=database, schema=schema, identifier=identifier) -%}\r\n  {%- set target_relation = api.Relation.create(identifier=identifier, schema=schema, type='table') -%}\r\n\r\n  {%- set non_destructive_mode = (flags.NON_DESTRUCTIVE == True) -%}\r\n  {%- set full_refresh_mode = (flags.FULL_REFRESH == True) -%}\r\n\r\n  {%- set exists_as_table = (old_relation is not none and old_relation.is_table) -%}\r\n  {%- set exists_not_as_table = (old_relation is not none and not old_relation.is_table) -%}\r\n\r\n  {%- set should_truncate = (non_destructive_mode and full_refresh_mode and exists_as_table) -%}\r\n  {%- set should_drop = (not should_truncate and (full_refresh_mode or exists_not_as_table)) -%}\r\n  {%- set force_create = (flags.FULL_REFRESH and not flags.NON_DESTRUCTIVE) -%}\r\n\r\n  -- setup\r\n  {% if old_relation is none -%}\r\n    -- noop\r\n  {%- elif should_truncate -%}\r\n    {{adapter.truncate_relation(old_relation)}}\r\n  {%- elif should_drop -%}\r\n    {{adapter.drop_relation(old_relation)}}\r\n    {%- set old_relation = none -%}\r\n  {%- endif %}\r\n\r\n  {{run_hooks(pre_hooks, inside_transaction=False)}}\r\n\r\n  -- `begin` happens here, so `commit` after it to finish the transaction\r\n  {{run_hooks(pre_hooks, inside_transaction=True)}}\r\n  {% call statement() -%}\r\n    begin; -- make extra sure we've closed out the transaction\r\n    commit;\r\n  {%- endcall %}\r\n\r\n  -- build model\r\n  {% if force_create or old_relation is none -%}\r\n    {# Create an empty target table -#}\r\n    {% call statement('main') -%}\r\n      {%- set empty_sql = sql | replace(\"__PERIOD_FILTER__\", 'false') -%}\r\n      {{create_table_as(False, target_relation, empty_sql)}};\r\n    {%- endcall %}\r\n  {%- endif %}\r\n\r\n  {% set _ = dbt_utils.get_period_boundaries(schema,\r\n                                              identifier,\r\n                                              timestamp_field,\r\n                                              start_date,\r\n                                              stop_date,\r\n                                              period) %}\r\n  {%- set start_timestamp = load_result('period_boundaries')['data'][0][0] | string -%}\r\n  {%- set stop_timestamp = load_result('period_boundaries')['data'][0][1] | string -%}\r\n  {%- set num_periods = load_result('period_boundaries')['data'][0][2] | int -%}\r\n\r\n  {% set target_columns = adapter.get_columns_in_relation(target_relation) %}\r\n  {%- set target_cols_csv = target_columns | map(attribute='quoted') | join(', ') -%}\r\n  {%- set loop_vars = {'sum_rows_inserted': 0} -%}\r\n\r\n  -- commit each period as a separate transaction\r\n  {% for i in range(num_periods) -%}\r\n    {%- set msg = \"Running for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) -%}\r\n    {{ dbt_utils.log_info(msg) }}\r\n\r\n    {%- set tmp_identifier = model['name'] ~ '__dbt_incremental_period' ~ i ~ '_tmp' -%}\r\n    {%- set tmp_relation = api.Relation.create(identifier=tmp_identifier,\r\n                                               schema=schema, type='table') -%}\r\n    {% call statement() -%}\r\n      {% set tmp_table_sql = dbt_utils.get_period_sql(target_cols_csv,\r\n                                                       sql,\r\n                                                       timestamp_field,\r\n                                                       period,\r\n                                                       start_timestamp,\r\n                                                       stop_timestamp,\r\n                                                       i) %}\r\n      {{dbt.create_table_as(True, tmp_relation, tmp_table_sql)}}\r\n    {%- endcall %}\r\n\r\n    {{adapter.expand_target_column_types(from_relation=tmp_relation,\r\n                                         to_relation=target_relation)}}\r\n    {%- set name = 'main-' ~ i -%}\r\n    {% call statement(name, fetch_result=True) -%}\r\n      insert into {{target_relation}} ({{target_cols_csv}})\r\n      (\r\n          select\r\n              {{target_cols_csv}}\r\n          from {{tmp_relation.include(schema=False)}}\r\n      );\r\n    {%- endcall %}\r\n    {%- set rows_inserted = (load_result('main-' ~ i)['status'].split(\" \"))[2] | int -%}\r\n    {%- set sum_rows_inserted = loop_vars['sum_rows_inserted'] + rows_inserted -%}\r\n    {%- if loop_vars.update({'sum_rows_inserted': sum_rows_inserted}) %} {% endif -%}\r\n\r\n    {%- set msg = \"Ran for \" ~ period ~ \" \" ~ (i + 1) ~ \" of \" ~ (num_periods) ~ \"; \" ~ rows_inserted ~ \" records inserted\" -%}\r\n    {{ dbt_utils.log_info(msg) }}\r\n\r\n  {%- endfor %}\r\n\r\n  {% call statement() -%}\r\n    begin;\r\n  {%- endcall %}\r\n\r\n  {{run_hooks(post_hooks, inside_transaction=True)}}\r\n\r\n  {% call statement() -%}\r\n    commit;\r\n  {%- endcall %}\r\n\r\n  {{run_hooks(post_hooks, inside_transaction=False)}}\r\n\r\n  {%- set status_string = \"INSERT \" ~ loop_vars['sum_rows_inserted'] -%}\r\n\r\n  {% call noop_statement(name='main', status=status_string) -%}\r\n    -- no-op\r\n  {%- endcall %}\r\n\r\n  -- Return the relations created in this materialization\r\n  {{ return({'relations': [target_relation]}) }}  \r\n\r\n{%- endmaterialization %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_at_least_one": {"unique_id": "macro.dbt_utils.test_at_least_one", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\at_least_one.sql", "original_file_path": "macros\\schema_tests\\at_least_one.sql", "name": "test_at_least_one", "macro_sql": "{% macro test_at_least_one(model) %}\r\n\r\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\r\n\r\nselect count(*)\r\nfrom (\r\n    select\r\n\r\n      count({{ column_name }})\r\n\r\n    from {{ model }}\r\n\r\n    having count({{ column_name }}) = 0\r\n\r\n) validation_errors\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_cardinality_equality": {"unique_id": "macro.dbt_utils.test_cardinality_equality", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\cardinality_equality.sql", "original_file_path": "macros\\schema_tests\\cardinality_equality.sql", "name": "test_cardinality_equality", "macro_sql": "{% macro test_cardinality_equality(model, to, field) %}\r\n\r\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\r\n\r\n\r\nwith table_a as (\r\nselect\r\n  {{ column_name }},\r\n  count(*) as num_rows\r\nfrom {{ model }}\r\ngroup by 1\r\n),\r\n\r\ntable_b as (\r\nselect\r\n  {{ field }},\r\n  count(*) as num_rows\r\nfrom {{ to }}\r\ngroup by 1\r\n),\r\n\r\nexcept_a as (\r\n  select *\r\n  from table_a\r\n  {{ dbt_utils.except() }}\r\n  select *\r\n  from table_b\r\n),\r\n\r\nexcept_b as (\r\n  select *\r\n  from table_b\r\n  {{ dbt_utils.except() }}\r\n  select *\r\n  from table_a\r\n),\r\n\r\nunioned as (\r\n  select *\r\n  from except_a\r\n  union all\r\n  select *\r\n  from except_b\r\n)\r\n\r\nselect count(*)\r\nfrom unioned\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_equality": {"unique_id": "macro.dbt_utils.test_equality", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\equality.sql", "original_file_path": "macros\\schema_tests\\equality.sql", "name": "test_equality", "macro_sql": "{% macro test_equality(model) %}\r\n\r\n\r\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\r\n{%- if not execute -%}\r\n    {{ return('') }}\r\n{% endif %}\r\n\r\n-- setup\r\n{%- do dbt_utils._is_relation(model, 'test_equality') -%}\r\n\r\n{#-\r\nIf the compare_cols arg is provided, we can run this test without querying the\r\ninformation schema\u00a0\u2014 this allows the model to be an ephemeral model\r\n-#}\r\n{%- if not kwargs.get('compare_columns', None) -%}\r\n    {%- do dbt_utils._is_ephemeral(model, 'test_equality') -%}\r\n{%- endif -%}\r\n\r\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\r\n{% set compare_columns = kwargs.get('compare_columns', adapter.get_columns_in_relation(model) | map(attribute='quoted') ) %}\r\n{% set compare_cols_csv = compare_columns | join(', ') %}\r\n\r\nwith a as (\r\n\r\n    select * from {{ model }}\r\n\r\n),\r\n\r\nb as (\r\n\r\n    select * from {{ compare_model }}\r\n\r\n),\r\n\r\na_minus_b as (\r\n\r\n    select {{compare_cols_csv}} from a\r\n    {{ dbt_utils.except() }}\r\n    select {{compare_cols_csv}} from b\r\n\r\n),\r\n\r\nb_minus_a as (\r\n\r\n    select {{compare_cols_csv}} from b\r\n    {{ dbt_utils.except() }}\r\n    select {{compare_cols_csv}} from a\r\n\r\n),\r\n\r\nunioned as (\r\n\r\n    select * from a_minus_b\r\n    union all\r\n    select * from b_minus_a\r\n\r\n),\r\n\r\nfinal as (\r\n\r\n    select (select count(*) from unioned) +\r\n        (select abs(\r\n            (select count(*) from a_minus_b) -\r\n            (select count(*) from b_minus_a)\r\n            ))\r\n        as count\r\n\r\n)\r\n\r\nselect count from final\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_equal_rowcount": {"unique_id": "macro.dbt_utils.test_equal_rowcount", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\equal_rowcount.sql", "original_file_path": "macros\\schema_tests\\equal_rowcount.sql", "name": "test_equal_rowcount", "macro_sql": "{% macro test_equal_rowcount(model) %}\r\n\r\n{% set compare_model = kwargs.get('compare_model', kwargs.get('arg')) %}\r\n\r\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\r\n{%- if not execute -%}\r\n    {{ return('') }}\r\n{% endif %}\r\n\r\nwith a as (\r\n\r\n    select count(*) as count_a from {{ model }}\r\n\r\n),\r\nb as (\r\n\r\n    select count(*) as count_b from {{ compare_model }}\r\n\r\n),\r\nfinal as (\r\n\r\n    select abs(\r\n            (select count_a from a) -\r\n            (select count_b from b)\r\n            )\r\n        as diff_count\r\n\r\n)\r\n\r\nselect diff_count from final\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_expression_is_true": {"unique_id": "macro.dbt_utils.test_expression_is_true", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\expression_is_true.sql", "original_file_path": "macros\\schema_tests\\expression_is_true.sql", "name": "test_expression_is_true", "macro_sql": "{% macro test_expression_is_true(model, condition='true') %}\r\n\r\n{% set expression = kwargs.get('expression', kwargs.get('arg')) %}\r\n\r\nwith meet_condition as (\r\n\r\n    select * from {{ model }} where {{ condition }}\r\n\r\n),\r\nvalidation_errors as (\r\n\r\n    select\r\n        *\r\n    from meet_condition\r\n    where not({{expression}})\r\n\r\n)\r\n\r\nselect count(*)\r\nfrom validation_errors\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_mutually_exclusive_ranges": {"unique_id": "macro.dbt_utils.test_mutually_exclusive_ranges", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\mutually_exclusive_ranges.sql", "original_file_path": "macros\\schema_tests\\mutually_exclusive_ranges.sql", "name": "test_mutually_exclusive_ranges", "macro_sql": "{% macro test_mutually_exclusive_ranges(model, lower_bound_column, upper_bound_column, partition_by=None, gaps='allowed') %}\r\n\r\n{% if gaps == 'not_allowed' %}\r\n    {% set allow_gaps_operator='=' %}\r\n    {% set allow_gaps_operator_in_words='equal_to' %}\r\n{% elif gaps == 'allowed' %}\r\n    {% set allow_gaps_operator='<=' %}\r\n    {% set allow_gaps_operator_in_words='less_than_or_equal_to' %}\r\n{% elif gaps == 'required' %}\r\n    {% set allow_gaps_operator='<' %}\r\n    {% set allow_gaps_operator_in_words='less_than' %}\r\n{% else %}\r\n    {{ exceptions.raise_compiler_error(\r\n        \"`gaps` argument for mutually_exclusive_ranges test must be one of ['not_allowed', 'allowed', 'required'] Got: '\" ~ gaps ~\"'.'\"\r\n    ) }}\r\n\r\n{% endif %}\r\n\r\n{% set partition_clause=\"partition by \" ~ partition_by if partition_by else '' %}\r\n\r\nwith window_functions as (\r\n\r\n    select\r\n        {% if partition_by %}\r\n        {{ partition_by }},\r\n        {% endif %}\r\n        {{ lower_bound_column }} as lower_bound,\r\n        {{ upper_bound_column }} as upper_bound,\r\n\r\n        lead({{ lower_bound_column }}) over (\r\n            {{ partition_clause }}\r\n            order by {{ lower_bound_column }}\r\n        ) as next_lower_bound,\r\n\r\n        row_number() over (\r\n            {{ partition_clause }}\r\n            order by {{ lower_bound_column }} desc\r\n        ) = 1 as is_last_record\r\n\r\n    from {{ model }}\r\n\r\n),\r\n\r\ncalc as (\r\n    -- We want to return records where one of our assumptions fails, so we'll use\r\n    -- the `not` function with `and` statements so we can write our assumptions nore cleanly\r\n    select\r\n        *,\r\n\r\n        -- For each record: lower_bound should be < upper_bound.\r\n        -- Coalesce it to return an error on the null case (implicit assumption\r\n        -- these columns are not_null)\r\n        coalesce(\r\n            lower_bound < upper_bound,\r\n            false\r\n        ) as lower_bound_less_than_upper_bound,\r\n\r\n        -- For each record: upper_bound {{ allow_gaps_operator }} the next lower_bound.\r\n        -- Coalesce it to handle null cases for the last record.\r\n        coalesce(\r\n            upper_bound {{ allow_gaps_operator }} next_lower_bound,\r\n            is_last_record,\r\n            false\r\n        ) as upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\r\n\r\n    from window_functions\r\n\r\n),\r\n\r\nvalidation_errors as (\r\n\r\n    select\r\n        *\r\n    from calc\r\n\r\n    where not(\r\n        -- THE FOLLOWING SHOULD BE TRUE --\r\n        lower_bound_less_than_upper_bound\r\n        and upper_bound_{{ allow_gaps_operator_in_words }}_next_lower_bound\r\n    )\r\n)\r\n\r\nselect count(*) from validation_errors\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_not_constant": {"unique_id": "macro.dbt_utils.test_not_constant", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\not_constant.sql", "original_file_path": "macros\\schema_tests\\not_constant.sql", "name": "test_not_constant", "macro_sql": "{% macro test_not_constant(model) %}\r\n\r\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\r\n\r\nselect count(*)\r\n\r\nfrom (\r\n\r\n    select\r\n          count(distinct {{ column_name }})\r\n\r\n    from {{ model }}\r\n\r\n    having count(distinct {{ column_name }}) = 1\r\n\r\n    ) validation_errors\r\n\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_recency": {"unique_id": "macro.dbt_utils.test_recency", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\recency.sql", "original_file_path": "macros\\schema_tests\\recency.sql", "name": "test_recency", "macro_sql": "{% macro test_recency(model, datepart, interval) %}\r\n\r\n{% set column_name = kwargs.get('column_name', kwargs.get('field')) %}\r\n\r\nselect\r\n    case when count(*) > 0 then 0\r\n    else 1\r\n    end as error_result\r\nfrom {{model}}\r\nwhere {{column_name}} >=\r\n    {{dbt_utils.dateadd(datepart, interval * -1, dbt_utils.current_timestamp())}}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_relationships_where": {"unique_id": "macro.dbt_utils.test_relationships_where", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\relationships_where.sql", "original_file_path": "macros\\schema_tests\\relationships_where.sql", "name": "test_relationships_where", "macro_sql": "{% macro test_relationships_where(model, to, field) %}\r\n\r\n{% set column_name = kwargs.get('column_name', kwargs.get('from')) %}\r\n{% set from_condition = kwargs.get('from_condition', \"true\") %}\r\n{% set to_condition = kwargs.get('to_condition', \"true\") %}\r\n\r\nwith left_table as (\r\n\r\n  select\r\n    {{column_name}} as id\r\n\r\n  from {{model}}\r\n\r\n  where {{column_name}} is not null\r\n    and {{from_condition}}\r\n\r\n),\r\n\r\nright_table as (\r\n\r\n  select\r\n    {{field}} as id\r\n\r\n  from {{to}}\r\n\r\n  where {{field}} is not null\r\n    and {{to_condition}}\r\n\r\n),\r\n\r\nexceptions as (\r\n\r\n  select\r\n    left_table.id,\r\n    right_table.id as right_id\r\n\r\n  from left_table\r\n\r\n  left join right_table\r\n         on left_table.id = right_table.id\r\n\r\n  where right_table.id is null\r\n\r\n)\r\n\r\nselect count(*) from exceptions\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_not_null_where": {"unique_id": "macro.dbt_utils.test_not_null_where", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\test_not_null_where.sql", "original_file_path": "macros\\schema_tests\\test_not_null_where.sql", "name": "test_not_null_where", "macro_sql": "{% macro test_not_null_where(model) %}\r\n\r\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\r\n{% set where = kwargs.get('where', kwargs.get('arg')) %}\r\n\r\nselect count(*)\r\nfrom {{ model }}\r\nwhere {{ column_name }} is null\r\n{% if where %} and {{ where }} {% endif %}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_unique_where": {"unique_id": "macro.dbt_utils.test_unique_where", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\test_unique_where.sql", "original_file_path": "macros\\schema_tests\\test_unique_where.sql", "name": "test_unique_where", "macro_sql": "{% macro test_unique_where(model) %}\r\n\r\n{% set column_name = kwargs.get('column_name', kwargs.get('arg')) %}\r\n{% set where = kwargs.get('where', kwargs.get('arg')) %}\r\n\r\nselect count(*)\r\nfrom (\r\n\r\n    select\r\n        {{ column_name }}\r\n\r\n    from {{ model }}\r\n    where {{ column_name }} is not null\r\n      {% if where %} and {{ where }} {% endif %}\r\n    group by {{ column_name }}\r\n    having count(*) > 1\r\n\r\n) validation_errors\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.test_unique_combination_of_columns": {"unique_id": "macro.dbt_utils.test_unique_combination_of_columns", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\schema_tests\\unique_combination_of_columns.sql", "original_file_path": "macros\\schema_tests\\unique_combination_of_columns.sql", "name": "test_unique_combination_of_columns", "macro_sql": "{% macro test_unique_combination_of_columns(model, quote_columns = false) %}\r\n\r\n{%- set columns = kwargs.get('combination_of_columns', kwargs.get('arg')) %}\r\n\r\n{% if not quote_columns %}\r\n    {%- set column_list=columns %}\r\n{% elif quote_columns %}\r\n    {%- set column_list=[] %}\r\n        {% for column in columns -%}\r\n            {% set column_list = column_list.append( adapter.quote(column) ) %}\r\n        {%- endfor %}\r\n{% else %}\r\n    {{ exceptions.raise_compiler_error(\r\n        \"`quote_columns` argument for unique_combination_of_columns test must be one of [True, False] Got: '\" ~ quote ~\"'.'\"\r\n    ) }}\r\n{% endif %}\r\n\r\n{%- set columns_csv=column_list | join(', ') %}\r\n\r\n\r\nwith validation_errors as (\r\n\r\n    select\r\n        {{ columns_csv }}\r\n    from {{ model }}\r\n\r\n    group by {{ columns_csv }}\r\n    having count(*) > 1\r\n\r\n)\r\n\r\nselect count(*)\r\nfrom validation_errors\r\n\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_powers_of_two": {"unique_id": "macro.dbt_utils.get_powers_of_two", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\generate_series.sql", "original_file_path": "macros\\sql\\generate_series.sql", "name": "get_powers_of_two", "macro_sql": "{% macro get_powers_of_two(upper_bound) %}\r\n\r\n    {% if upper_bound <= 0 %}\r\n    {{ exceptions.raise_compiler_error(\"upper bound must be positive\") }}\r\n    {% endif %}\r\n\r\n    {% for _ in range(1, 100) %}\r\n       {% if upper_bound <= 2 ** loop.index %}{{ return(loop.index) }}{% endif %}\r\n    {% endfor %}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.generate_series": {"unique_id": "macro.dbt_utils.generate_series", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\generate_series.sql", "original_file_path": "macros\\sql\\generate_series.sql", "name": "generate_series", "macro_sql": "{% macro generate_series(upper_bound) %}\r\n\r\n    {% set n = dbt_utils.get_powers_of_two(upper_bound) %}\r\n\r\n    with p as (\r\n        select 0 as generated_number union all select 1\r\n    ), unioned as (\r\n\r\n    select\r\n\r\n    {% for i in range(n) %}\r\n    p{{i}}.generated_number * pow(2, {{i}})\r\n    {% if not loop.last %} + {% endif %}\r\n    {% endfor %}\r\n    + 1\r\n    as generated_number\r\n\r\n    from\r\n\r\n    {% for i in range(n) %}\r\n    p as p{{i}}\r\n    {% if not loop.last %} cross join {% endif %}\r\n    {% endfor %}\r\n\r\n    )\r\n\r\n    select *\r\n    from unioned\r\n    where generated_number <= {{upper_bound}}\r\n    order by generated_number\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_column_values": {"unique_id": "macro.dbt_utils.get_column_values", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_column_values.sql", "original_file_path": "macros\\sql\\get_column_values.sql", "name": "get_column_values", "macro_sql": "{% macro get_column_values(table, column, max_records=none, default=none) -%}\r\n\r\n{#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\r\n    {%- if not execute -%}\r\n        {{ return('') }}\r\n    {% endif %}\r\n{#--  #}\r\n\r\n    {%- set target_relation = adapter.get_relation(database=table.database,\r\n                                          schema=table.schema,\r\n                                         identifier=table.identifier) -%}\r\n\r\n    {%- call statement('get_column_values', fetch_result=true) %}\r\n\r\n        {%- if not target_relation and default is none -%}\r\n\r\n          {{ exceptions.raise_compiler_error(\"In get_column_values(): relation \" ~ table ~ \" does not exist and no default value was provided.\") }}\r\n\r\n        {%- elif not target_relation and default is not none -%}\r\n\r\n          {{ log(\"Relation \" ~ table ~ \" does not exist. Returning the default value: \" ~ default) }}\r\n\r\n          {{ return(default) }}\r\n\r\n        {%- else -%}\r\n\r\n            select\r\n                {{ column }} as value\r\n\r\n            from {{ target_relation }}\r\n            group by 1\r\n            order by count(*) desc\r\n\r\n            {% if max_records is not none %}\r\n            limit {{ max_records }}\r\n            {% endif %}\r\n\r\n        {% endif %}\r\n\r\n    {%- endcall -%}\r\n\r\n    {%- set value_list = load_result('get_column_values') -%}\r\n\r\n    {%- if value_list and value_list['data'] -%}\r\n        {%- set values = value_list['data'] | map(attribute=0) | list %}\r\n        {{ return(values) }}\r\n    {%- else -%}\r\n        {{ return(default) }}\r\n    {%- endif -%}\r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_query_results_as_dict": {"unique_id": "macro.dbt_utils.get_query_results_as_dict", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_query_results_as_dict.sql", "original_file_path": "macros\\sql\\get_query_results_as_dict.sql", "name": "get_query_results_as_dict", "macro_sql": "{% macro get_query_results_as_dict(query) %}\r\n{# This macro returns a dictionary of the form {column_name: (tuple_of_results)} #}\r\n\r\n    {%- call statement('get_query_results', fetch_result=True,auto_begin=false) -%}\r\n\r\n        {{ query }}\r\n\r\n    {%- endcall -%}\r\n\r\n    {% set sql_results={} %}\r\n\r\n    {%- if execute -%}\r\n        {% set sql_results_table = load_result('get_query_results').table.columns %}\r\n        {% for column_name, column in sql_results_table.items() %}\r\n            {% do sql_results.update({column_name: column.values()}) %}\r\n        {% endfor %}\r\n    {%- endif -%}\r\n\r\n    {{ return(sql_results) }}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_relations_by_pattern": {"unique_id": "macro.dbt_utils.get_relations_by_pattern", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_relations_by_pattern.sql", "original_file_path": "macros\\sql\\get_relations_by_pattern.sql", "name": "get_relations_by_pattern", "macro_sql": "{% macro get_relations_by_pattern(schema_pattern, table_pattern, exclude='', database=target.database) %}\r\n\r\n    {%- call statement('get_tables', fetch_result=True) %}\r\n\r\n      {{ dbt_utils.get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude, database) }}\r\n\r\n    {%- endcall -%}\r\n\r\n    {%- set table_list = load_result('get_tables') -%}\r\n\r\n    {%- if table_list and table_list['table'] -%}\r\n        {%- set tbl_relations = [] -%}\r\n        {%- for row in table_list['table'] -%}\r\n            {%- set tbl_relation = api.Relation.create(database, row.table_schema, row.table_name) -%}\r\n            {%- do tbl_relations.append(tbl_relation) -%}\r\n        {%- endfor -%}\r\n\r\n        {{ return(tbl_relations) }}\r\n    {%- else -%}\r\n        {{ return([]) }}\r\n    {%- endif -%}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_relations_by_prefix": {"unique_id": "macro.dbt_utils.get_relations_by_prefix", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_relations_by_prefix.sql", "original_file_path": "macros\\sql\\get_relations_by_prefix.sql", "name": "get_relations_by_prefix", "macro_sql": "{% macro get_relations_by_prefix(schema, prefix, exclude='', database=target.database) %}\r\n\r\n    {%- call statement('get_tables', fetch_result=True) %}\r\n\r\n      {{ dbt_utils.get_tables_by_prefix_sql(schema, prefix, exclude, database) }}\r\n\r\n    {%- endcall -%}\r\n\r\n    {%- set table_list = load_result('get_tables') -%}\r\n\r\n    {%- if table_list and table_list['table'] -%}\r\n        {%- set tbl_relations = [] -%}\r\n        {%- for row in table_list['table'] -%}\r\n            {%- set tbl_relation = api.Relation.create(database, row.table_schema, row.table_name) -%}\r\n            {%- do tbl_relations.append(tbl_relation) -%}\r\n        {%- endfor -%}\r\n\r\n        {{ return(tbl_relations) }}\r\n    {%- else -%}\r\n        {{ return([]) }}\r\n    {%- endif -%}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_tables_by_pattern_sql": {"unique_id": "macro.dbt_utils.get_tables_by_pattern_sql", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_tables_by_pattern_sql.sql", "original_file_path": "macros\\sql\\get_tables_by_pattern_sql.sql", "name": "get_tables_by_pattern_sql", "macro_sql": "{% macro get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\r\n    {{ adapter.dispatch('get_tables_by_pattern_sql', packages = dbt_utils._get_utils_namespaces())\r\n        (schema_pattern, table_pattern, exclude, database) }}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.default__get_tables_by_pattern_sql": {"unique_id": "macro.dbt_utils.default__get_tables_by_pattern_sql", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_tables_by_pattern_sql.sql", "original_file_path": "macros\\sql\\get_tables_by_pattern_sql.sql", "name": "default__get_tables_by_pattern_sql", "macro_sql": "{% macro default__get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\r\n\r\n        select distinct\r\n            table_schema as \"table_schema\", table_name as \"table_name\"\r\n        from {{database}}.information_schema.tables\r\n        where table_schema ilike '{{ schema_pattern }}'\r\n        and table_name ilike '{{ table_pattern }}'\r\n        and table_name not ilike '{{ exclude }}'\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.bigquery__get_tables_by_pattern_sql": {"unique_id": "macro.dbt_utils.bigquery__get_tables_by_pattern_sql", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_tables_by_pattern_sql.sql", "original_file_path": "macros\\sql\\get_tables_by_pattern_sql.sql", "name": "bigquery__get_tables_by_pattern_sql", "macro_sql": "{% macro bigquery__get_tables_by_pattern_sql(schema_pattern, table_pattern, exclude='', database=target.database) %}\r\n\r\n    {% if '%' in schema_pattern %}\r\n        {% set schemata=dbt_utils._bigquery__get_matching_schemata(schema_pattern, database) %}\r\n    {% else %}\r\n        {% set schemata=[schema_pattern] %}\r\n    {% endif %}\r\n\r\n    {% set sql %}\r\n        {% for schema in schemata %}\r\n            select distinct\r\n                table_schema, table_name\r\n\r\n            from {{ adapter.quote(database) }}.{{ schema }}.INFORMATION_SCHEMA.TABLES\r\n            where lower(table_name) like lower ('{{ table_pattern }}')\r\n                and lower(table_name) not like lower ('{{ exclude }}')\r\n\r\n            {% if not loop.last %} union all {% endif %}\r\n\r\n        {% endfor %}\r\n    {% endset %}\r\n\r\n    {{ return(sql) }}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils._bigquery__get_matching_schemata": {"unique_id": "macro.dbt_utils._bigquery__get_matching_schemata", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_tables_by_pattern_sql.sql", "original_file_path": "macros\\sql\\get_tables_by_pattern_sql.sql", "name": "_bigquery__get_matching_schemata", "macro_sql": "{% macro _bigquery__get_matching_schemata(schema_pattern, database) %}\r\n    {% if execute %}\r\n\r\n        {% set sql %}\r\n        select schema_name from {{ adapter.quote(database) }}.INFORMATION_SCHEMA.SCHEMATA\r\n        where lower(schema_name) like lower('{{ schema_pattern }}')\r\n        {% endset %}\r\n\r\n        {% set results=run_query(sql) %}\r\n\r\n        {% set schemata=results.columns['schema_name'].values() %}\r\n\r\n        {{ return(schemata) }}\r\n\r\n    {% else %}\r\n\r\n        {{ return([]) }}\r\n\r\n    {% endif %}\r\n\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_tables_by_prefix_sql": {"unique_id": "macro.dbt_utils.get_tables_by_prefix_sql", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\get_tables_by_prefix_sql.sql", "original_file_path": "macros\\sql\\get_tables_by_prefix_sql.sql", "name": "get_tables_by_prefix_sql", "macro_sql": "{% macro get_tables_by_prefix_sql(schema, prefix, exclude='', database=target.database) %}\r\n    \r\n    {{ dbt_utils.get_tables_by_pattern_sql(\r\n        schema_pattern = schema,\r\n        table_pattern = prefix ~ '%',\r\n        exclude = exclude,\r\n        database = database\r\n    ) }}\r\n    \r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.group_by": {"unique_id": "macro.dbt_utils.group_by", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\groupby.sql", "original_file_path": "macros\\sql\\groupby.sql", "name": "group_by", "macro_sql": "{%- macro group_by(n) -%}\r\n\r\n  group by {% for i in range(1, n + 1) -%}\r\n      {{ i }}{{ ',' if not loop.last }}   \r\n   {%- endfor -%}\r\n\r\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.nullcheck": {"unique_id": "macro.dbt_utils.nullcheck", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\nullcheck.sql", "original_file_path": "macros\\sql\\nullcheck.sql", "name": "nullcheck", "macro_sql": "{% macro nullcheck(cols) %}\r\n{%- for col in cols %}\r\n\r\n    {% if col.is_string() -%}\r\n\r\n    nullif({{col.name}},'') as {{col.name}}\r\n\r\n    {%- else -%}\r\n\r\n    {{col.name}}\r\n\r\n    {%- endif -%}\r\n\r\n{%- if not loop.last -%} , {%- endif -%}\r\n\r\n{%- endfor -%}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.nullcheck_table": {"unique_id": "macro.dbt_utils.nullcheck_table", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\nullcheck_table.sql", "original_file_path": "macros\\sql\\nullcheck_table.sql", "name": "nullcheck_table", "macro_sql": "{% macro nullcheck_table(relation) %}\r\n\r\n  {%- do dbt_utils._is_relation(relation, 'nullcheck_table') -%}\r\n  {%- do dbt_utils._is_ephemeral(relation, 'nullcheck_table') -%}\r\n  {% set cols = adapter.get_columns_in_relation(relation) %}\r\n\r\n  select {{ dbt_utils.nullcheck(cols) }}\r\n  from {{relation}}\r\n\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.pivot": {"unique_id": "macro.dbt_utils.pivot", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\pivot.sql", "original_file_path": "macros\\sql\\pivot.sql", "name": "pivot", "macro_sql": "{% macro pivot(column,\r\n               values,\r\n               alias=True,\r\n               agg='sum',\r\n               cmp='=',\r\n               prefix='',\r\n               suffix='',\r\n               then_value=1,\r\n               else_value=0,\r\n               quote_identifiers=True,\r\n               distinct=False) %}\r\n  {% for v in values %}\r\n    {{ agg }}(\r\n      {% if distinct %} distinct {% endif %}\r\n      case\r\n      when {{ column }} {{ cmp }} '{{ v }}'\r\n        then {{ then_value }}\r\n      else {{ else_value }}\r\n      end\r\n    )\r\n    {% if alias %}\r\n      {% if quote_identifiers %}\r\n            as {{ adapter.quote(prefix ~ v ~ suffix) }}\r\n      {% else %}\r\n        as {{prefix ~ v ~ suffix }}\r\n      {% endif %}\r\n    {% endif %}\r\n    {% if not loop.last %},{% endif %}\r\n  {% endfor %}\r\n{% endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.safe_add": {"unique_id": "macro.dbt_utils.safe_add", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\safe_add.sql", "original_file_path": "macros\\sql\\safe_add.sql", "name": "safe_add", "macro_sql": "{%- macro safe_add() -%}\r\n\r\n{% set fields = [] %}\r\n\r\n{%- for field in varargs -%}\r\n\r\n    {% do fields.append(\"coalesce(\" ~ field ~ \", 0)\") %}\r\n\r\n{%- endfor -%}\r\n\r\n{{ fields|join(' +\\n  ') }}\r\n\r\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.star": {"unique_id": "macro.dbt_utils.star", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\star.sql", "original_file_path": "macros\\sql\\star.sql", "name": "star", "macro_sql": "{% macro star(from, relation_alias=False, except=[]) -%}\r\n\r\n    {%- do dbt_utils._is_relation(from, 'star') -%}\r\n    {%- do dbt_utils._is_ephemeral(from, 'star') -%}\r\n\r\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. #}\r\n    {%- if not execute -%}\r\n        {{ return('') }}\r\n    {% endif %}\r\n\r\n    {%- set include_cols = [] %}\r\n    {%- set cols = adapter.get_columns_in_relation(from) -%}\r\n\r\n    {%- for col in cols -%}\r\n\r\n        {%- if col.column not in except -%}\r\n            {% do include_cols.append(col.column) %}\r\n\r\n        {%- endif %}\r\n    {%- endfor %}\r\n\r\n    {%- for col in include_cols %}\r\n\r\n        {%- if relation_alias %}{{ relation_alias }}.{% else %}{%- endif -%}{{ adapter.quote(col)|trim }}\r\n        {%- if not loop.last %},{{ '\\n  ' }}{% endif %}\r\n\r\n    {%- endfor -%}\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.surrogate_key": {"unique_id": "macro.dbt_utils.surrogate_key", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\surrogate_key.sql", "original_file_path": "macros\\sql\\surrogate_key.sql", "name": "surrogate_key", "macro_sql": "{%- macro surrogate_key(field_list) -%}\r\n\r\n{%- if varargs|length >= 1 or field_list is string %}\r\n\r\n{%- set error_message = '\r\nWarning: the `surrogate_key` macro now takes a single list argument instead of \\\r\nmultiple string arguments. Support for multiple string arguments will be \\\r\ndeprecated in a future release of dbt-utils. The {}.{} model triggered this warning. \\\r\n'.format(model.package_name, model.name) -%}\r\n\r\n{%- do exceptions.warn(error_message) -%}\r\n\r\n{# first argument is not included in varargs, so add first element to field_list_xf #}\r\n{%- set field_list_xf = [field_list] -%}\r\n\r\n{%- for field in varargs %}\r\n{%- set _ = field_list_xf.append(field) -%}\r\n{%- endfor -%}\r\n\r\n{%- else -%}\r\n\r\n{# if using list, just set field_list_xf as field_list #}\r\n{%- set field_list_xf = field_list -%}\r\n\r\n{%- endif -%}\r\n\r\n\r\n{%- set fields = [] -%}\r\n\r\n{%- for field in field_list_xf -%}\r\n\r\n    {%- set _ = fields.append(\r\n        \"coalesce(cast(\" ~ field ~ \" as \" ~ dbt_utils.type_string() ~ \"), '')\"\r\n    ) -%}\r\n\r\n    {%- if not loop.last %}\r\n        {%- set _ = fields.append(\"'-'\") -%}\r\n    {%- endif -%}\r\n\r\n{%- endfor -%}\r\n\r\n{{dbt_utils.hash(dbt_utils.concat(fields))}}\r\n\r\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.union_relations": {"unique_id": "macro.dbt_utils.union_relations", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\union.sql", "original_file_path": "macros\\sql\\union.sql", "name": "union_relations", "macro_sql": "{%- macro union_relations(relations, column_override=none, include=[], exclude=[], source_column_name='_dbt_source_relation') -%}\r\n\r\n    {%- if exclude and include -%}\r\n        {{ exceptions.raise_compiler_error(\"Both an exclude and include list were provided to the `union` macro. Only one is allowed\") }}\r\n    {%- endif -%}\r\n\r\n    {#-- Prevent querying of db in parsing mode. This works because this macro does not create any new refs. -#}\r\n    {%- if not execute %}\r\n        {{ return('') }}\r\n    {% endif -%}\r\n\r\n    {%- set column_override = column_override if column_override is not none else {} -%}\r\n\r\n    {%- set relation_columns = {} -%}\r\n    {%- set column_superset = {} -%}\r\n\r\n    {%- for relation in relations -%}\r\n\r\n        {%- do relation_columns.update({relation: []}) -%}\r\n\r\n        {%- do dbt_utils._is_relation(relation, 'union_relations') -%}\r\n        {%- do dbt_utils._is_ephemeral(relation, 'union_relations') -%}\r\n        {%- set cols = adapter.get_columns_in_relation(relation) -%}\r\n        {%- for col in cols -%}\r\n\r\n        {#- If an exclude list was provided and the column is in the list, do nothing -#}\r\n        {%- if exclude and col.column in exclude -%}\r\n\r\n        {#- If an include list was provided and the column is not in the list, do nothing -#}\r\n        {%- elif include and col.column not in include -%}\r\n\r\n        {#- Otherwise add the column to the column superset -#}\r\n        {%- else -%}\r\n\r\n            {#- update the list of columns in this relation -#}\r\n            {%- do relation_columns[relation].append(col.column) -%}\r\n\r\n            {%- if col.column in column_superset -%}\r\n\r\n                {%- set stored = column_superset[col.column] -%}\r\n                {%- if col.is_string() and stored.is_string() and col.string_size() > stored.string_size() -%}\r\n\r\n                    {%- do column_superset.update({col.column: col}) -%}\r\n\r\n                {%- endif %}\r\n\r\n            {%- else -%}\r\n\r\n                {%- do column_superset.update({col.column: col}) -%}\r\n\r\n            {%- endif -%}\r\n\r\n        {%- endif -%}\r\n\r\n        {%- endfor -%}\r\n    {%- endfor -%}\r\n\r\n    {%- set ordered_column_names = column_superset.keys() -%}\r\n\r\n    {%- for relation in relations %}\r\n\r\n        (\r\n            select\r\n\r\n                cast({{ dbt_utils.string_literal(relation) }} as {{ dbt_utils.type_string() }}) as {{ source_column_name }},\r\n                {% for col_name in ordered_column_names -%}\r\n\r\n                    {%- set col = column_superset[col_name] %}\r\n                    {%- set col_type = column_override.get(col.column, col.data_type) %}\r\n                    {%- set col_name = adapter.quote(col_name) if col_name in relation_columns[relation] else 'null' %}\r\n                    cast({{ col_name }} as {{ col_type }}) as {{ col.quoted }} {% if not loop.last %},{% endif -%}\r\n\r\n                {%- endfor %}\r\n\r\n            from {{ relation }}\r\n        )\r\n\r\n        {% if not loop.last -%}\r\n            union all\r\n        {% endif -%}\r\n\r\n    {%- endfor -%}\r\n\r\n{%- endmacro -%}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.unpivot": {"unique_id": "macro.dbt_utils.unpivot", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\sql\\unpivot.sql", "original_file_path": "macros\\sql\\unpivot.sql", "name": "unpivot", "macro_sql": "{% macro unpivot(relation=none, cast_to='varchar', exclude=none, remove=none, field_name='field_name', value_name='value', table=none) -%}\r\n\r\n    {% if table %}\r\n        {%- set error_message = '\r\n            Warning: the `unpivot` macro no longer accepts a `table` parameter. \\\r\n            This parameter will be deprecated in a future release of dbt-utils. Use the `relation` parameter instead. \\\r\n            The {}.{} model triggered this warning. \\\r\n            '.format(model.package_name, model.name) -%}\r\n        {%- do exceptions.warn(error_message) -%}\r\n    {% endif %}\r\n\r\n    {% if relation and table %}\r\n        {{ exceptions.raise_compiler_error(\"Error: both the `relation` and `table` parameters were provided to `unpivot` macro. Choose one only (we recommend `relation`).\") }}\r\n    {% elif not relation and table %}\r\n        {% set relation=table %}\r\n    {% elif not relation and not table %}\r\n        {{ exceptions.raise_compiler_error(\"Error: argument `relation` is required for `unpivot` macro.\") }}\r\n    {% endif %}\r\n\r\n  {%- set exclude = exclude if exclude is not none else [] %}\r\n  {%- set remove = remove if remove is not none else [] %}\r\n\r\n  {%- set include_cols = [] %}\r\n\r\n  {%- set table_columns = {} %}\r\n\r\n  {%- do table_columns.update({relation: []}) %}\r\n\r\n  {%- do dbt_utils._is_relation(relation, 'unpivot') -%}\r\n  {%- do dbt_utils._is_ephemeral(relation, 'unpivot') -%}\r\n  {%- set cols = adapter.get_columns_in_relation(relation) %}\r\n\r\n  {%- for col in cols -%}\r\n    {%- if col.column.lower() not in remove|map('lower') and col.column.lower() not in exclude|map('lower') -%}\r\n      {% do include_cols.append(col) %}\r\n    {%- endif %}\r\n  {%- endfor %}\r\n\r\n\r\n  {%- for col in include_cols -%}\r\n    select\r\n      {%- for exclude_col in exclude %}\r\n        {{ exclude_col }},\r\n      {%- endfor %}\r\n\r\n      cast('{{ col.column }}' as {{ dbt_utils.type_string() }}) as {{ field_name }},\r\n      cast({{ col.column }} as {{ cast_to }}) as {{ value_name }}\r\n\r\n    from {{ relation }}\r\n\r\n    {% if not loop.last -%}\r\n      union all\r\n    {% endif -%}\r\n  {%- endfor -%}\r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_url_host": {"unique_id": "macro.dbt_utils.get_url_host", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\web\\get_url_host.sql", "original_file_path": "macros\\web\\get_url_host.sql", "name": "get_url_host", "macro_sql": "{% macro get_url_host(field) -%}\r\n\r\n{%- set parsed = \r\n    dbt_utils.split_part(\r\n        dbt_utils.split_part(\r\n            dbt_utils.replace(\r\n                dbt_utils.replace(field, \"'http://'\", \"''\"\r\n                ), \"'https://'\", \"''\"\r\n            ), \"'/'\", 1\r\n        ), \"'?'\", 1\r\n    )\r\n    \r\n-%}\r\n\r\n     \r\n    {{ dbt_utils.safe_cast(\r\n        parsed,\r\n        dbt_utils.type_string()\r\n        )}}\r\n        \r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_url_parameter": {"unique_id": "macro.dbt_utils.get_url_parameter", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\web\\get_url_parameter.sql", "original_file_path": "macros\\web\\get_url_parameter.sql", "name": "get_url_parameter", "macro_sql": "{% macro get_url_parameter(field, url_parameter) -%}\r\n\r\n{%- set formatted_url_parameter = \"'\" + url_parameter + \"='\" -%}\r\n\r\n{%- set split = dbt_utils.split_part(dbt_utils.split_part(field, formatted_url_parameter, 2), \"'&'\", 1) -%}\r\n\r\nnullif({{ split }},'')\r\n\r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}, "macro.dbt_utils.get_url_path": {"unique_id": "macro.dbt_utils.get_url_path", "package_name": "dbt_utils", "root_path": "C:\\Users\\james\\Documents\\GitHub\\dbt-ml-preprocessing\\integration_tests\\dbt_modules\\dbt_utils", "path": "macros\\web\\get_url_path.sql", "original_file_path": "macros\\web\\get_url_path.sql", "name": "get_url_path", "macro_sql": "{% macro get_url_path(field) -%}\r\n\r\n    {%- set stripped_url = \r\n        dbt_utils.replace(\r\n            dbt_utils.replace(field, \"'http://'\", \"''\"), \"'https://'\", \"''\")\r\n    -%}\r\n\r\n    {%- set first_slash_pos -%}\r\n        coalesce(\r\n            nullif({{dbt_utils.position(\"'/'\", stripped_url)}}, 0),\r\n            {{dbt_utils.position(\"'?'\", stripped_url)}} - 1\r\n            )\r\n    {%- endset -%}\r\n\r\n    {%- set parsed_path =\r\n        dbt_utils.split_part(\r\n            dbt_utils.right(\r\n                stripped_url, \r\n                dbt_utils.length(stripped_url) ~ \"-\" ~ first_slash_pos\r\n                ), \r\n            \"'?'\", 1\r\n            )\r\n    -%}\r\n\r\n    {{ dbt_utils.safe_cast(\r\n        parsed_path,\r\n        dbt_utils.type_string()\r\n    )}}\r\n    \r\n{%- endmacro %}", "resource_type": "macro", "tags": [], "depends_on": {"macros": []}, "description": "", "meta": {}, "docs": {"show": true}, "patch_path": null, "arguments": []}}, "docs": {"dbt.__overview__": {"unique_id": "dbt.__overview__", "package_name": "dbt", "root_path": "C:\\Users\\james\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\dbt\\include\\global_project", "path": "overview.md", "original_file_path": "docs\\overview.md", "name": "__overview__", "block_contents": "### Welcome!\n\nWelcome to the auto-generated documentation for your dbt project!\n\n### Navigation\n\nYou can use the `Project` and `Database` navigation tabs on the left side of the window to explore the models\nin your project.\n\n#### Project Tab\nThe `Project` tab mirrors the directory structure of your dbt project. In this tab, you can see all of the\nmodels defined in your dbt project, as well as models imported from dbt packages.\n\n#### Database Tab\nThe `Database` tab also exposes your models, but in a format that looks more like a database explorer. This view\nshows relations (tables and views) grouped into database schemas. Note that ephemeral models are _not_ shown\nin this interface, as they do not exist in the database.\n\n### Graph Exploration\nYou can click the blue icon on the bottom-right corner of the page to view the lineage graph of your models.\n\nOn model pages, you'll see the immediate parents and children of the model you're exploring. By clicking the `Expand`\nbutton at the top-right of this lineage pane, you'll be able to see all of the models that are used to build,\nor are built from, the model you're exploring.\n\nOnce expanded, you'll be able to use the `--models` and `--exclude` model selection syntax to filter the\nmodels in the graph. For more information on model selection, check out the [dbt docs](https://docs.getdbt.com/docs/model-selection-syntax).\n\nNote that you can also right-click on models to interactively filter and explore the graph.\n\n---\n\n### More information\n\n- [What is dbt](https://docs.getdbt.com/docs/overview)?\n- Read the [dbt viewpoint](https://docs.getdbt.com/docs/viewpoint)\n- [Installation](https://docs.getdbt.com/docs/installation)\n- Join the [chat](https://community.getdbt.com/) on Slack for live questions and support."}}, "exposures": {}, "disabled": [], "generated_at": "2021-03-10T01:29:10.763790Z", "parent_map": {"model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_50_bins": ["seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer"], "model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_default_bins": ["seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer"], "model.dbt_ml_preprocessing_integration_tests.test_label_encoder": ["seed.dbt_ml_preprocessing_integration_tests.data_label_encoder"], "model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler": ["seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler"], "model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler_with_column_selection": ["seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler"], "model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler": ["seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler"], "model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler_with_column_selection": ["seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler"], "model.dbt_ml_preprocessing_integration_tests.test_normalizer": ["seed.dbt_ml_preprocessing_integration_tests.data_normalizer"], "model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder": ["seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder"], "model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder_category_selected": ["seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder"], "model.dbt_ml_preprocessing_integration_tests.test_quantile_transformer": ["seed.dbt_ml_preprocessing_integration_tests.data_quantile_transformer"], "model.dbt_ml_preprocessing_integration_tests.test_robust_scaler": ["seed.dbt_ml_preprocessing_integration_tests.data_robust_scaler"], "model.dbt_ml_preprocessing_integration_tests.test_standard_scaler": ["seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler"], "test.dbt_ml_preprocessing_integration_tests.test_quantile_transformer_result_with_tolerance": [], "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer": [], "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer_50_bins_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer_default_bins_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_label_encoder": [], "seed.dbt_ml_preprocessing_integration_tests.data_label_encoder_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler": [], "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler_with_column_selection_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler": [], "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler_with_column_selection_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_normalizer": [], "seed.dbt_ml_preprocessing_integration_tests.data_normalizer_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder": [], "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder_category_selected_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_quantile_transformer": [], "seed.dbt_ml_preprocessing_integration_tests.data_quantile_transformer_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_robust_scaler": [], "seed.dbt_ml_preprocessing_integration_tests.data_robust_scaler_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler": [], "seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler_expected": [], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_max_abs_scaler_ref_data_max_abs_scaler_expected_": ["model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler", "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler_expected"], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_max_abs_scaler_with_column_selection_ref_data_max_abs_scaler_with_column_selection_expected_": ["model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler_with_column_selection", "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler_with_column_selection_expected"], "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_min_max_scaler_ref_data_min_max_scaler_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled": ["model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler", "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler_expected"], "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_min_max_scaler_with_column_selection_ref_data_min_max_scaler_with_column_selection_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled": ["model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler_with_column_selection", "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler_with_column_selection_expected"], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_k_bins_discretizer_default_bins_ref_data_k_bins_discretizer_default_bins_expected_": ["model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_default_bins", "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer_default_bins_expected"], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_k_bins_discretizer_50_bins_ref_data_k_bins_discretizer_50_bins_expected_": ["model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_50_bins", "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer_50_bins_expected"], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_label_encoder_ref_data_label_encoder_expected_": ["model.dbt_ml_preprocessing_integration_tests.test_label_encoder", "seed.dbt_ml_preprocessing_integration_tests.data_label_encoder_expected"], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_normalizer_ref_data_normalizer_expected_": ["model.dbt_ml_preprocessing_integration_tests.test_normalizer", "seed.dbt_ml_preprocessing_integration_tests.data_normalizer_expected"], "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_1_scaled__id_col__col_to_scale_1_scaled": ["model.dbt_ml_preprocessing_integration_tests.test_standard_scaler", "seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler_expected"], "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_2_scaled__id_col__col_to_scale_2_scaled": ["model.dbt_ml_preprocessing_integration_tests.test_standard_scaler", "seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler_expected"], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_one_hot_encoder_ref_data_one_hot_encoder_expected_": ["model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder", "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder_expected"], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_one_hot_encoder_category_selected_ref_data_one_hot_encoder_category_selected_expected_": ["model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder_category_selected", "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder_category_selected_expected"], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_robust_scaler_ref_data_robust_scaler_expected_": ["model.dbt_ml_preprocessing_integration_tests.test_robust_scaler", "seed.dbt_ml_preprocessing_integration_tests.data_robust_scaler_expected"]}, "child_map": {"model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_50_bins": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_k_bins_discretizer_50_bins_ref_data_k_bins_discretizer_50_bins_expected_"], "model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_default_bins": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_k_bins_discretizer_default_bins_ref_data_k_bins_discretizer_default_bins_expected_"], "model.dbt_ml_preprocessing_integration_tests.test_label_encoder": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_label_encoder_ref_data_label_encoder_expected_"], "model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_max_abs_scaler_ref_data_max_abs_scaler_expected_"], "model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler_with_column_selection": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_max_abs_scaler_with_column_selection_ref_data_max_abs_scaler_with_column_selection_expected_"], "model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler": ["test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_min_max_scaler_ref_data_min_max_scaler_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled"], "model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler_with_column_selection": ["test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_min_max_scaler_with_column_selection_ref_data_min_max_scaler_with_column_selection_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled"], "model.dbt_ml_preprocessing_integration_tests.test_normalizer": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_normalizer_ref_data_normalizer_expected_"], "model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_one_hot_encoder_ref_data_one_hot_encoder_expected_"], "model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder_category_selected": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_one_hot_encoder_category_selected_ref_data_one_hot_encoder_category_selected_expected_"], "model.dbt_ml_preprocessing_integration_tests.test_quantile_transformer": [], "model.dbt_ml_preprocessing_integration_tests.test_robust_scaler": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_robust_scaler_ref_data_robust_scaler_expected_"], "model.dbt_ml_preprocessing_integration_tests.test_standard_scaler": ["test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_1_scaled__id_col__col_to_scale_1_scaled", "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_2_scaled__id_col__col_to_scale_2_scaled"], "test.dbt_ml_preprocessing_integration_tests.test_quantile_transformer_result_with_tolerance": [], "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer": ["model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_50_bins", "model.dbt_ml_preprocessing_integration_tests.test_k_bins_discretizer_default_bins"], "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer_50_bins_expected": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_k_bins_discretizer_50_bins_ref_data_k_bins_discretizer_50_bins_expected_"], "seed.dbt_ml_preprocessing_integration_tests.data_k_bins_discretizer_default_bins_expected": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_k_bins_discretizer_default_bins_ref_data_k_bins_discretizer_default_bins_expected_"], "seed.dbt_ml_preprocessing_integration_tests.data_label_encoder": ["model.dbt_ml_preprocessing_integration_tests.test_label_encoder"], "seed.dbt_ml_preprocessing_integration_tests.data_label_encoder_expected": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_label_encoder_ref_data_label_encoder_expected_"], "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler": ["model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler", "model.dbt_ml_preprocessing_integration_tests.test_max_abs_scaler_with_column_selection", "model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler", "model.dbt_ml_preprocessing_integration_tests.test_min_max_scaler_with_column_selection"], "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler_expected": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_max_abs_scaler_ref_data_max_abs_scaler_expected_"], "seed.dbt_ml_preprocessing_integration_tests.data_max_abs_scaler_with_column_selection_expected": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_max_abs_scaler_with_column_selection_ref_data_max_abs_scaler_with_column_selection_expected_"], "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler": [], "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler_expected": ["test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_min_max_scaler_ref_data_min_max_scaler_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled"], "seed.dbt_ml_preprocessing_integration_tests.data_min_max_scaler_with_column_selection_expected": ["test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_min_max_scaler_with_column_selection_ref_data_min_max_scaler_with_column_selection_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled"], "seed.dbt_ml_preprocessing_integration_tests.data_normalizer": ["model.dbt_ml_preprocessing_integration_tests.test_normalizer"], "seed.dbt_ml_preprocessing_integration_tests.data_normalizer_expected": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_normalizer_ref_data_normalizer_expected_"], "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder": ["model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder", "model.dbt_ml_preprocessing_integration_tests.test_one_hot_encoder_category_selected"], "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder_category_selected_expected": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_one_hot_encoder_category_selected_ref_data_one_hot_encoder_category_selected_expected_"], "seed.dbt_ml_preprocessing_integration_tests.data_one_hot_encoder_expected": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_one_hot_encoder_ref_data_one_hot_encoder_expected_"], "seed.dbt_ml_preprocessing_integration_tests.data_quantile_transformer": ["model.dbt_ml_preprocessing_integration_tests.test_quantile_transformer"], "seed.dbt_ml_preprocessing_integration_tests.data_quantile_transformer_expected": [], "seed.dbt_ml_preprocessing_integration_tests.data_robust_scaler": ["model.dbt_ml_preprocessing_integration_tests.test_robust_scaler"], "seed.dbt_ml_preprocessing_integration_tests.data_robust_scaler_expected": ["test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_robust_scaler_ref_data_robust_scaler_expected_"], "seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler": ["model.dbt_ml_preprocessing_integration_tests.test_standard_scaler"], "seed.dbt_ml_preprocessing_integration_tests.data_standard_scaler_expected": ["test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_1_scaled__id_col__col_to_scale_1_scaled", "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_2_scaled__id_col__col_to_scale_2_scaled"], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_max_abs_scaler_ref_data_max_abs_scaler_expected_": [], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_max_abs_scaler_with_column_selection_ref_data_max_abs_scaler_with_column_selection_expected_": [], "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_min_max_scaler_ref_data_min_max_scaler_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled": [], "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_min_max_scaler_with_column_selection_ref_data_min_max_scaler_with_column_selection_expected___1e_08__id_col__col_to_scale_scaled__id_col__col_to_scale_scaled": [], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_k_bins_discretizer_default_bins_ref_data_k_bins_discretizer_default_bins_expected_": [], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_k_bins_discretizer_50_bins_ref_data_k_bins_discretizer_50_bins_expected_": [], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_label_encoder_ref_data_label_encoder_expected_": [], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_normalizer_ref_data_normalizer_expected_": [], "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_1_scaled__id_col__col_to_scale_1_scaled": [], "test.dbt_ml_preprocessing_integration_tests.equality_with_numeric_tolerance_test_standard_scaler_ref_data_standard_scaler_expected___1e_07__id_col__col_to_scale_2_scaled__id_col__col_to_scale_2_scaled": [], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_one_hot_encoder_ref_data_one_hot_encoder_expected_": [], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_one_hot_encoder_category_selected_ref_data_one_hot_encoder_category_selected_expected_": [], "test.dbt_ml_preprocessing_integration_tests.dbt_utils_equality_test_robust_scaler_ref_data_robust_scaler_expected_": []}, "metadata": {"project_id": "4c39ee91a67199a1369c99b754902aec", "user_id": "47416b18-398f-4b5a-854c-bd5fa018fcbd", "send_anonymous_usage_stats": true, "adapter_type": "snowflake"}}